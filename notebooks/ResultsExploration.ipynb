{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfadbdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 24 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Import\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "# Initialization\n",
    "pandarallel.initialize()\n",
    "\n",
    "import os\n",
    "import json\n",
    "# !pip install pywer\n",
    "import pywer\n",
    "# !pip install pyjarowinkler\n",
    "from pyjarowinkler import distance as jwdistance\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Const:\n",
    "    OCR = 'ocr'\n",
    "    GROUND = 'groundtruth'\n",
    "    REGION = 'region'\n",
    "    LINE = 'line'\n",
    "    SENTENCE = 'sentence'\n",
    "    FILE = 'filename'\n",
    "    DATASET = 'dataset_name'\n",
    "    PREDICTION = 'prediction'\n",
    "    PROMPT = 'prompt'\n",
    "    LANGUAGE = 'language'\n",
    "    NONE = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00f4b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandarallel\n",
    "# !pip install pywer\n",
    "# !pip install pyjarowinkler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118ead6e",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f79f14e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/datasets/ocr/converted/icdar-2019/icdar-2019.jsonl icdar-2019\n",
      "../data/datasets/ocr/converted/ajmc-primary/ajmc_primary_text.jsonl ajmc-primary\n",
      "../data/datasets/ocr/converted/overproof/overproof.jsonl overproof\n",
      "../data/datasets/ocr/converted/ajmc-mixed/ajmc_mixed.jsonl ajmc-mixed\n",
      "../data/datasets/ocr/converted/impresso/impresso-nzz.jsonl impresso\n",
      "../data/datasets/ocr/converted/icdar-2017/icdar-2017.jsonl icdar-2017\n",
      "../data/datasets/htr/converted/htrec/htrec.jsonl htrec\n",
      "../data/datasets/asr/converted/ina/ina.jsonl ina\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for root, dirs, files in os.walk(f'data/processed_data/'):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            input_file = os.path.join(root, file)\n",
    "            df = pd.read_csv(input_file)\n",
    "            results.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea001bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>filename</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>ocr.line</th>\n",
       "      <th>ocr.sentence</th>\n",
       "      <th>ocr.region</th>\n",
       "      <th>groundtruth.line</th>\n",
       "      <th>groundtruth.sentence</th>\n",
       "      <th>groundtruth.region</th>\n",
       "      <th>prediction.prompt</th>\n",
       "      <th>prediction.sentence</th>\n",
       "      <th>prediction.region</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>type</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fr</td>\n",
       "      <td>../../data/datasets/ocr/original/icdar-2019/IC...</td>\n",
       "      <td>icdar-2019</td>\n",
       "      <td>None</td>\n",
       "      <td>Charles, par la grace de Dieu, etc.</td>\n",
       "      <td>Charles, par la grace de Dieu, etc. Savoir fai...</td>\n",
       "      <td>None</td>\n",
       "      <td>Charles, par la grace de Dieu, etc.</td>\n",
       "      <td>Charles, par la grace de Dieu, etc. Savoir fai...</td>\n",
       "      <td>Veuillez nous aider à réviser et à corriger le...</td>\n",
       "      <td>/s&gt;Veuillez nous aider à réviser et à corriger...</td>\n",
       "      <td>/s&gt;Veuillez nous aider à réviser et à corriger...</td>\n",
       "      <td>facebook-opt-6.7b</td>\n",
       "      <td>prompt_complex_lang</td>\n",
       "      <td>prompt_complex_03_per_lang</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>results-icdar-2019-facebook-opt-6.7b.jsonl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fr</td>\n",
       "      <td>../../data/datasets/ocr/original/icdar-2019/IC...</td>\n",
       "      <td>icdar-2019</td>\n",
       "      <td>None</td>\n",
       "      <td>Savoir faisons à touz, presens et avenir, à no...</td>\n",
       "      <td>Charles, par la grace de Dieu, etc. Savoir fai...</td>\n",
       "      <td>None</td>\n",
       "      <td>Savoir faisons à touz, presens et avenir, à no...</td>\n",
       "      <td>Charles, par la grace de Dieu, etc. Savoir fai...</td>\n",
       "      <td>Veuillez nous aider à réviser et à corriger le...</td>\n",
       "      <td>/s&gt;Veuillez nous aider à réviser et à corriger...</td>\n",
       "      <td>/s&gt;Veuillez nous aider à réviser et à corriger...</td>\n",
       "      <td>facebook-opt-6.7b</td>\n",
       "      <td>prompt_complex_lang</td>\n",
       "      <td>prompt_complex_03_per_lang</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>results-icdar-2019-facebook-opt-6.7b.jsonl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fr</td>\n",
       "      <td>../../data/datasets/ocr/original/icdar-2019/IC...</td>\n",
       "      <td>icdar-2019</td>\n",
       "      <td>None</td>\n",
       "      <td>Et avant que le dit Amelin peust sur ce remedi...</td>\n",
       "      <td>Charles, par la grace de Dieu, etc. Savoir fai...</td>\n",
       "      <td>None</td>\n",
       "      <td>et avant que le dit Amelin peust sur ce remedi...</td>\n",
       "      <td>Charles, par la grace de Dieu, etc. Savoir fai...</td>\n",
       "      <td>Veuillez nous aider à réviser et à corriger le...</td>\n",
       "      <td>/s&gt;Veuillez nous aider à réviser et à corriger...</td>\n",
       "      <td>/s&gt;Veuillez nous aider à réviser et à corriger...</td>\n",
       "      <td>facebook-opt-6.7b</td>\n",
       "      <td>prompt_complex_lang</td>\n",
       "      <td>prompt_complex_03_per_lang</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>results-icdar-2019-facebook-opt-6.7b.jsonl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fr</td>\n",
       "      <td>../../data/datasets/ocr/original/icdar-2019/IC...</td>\n",
       "      <td>icdar-2019</td>\n",
       "      <td>None</td>\n",
       "      <td>linceulz et ii.</td>\n",
       "      <td>Charles, par la grace de Dieu, etc. Savoir fai...</td>\n",
       "      <td>None</td>\n",
       "      <td>linceulz et n</td>\n",
       "      <td>Charles, par la grace de Dieu, etc. Savoir fai...</td>\n",
       "      <td>Veuillez nous aider à réviser et à corriger le...</td>\n",
       "      <td>/s&gt;Veuillez nous aider à réviser et à corriger...</td>\n",
       "      <td>/s&gt;Veuillez nous aider à réviser et à corriger...</td>\n",
       "      <td>facebook-opt-6.7b</td>\n",
       "      <td>prompt_complex_lang</td>\n",
       "      <td>prompt_complex_03_per_lang</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>results-icdar-2019-facebook-opt-6.7b.jsonl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr</td>\n",
       "      <td>../../data/datasets/ocr/original/icdar-2019/IC...</td>\n",
       "      <td>icdar-2019</td>\n",
       "      <td>None</td>\n",
       "      <td>couvertes, et d’ilecques s’en alerent là où bo...</td>\n",
       "      <td>Charles, par la grace de Dieu, etc. Savoir fai...</td>\n",
       "      <td>None</td>\n",
       "      <td>convertes, et d'ilecques s'en alerent là où bo...</td>\n",
       "      <td>Charles, par la grace de Dieu, etc. Savoir fai...</td>\n",
       "      <td>Veuillez nous aider à réviser et à corriger le...</td>\n",
       "      <td>/s&gt;Veuillez nous aider à réviser et à corriger...</td>\n",
       "      <td>/s&gt;Veuillez nous aider à réviser et à corriger...</td>\n",
       "      <td>facebook-opt-6.7b</td>\n",
       "      <td>prompt_complex_lang</td>\n",
       "      <td>prompt_complex_03_per_lang</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>results-icdar-2019-facebook-opt-6.7b.jsonl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                           filename dataset_name  \\\n",
       "0       fr  ../../data/datasets/ocr/original/icdar-2019/IC...   icdar-2019   \n",
       "1       fr  ../../data/datasets/ocr/original/icdar-2019/IC...   icdar-2019   \n",
       "2       fr  ../../data/datasets/ocr/original/icdar-2019/IC...   icdar-2019   \n",
       "3       fr  ../../data/datasets/ocr/original/icdar-2019/IC...   icdar-2019   \n",
       "4       fr  ../../data/datasets/ocr/original/icdar-2019/IC...   icdar-2019   \n",
       "\n",
       "  ocr.line                                       ocr.sentence  \\\n",
       "0     None                Charles, par la grace de Dieu, etc.   \n",
       "1     None  Savoir faisons à touz, presens et avenir, à no...   \n",
       "2     None  Et avant que le dit Amelin peust sur ce remedi...   \n",
       "3     None                                    linceulz et ii.   \n",
       "4     None  couvertes, et d’ilecques s’en alerent là où bo...   \n",
       "\n",
       "                                          ocr.region groundtruth.line  \\\n",
       "0  Charles, par la grace de Dieu, etc. Savoir fai...             None   \n",
       "1  Charles, par la grace de Dieu, etc. Savoir fai...             None   \n",
       "2  Charles, par la grace de Dieu, etc. Savoir fai...             None   \n",
       "3  Charles, par la grace de Dieu, etc. Savoir fai...             None   \n",
       "4  Charles, par la grace de Dieu, etc. Savoir fai...             None   \n",
       "\n",
       "                                groundtruth.sentence  \\\n",
       "0                Charles, par la grace de Dieu, etc.   \n",
       "1  Savoir faisons à touz, presens et avenir, à no...   \n",
       "2  et avant que le dit Amelin peust sur ce remedi...   \n",
       "3                                      linceulz et n   \n",
       "4  convertes, et d'ilecques s'en alerent là où bo...   \n",
       "\n",
       "                                  groundtruth.region  \\\n",
       "0  Charles, par la grace de Dieu, etc. Savoir fai...   \n",
       "1  Charles, par la grace de Dieu, etc. Savoir fai...   \n",
       "2  Charles, par la grace de Dieu, etc. Savoir fai...   \n",
       "3  Charles, par la grace de Dieu, etc. Savoir fai...   \n",
       "4  Charles, par la grace de Dieu, etc. Savoir fai...   \n",
       "\n",
       "                                   prediction.prompt  \\\n",
       "0  Veuillez nous aider à réviser et à corriger le...   \n",
       "1  Veuillez nous aider à réviser et à corriger le...   \n",
       "2  Veuillez nous aider à réviser et à corriger le...   \n",
       "3  Veuillez nous aider à réviser et à corriger le...   \n",
       "4  Veuillez nous aider à réviser et à corriger le...   \n",
       "\n",
       "                                 prediction.sentence  \\\n",
       "0  /s>Veuillez nous aider à réviser et à corriger...   \n",
       "1  /s>Veuillez nous aider à réviser et à corriger...   \n",
       "2  /s>Veuillez nous aider à réviser et à corriger...   \n",
       "3  /s>Veuillez nous aider à réviser et à corriger...   \n",
       "4  /s>Veuillez nous aider à réviser et à corriger...   \n",
       "\n",
       "                                   prediction.region              model  \\\n",
       "0  /s>Veuillez nous aider à réviser et à corriger...  facebook-opt-6.7b   \n",
       "1  /s>Veuillez nous aider à réviser et à corriger...  facebook-opt-6.7b   \n",
       "2  /s>Veuillez nous aider à réviser et à corriger...  facebook-opt-6.7b   \n",
       "3  /s>Veuillez nous aider à réviser et à corriger...  facebook-opt-6.7b   \n",
       "4  /s>Veuillez nous aider à réviser et à corriger...  facebook-opt-6.7b   \n",
       "\n",
       "                prompt                 prompt_text       type  \\\n",
       "0  prompt_complex_lang  prompt_complex_03_per_lang  zero-shot   \n",
       "1  prompt_complex_lang  prompt_complex_03_per_lang  zero-shot   \n",
       "2  prompt_complex_lang  prompt_complex_03_per_lang  zero-shot   \n",
       "3  prompt_complex_lang  prompt_complex_03_per_lang  zero-shot   \n",
       "4  prompt_complex_lang  prompt_complex_03_per_lang  zero-shot   \n",
       "\n",
       "                                         file  \n",
       "0  results-icdar-2019-facebook-opt-6.7b.jsonl  \n",
       "1  results-icdar-2019-facebook-opt-6.7b.jsonl  \n",
       "2  results-icdar-2019-facebook-opt-6.7b.jsonl  \n",
       "3  results-icdar-2019-facebook-opt-6.7b.jsonl  \n",
       "4  results-icdar-2019-facebook-opt-6.7b.jsonl  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7756144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(results)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9300d6b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.model.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c0f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.prompt.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[f\"quality-band\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83313819",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[f'overall-lvenshtein-improvement'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b541a3",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e8925",
   "metadata": {},
   "source": [
    "## Sampling for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4147f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# dataset_names = data.dataset_name.unique()\n",
    "# quality_bands = [\"0-40%\", \"40-60%\", \"60-80%\", \"80-99%\", \"99-100%\"]\n",
    "\n",
    "# sample_list = []\n",
    "# # Iterate over all unique datasets\n",
    "# for dataset in tqdm(dataset_names, total = len(dataset_names)):\n",
    "#     # Get the unique languages for the current dataset\n",
    "#     languages = data[data['dataset_name'] == dataset]['language'].unique()\n",
    "#     print(dataset)\n",
    "#     # Iterate over each unique language\n",
    "#     for language in languages:\n",
    "#         print('  --', language)\n",
    "#         groundtruth_samples = data[(data['dataset_name'] == dataset) \n",
    "#                                    & (data['language'] == language)\n",
    "#                                    & (data['groundtruth.sentence'].str.len() > 10)].drop_duplicates(subset=['groundtruth.line', 'groundtruth.sentence', 'groundtruth.region'])\n",
    "#         # Limit the groundtruth_samples to three\n",
    "#         if len(groundtruth_samples) >= 3:\n",
    "#             groundtruth_samples = groundtruth_samples.sample(3, random_state=1335)\n",
    "\n",
    "            \n",
    "#         print(len(groundtruth_samples))             \n",
    "#         # Iterate over each unique groundtruth samples\n",
    "#         for idx, gt_sample in groundtruth_samples.iterrows():\n",
    "#             prompts = data[data['dataset_name'] == dataset]['prompt'].unique()\n",
    "                           \n",
    "#             models = data[data['dataset_name'] == dataset]['model'].unique()\n",
    "                          \n",
    "#             improvement_bands = data[data['dataset_name'] == dataset]['Improvement Band'].unique()\n",
    "#             is_few_shot_or_not = data[data['dataset_name'] == dataset]['type'].unique()\n",
    "\n",
    "#             # Iterate over each unique prompt\n",
    "#             for prompt in prompts:\n",
    "#                 print('    -', prompt)\n",
    "#                 # Iterate over each unique model\n",
    "#                 for model in models:\n",
    "# #                     print('     --', model)\n",
    "#                     # Iterate over each quality band\n",
    "#                     for band in quality_bands:\n",
    "# #                         print('        ---', band)\n",
    "#                         # Iterate over each improvement band\n",
    "#                         for improvement_band in improvement_bands:\n",
    "# #                             print('          ----', improvement_band)\n",
    "#                             for is_few_shot in is_few_shot_or_not:\n",
    "# #                                 print('-------', is_few_shot)\n",
    "#                                 subset = data[(data['dataset_name'] == dataset) \n",
    "#                                               & (data['language'] == language)\n",
    "#                                               & (data['prompt'] == prompt)\n",
    "#                                               & (data['model'] == model)\n",
    "#                                               & (data['Improvement Band'] == improvement_band)\n",
    "#                                               & (data['Quality Band'] == band)\n",
    "#                                               & (data['type'] == is_few_shot)\n",
    "#                                               & (data['groundtruth.line'] == gt_sample['groundtruth.line'])\n",
    "#                                               & (data['groundtruth.sentence'] == gt_sample['groundtruth.sentence'])\n",
    "#                                               & (data['groundtruth.region'] == gt_sample['groundtruth.region'])]\n",
    "                                          \n",
    "#                                 # If the subset is not empty, take a sample\n",
    "#                                 if not subset.empty:\n",
    "#                                     sample = subset.sample(1, random_state=1, replace=True)\n",
    "#                                     sample_list.append(sample)\n",
    "#     #                                 print(sample)\n",
    "#     #                             else:\n",
    "#     #                                 print(f\"No samples for Dataset: {dataset}, Language: {language}\")\n",
    "\n",
    "                                      \n",
    "# # Concatenate all the samples into a single DataFrame\n",
    "# sample_df = pd.concat(sample_list, ignore_index=True)\n",
    "                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27599ac0",
   "metadata": {},
   "source": [
    "### Order columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d91bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df = sample_df.drop(['length', 'NbAlignedChar', 'prompt_text', 'File'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd36acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 'index', \n",
    "# order = ['filename', 'dataset_name', 'model', 'language', 'prompt', \n",
    "#          'Overall Levenshtein Improvement', 'Quality Band', 'Improvement Band',\n",
    "#          'ocr.line', 'groundtruth.line', 'prediction.line', \n",
    "#          'line-lev-ocr', 'line-lev-pred', 'line-lev-improvement',\n",
    "#          'ocr.sentence', 'groundtruth.sentence', 'prediction.sentence', \n",
    "#          'sentence-lev-ocr', 'sentence-lev-pred', 'sentence-lev-improvement', \n",
    "#          'ocr.region', 'groundtruth.region', 'prediction.region',\n",
    "#          'region-lev-ocr', 'region-lev-pred', 'region-lev-improvement', \n",
    "#          'article_id', 'century', 'Date', 'Type']\n",
    "\n",
    "# # Reorder the DataFrame\n",
    "# sample_df = sample_df[order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea396a1d",
   "metadata": {},
   "source": [
    "### Write sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "\n",
    "# # Use today's date for the filename\n",
    "# today = datetime.now().strftime('%d%B')  # This will format the date as 'DayMonth'\n",
    "\n",
    "# # Save the DataFrame to a csv file\n",
    "# sample_df.to_csv(f'ResultsGPTUpdated{today}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff79fc4",
   "metadata": {},
   "source": [
    "### Distribution of WER/CER rates for all datasets in the four quality bands, established via Levenshtein similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c0561",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.type.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad95c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.prompt.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474e4d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Improvement Band'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.model.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['model'] != 'LLaMA-13B']\n",
    "data = data.loc[data['model'] != 'LLAMA-65B']\n",
    "data = data.loc[data['model'] != 'GPT-3-OLD']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc9cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.model.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aace7c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\n",
    "       'LLAMA-7B', 'LLAMA-2-7B', \n",
    "       'BLOOM-560M',  'BLOOM-3B',  'BLOOM-7.1B', \n",
    "       'BLOOMZ-560M', 'BLOOMZ-3B', 'BLOOMZ-7.1B', \n",
    "       'OPT-350M', 'OPT-6.7B',\n",
    "       'GPT-2', 'GPT-3', 'GPT-3.5', 'GPT-4']\n",
    "MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a91c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_models = ['LLAMA-7B', 'LLAMA-2-7B', \n",
    "       'BLOOM-560M',  'BLOOM-3B',  'BLOOM-7.1B', \n",
    "       'BLOOMZ-560M', 'BLOOMZ-3B', 'BLOOMZ-7.1B', \n",
    "       'OPT-350M', 'OPT-6.7B',\n",
    "       'GPT-2']  # Replace these with your list of 'limited' models\n",
    "open_models = ['GPT-3', 'GPT-3.5', 'GPT-4']  # Replace these with your list of 'open' models\n",
    "\n",
    "# Create new 'Access' column\n",
    "data['Access'] = data['model'].apply(lambda x: 'limited' if x in limited_models else ('open' if x in open_models else 'unknown'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dcd0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2079a585",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be71515d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ad365",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_palette('colorblind')\n",
    "sns.set_context(\"notebook\", font_scale=1.8)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Define OCR noise level bins\n",
    "bins = [0, 0.4, 0.6, 0.8, 0.99, 1.0]\n",
    "\n",
    "# Assign OCR noise level labels\n",
    "labels = [\"0-40%\", \"40-60%\", \"60-80%\", \"80-99%\", \"99-100%\"]\n",
    "\n",
    "# Count the number of unique datasets\n",
    "n_datasets = data.dataset_name.nunique()\n",
    "dataset_names = ['impresso-nzz', 'overproof', 'ajmc-mixed', \n",
    "                 'ajmc-primary-text', 'icdar-2017', 'icdar-2019', 'htrec', 'ina']\n",
    "\n",
    "prompt_names = ['prompt_basic_01', 'prompt_basic_02', 'prompt_complex_01', \n",
    "                'prompt_complex_02', 'prompt_complex_lang']\n",
    "\n",
    "\n",
    "n_plots = len(dataset_names)\n",
    "n_plots_per_figure = 4\n",
    "n_figures = int(np.ceil(n_plots / n_plots_per_figure))\n",
    "\n",
    "print(n_figures)\n",
    "\n",
    "for type_of_experiment in ['zero-shot', 'few-shot']:\n",
    "# for type_of_experiment in ['language-specific']:\n",
    "    for error_rate in ['lev']:\n",
    "        \n",
    "        for fig_idx in range(n_figures):\n",
    "            fig, axs = plt.subplots(2, 2, figsize=(30, 15))\n",
    "            axs = axs.flatten()\n",
    "\n",
    "            for i in range(n_plots_per_figure):\n",
    "                idx = fig_idx * n_plots_per_figure + i\n",
    "                if idx < n_plots:\n",
    "                    dataset = dataset_names[idx]\n",
    "                dataset_data = data[(data.dataset_name == dataset) & (data.type == type_of_experiment)]\n",
    "                # Compute the mean WER across line, sentence, and region levels\n",
    "                if 'icdar' not in dataset:\n",
    "                    dataset_data[f'Overall Levenshtein Improvement'] = dataset_data[[f'line-{error_rate}-improvement', \n",
    "                                                                      f'sentence-{error_rate}-improvement', \n",
    "                                                                      f'region-{error_rate}-improvement']].mean(axis=1)\n",
    "                else:\n",
    "                    dataset_data[f'Overall Levenshtein Improvement'] = dataset_data[[f'sentence-{error_rate}-improvement', \n",
    "                                                                  f'region-{error_rate}-improvement']].mean(axis=1)\n",
    "\n",
    "                try:\n",
    "                    # Plot the distribution of improvements for each model\n",
    "                    _ = sns.boxplot(x='model', y=f'Overall Levenshtein Improvement', data=dataset_data, \n",
    "                                    ax=axs[i], order=MODELS, hue='prompt', hue_order=prompt_names)\n",
    "                    axs[i].set_title(f'{dataset.upper()} ({type_of_experiment})')\n",
    "\n",
    "                    axs[i].set_ylim([-1, 1.2])\n",
    "                    axs[i].set_xticklabels(axs[i].get_xticklabels(), rotation=15)  # Rotate x-axis labels\n",
    "                    axs[i].set_xlabel('')  # Remove x-axis label\n",
    "                    axs[i].set_ylabel('')  # Remove y-axis label\n",
    "                except Exception as ex:\n",
    "                    print(f'Could not load {dataset} with {ex}')\n",
    "\n",
    "\n",
    "            # Remove empty subplots\n",
    "            for i in range(len(data.dataset_name.unique()), len(axs)):\n",
    "                fig.delaxes(axs[i])\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.suptitle(f'Overall Levenshtein Improvement across Datasets, Models, and Prompts ({type_of_experiment})', fontsize=20, y=1.02)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91890cfa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_palette('colorblind')\n",
    "sns.set_context(\"notebook\", font_scale=1.)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "prompt_names = ['prompt_basic_01', 'prompt_basic_02', 'prompt_complex_01', \n",
    "                'prompt_complex_02', 'prompt_complex_lang']\n",
    "\n",
    "\n",
    "for type_of_experiment in ['zero-shot', 'few-shot']:#\n",
    "    for error_rate in ['lev']:\n",
    "        for fig_idx in range(n_figures):\n",
    "            fig, axs = plt.subplots(2, 2, figsize=(17, 9))\n",
    "            axs = axs.flatten()\n",
    "\n",
    "            for i in range(n_plots_per_figure):\n",
    "                idx = fig_idx * n_plots_per_figure + i\n",
    "                if idx < n_plots:\n",
    "                    dataset = dataset_names[idx]\n",
    "                    \n",
    "                dataset_data = data[(data.dataset_name == dataset) & (data.type == type_of_experiment)]\n",
    "                \n",
    "                dataset_data['model'] = pd.Categorical(dataset_data['model'], categories=MODELS, ordered=True)\n",
    "                \n",
    "                if 'icdar' not in dataset:\n",
    "                    dataset_data[f'Overall Levenshtein Improvement'] = dataset_data[[f'line-{error_rate}-improvement', \n",
    "                                                                      f'sentence-{error_rate}-improvement', \n",
    "                                                                      f'region-{error_rate}-improvement']].mean(axis=1)\n",
    "                else:\n",
    "                    dataset_data[f'Overall Levenshtein Improvement'] = dataset_data[[f'sentence-{error_rate}-improvement', \n",
    "                                                                  f'region-{error_rate}-improvement']].mean(axis=1)\n",
    "\n",
    "                try:\n",
    "                    # Plot the line plot of improvements for each model\n",
    "                    _ = sns.lineplot(x='model', y=f'Overall Levenshtein Improvement', \n",
    "                                     data=dataset_data.sort_values('model'), \n",
    "                                    ax=axs[i], hue='prompt', sort=False, linewidth=2)\n",
    "                    axs[i].set_title(f'{dataset.upper()} ({type_of_experiment})')\n",
    "                    axs[i].set_ylim([-1, 1.2])\n",
    "                    axs[i].set_xticklabels(axs[i].get_xticklabels(), rotation=15)\n",
    "                    axs[i].set_xlabel('Prompt Complexity')  \n",
    "                    axs[i].set_ylabel('Overall Levenshtein Improvement')  \n",
    "                except Exception as ex:\n",
    "                    print(f'Could not load {dataset} with {ex}')\n",
    "\n",
    "            # Remove empty subplots\n",
    "            for i in range(len(data.dataset_name.unique()), len(axs)):\n",
    "                fig.delaxes(axs[i])\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.suptitle(f'Evolution of Prompt Complexity across Datasets, Models, and Improvements ({type_of_experiment})', fontsize=20, y=1.02)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f69825",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_palette('colorblind')\n",
    "sns.set_context(\"notebook\", font_scale=1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "for type_of_experiment in ['zero-shot', 'few-shot']:\n",
    "    for error_rate in ['lev']:\n",
    "        # Create a new DataFrame to store the average improvements for each language and prompt\n",
    "        average_improvements = pd.DataFrame(columns=['prompt', 'language', f'Overall Levenshtein Improvement'])\n",
    "\n",
    "        for language in data.language.unique():  # Iterate over each unique language\n",
    "            for dataset in dataset_names:\n",
    "                dataset_data = data[(data.dataset_name == dataset) & (data.language == language) & (data.type == type_of_experiment)]  # Filter data for the current language\n",
    "                if 'icdar' not in dataset:\n",
    "                    dataset_data[f'Overall Levenshtein Improvement'] = dataset_data[[f'line-{error_rate}-improvement', \n",
    "                                                                          f'sentence-{error_rate}-improvement', \n",
    "                                                                          f'region-{error_rate}-improvement']].mean(axis=1)\n",
    "                else:\n",
    "                    dataset_data[f'Overall Levenshtein Improvement'] = dataset_data[[f'sentence-{error_rate}-improvement', \n",
    "                                                                      f'region-{error_rate}-improvement']].mean(axis=1)\n",
    "\n",
    "                # Group the data by prompt and language, then calculate the mean Overall Levenshtein Improvement\n",
    "                grouped_data = dataset_data.groupby(['prompt', 'language'])[f'Overall Levenshtein Improvement'].mean().reset_index()\n",
    "\n",
    "                # Add the grouped data to the average_improvements DataFrame\n",
    "                average_improvements = pd.concat([average_improvements, grouped_data])\n",
    "\n",
    "        # Group the data by prompt and language again, this time averaging the averages for each language and prompt\n",
    "        average_improvements = average_improvements.groupby(['prompt', 'language'])[f'Overall Levenshtein Improvement'].mean().reset_index()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))  # Create the plot\n",
    "\n",
    "        try:\n",
    "            # Plot the line plot of average improvements for each prompt\n",
    "            _ = sns.lineplot(x='prompt', y=f'Overall Levenshtein Improvement', hue='language', data=average_improvements, \n",
    "                             ax=ax, legend='full')  # Add hue='language' to differentiate lines by language\n",
    "        except Exception as ex:\n",
    "            print(f'Could not load data with {ex}')\n",
    "\n",
    "        ax.set_title(f'Average Overall Levenshtein Improvement ({type_of_experiment})')  # Modify title since it's no longer specific to one language\n",
    "        ax.set_ylim([-1, 1.2])\n",
    "        ax.set_xlabel('Prompt Complexity')  \n",
    "        ax.set_ylabel('Average Overall Levenshtein Improvement')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f'Evolution of Prompt Complexity and Average Improvement ({type_of_experiment})', fontsize=20, y=1.02)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_of_experiment in ['zero-shot', 'few-shot']:\n",
    "    for error_rate in ['lev']:\n",
    "        # Create a new DataFrame to store the average improvements for each language and prompt\n",
    "        average_improvements = pd.DataFrame(columns=['prompt', 'language', f'Overall Levenshtein Improvement'])\n",
    "\n",
    "        for language in data.language.unique():  # Iterate over each unique language\n",
    "            for dataset in dataset_names:\n",
    "                dataset_data = data[(data.dataset_name == dataset) & (data.language == language) & (data.type == type_of_experiment)]  # Filter data for the current language\n",
    "                if 'icdar' not in dataset:\n",
    "                    dataset_data[f'Overall Levenshtein Improvement'] = dataset_data[[f'line-{error_rate}-improvement', \n",
    "                                                                          f'sentence-{error_rate}-improvement', \n",
    "                                                                          f'region-{error_rate}-improvement']].mean(axis=1)\n",
    "                else:\n",
    "                    dataset_data[f'Overall Levenshtein Improvement'] = dataset_data[[f'sentence-{error_rate}-improvement', \n",
    "                                                                      f'region-{error_rate}-improvement']].mean(axis=1)\n",
    "\n",
    "                # Group the data by prompt and language, then calculate the mean Overall Levenshtein Improvement\n",
    "                grouped_data = dataset_data.groupby(['prompt', 'language'])[f'Overall Levenshtein Improvement'].mean().reset_index()\n",
    "\n",
    "                # Add the grouped data to the average_improvements DataFrame\n",
    "                average_improvements = pd.concat([average_improvements, grouped_data])\n",
    "\n",
    "        # Group the data by prompt and language again, this time averaging the averages for each language and prompt\n",
    "        average_improvements = average_improvements.groupby(['prompt', 'language'])[f'Overall Levenshtein Improvement'].mean().reset_index()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 10))  # Create the plot\n",
    "\n",
    "        try:\n",
    "            # Plot the KDE plot of average improvements for each prompt\n",
    "            for language in average_improvements.language.unique():\n",
    "                _ = sns.kdeplot(average_improvements[average_improvements.language == language][f'Overall Levenshtein Improvement'], \n",
    "                                ax=ax, label=language, lw=2.5)  # Increase line width here\n",
    "        except Exception as ex:\n",
    "            print(f'Could not load data with {ex}')\n",
    "\n",
    "        ax.set_title(f'Average Overall Levenshtein Improvement KDE ({type_of_experiment})')  # Modify title since it's no longer specific to one language\n",
    "        ax.set_xlabel('Average Overall Levenshtein Improvement')\n",
    "        ax.set_ylabel('Density')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.legend(title='Language', title_fontsize='13', fontsize='12')  # Increase legend fontsize here\n",
    "        plt.suptitle(f'Evolution of Prompt Complexity and Average Improvement KDE ({type_of_experiment})', fontsize=20, y=1.02)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c5819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b91104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_of_experiment in ['zero-shot', 'few-shot']:\n",
    "    for error_rate in ['lev']:\n",
    "        # Create a new DataFrame to store the average improvements for each model and prompt\n",
    "        average_improvements = pd.DataFrame(columns=['prompt', 'model', f'Overall Levenshtein Improvement'])\n",
    "\n",
    "        for model in data.model.unique():  # Iterate over each unique model\n",
    "            for dataset in dataset_names:\n",
    "                dataset_data = data[(data.dataset_name == dataset) & (data.model == model) & (data.type == type_of_experiment)]  # Filter data for the current model\n",
    "                if 'icdar' not in dataset:\n",
    "                    dataset_data[f'Overall Levenshtein Improvement'] = dataset_data[[f'line-{error_rate}-improvement', \n",
    "                                                                          f'sentence-{error_rate}-improvement', \n",
    "                                                                          f'region-{error_rate}-improvement']].mean(axis=1)\n",
    "                else:\n",
    "                    dataset_data[f'Overall Levenshtein Improvement'] = dataset_data[[f'sentence-{error_rate}-improvement', \n",
    "                                                                      f'region-{error_rate}-improvement']].mean(axis=1)\n",
    "\n",
    "                # Group the data by prompt and model, then calculate the mean Overall Levenshtein Improvement\n",
    "                grouped_data = dataset_data.groupby(['prompt', 'model'])[f'Overall Levenshtein Improvement'].mean().reset_index()\n",
    "\n",
    "                # Add the grouped data to the average_improvements DataFrame\n",
    "                average_improvements = pd.concat([average_improvements, grouped_data])\n",
    "\n",
    "        # Group the data by prompt and model again, this time averaging the averages for each model and prompt\n",
    "        average_improvements = average_improvements.groupby(['prompt', 'model'])[f'Overall Levenshtein Improvement'].mean().reset_index()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 10))  # Create the plot\n",
    "\n",
    "        try:\n",
    "            # Plot the KDE plot of average improvements for each prompt\n",
    "            for model in average_improvements.model.unique():\n",
    "                _ = sns.kdeplot(average_improvements[average_improvements.model == model][f'Overall Levenshtein Improvement'], \n",
    "                                ax=ax, label=model, lw=2.5)  # Increase line width here\n",
    "        except Exception as ex:\n",
    "            print(f'Could not load data with {ex}')\n",
    "\n",
    "        ax.set_title(f'Average Overall Levenshtein Improvement KDE ({type_of_experiment})')  # Modify title since it's no longer specific to one model\n",
    "        ax.set_xlabel('Average Overall Levenshtein Improvement')\n",
    "        ax.set_ylabel('Density')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.legend(title='Model', title_fontsize='13', fontsize='12')  # Increase legend fontsize here\n",
    "        plt.suptitle(f'Evolution of Prompt Complexity and Average Improvement KDE ({type_of_experiment})', fontsize=20, y=1.02)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b6985",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_palette('colorblind')\n",
    "sns.set_context(\"notebook\", font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Define OCR noise level bins\n",
    "bins = [0, 0.4, 0.6, 0.8, 0.99, 1.0]\n",
    "\n",
    "# Assign OCR noise level labels\n",
    "labels = [\"0-40%\", \"40-60%\", \"60-80%\", \"80-99%\", \"99-100%\"]\n",
    "\n",
    "# Count the number of unique datasets\n",
    "n_datasets = data.dataset_name.nunique()\n",
    "dataset_names = ['impresso-nzz', 'overproof', 'ajmc-mixed', \n",
    "                 'ajmc-primary-text', 'icdar-2017', 'icdar-2019', 'htrec', 'ina']\n",
    "\n",
    "prompt_names = ['prompt_basic_01', 'prompt_basic_02', 'prompt_complex_01', \n",
    "                'prompt_complex_02', 'prompt_complex_lang']\n",
    "\n",
    "\n",
    "n_plots = len(dataset_names)\n",
    "n_plots_per_figure = 4\n",
    "n_figures = int(np.ceil(n_plots / n_plots_per_figure))\n",
    "\n",
    "for type_of_experiment in ['zero-shot', 'few-shot']:\n",
    "# for type_of_experiment in ['language-specific']:\n",
    "    for error_rate in ['lev']:\n",
    "        \n",
    "        for fig_idx in range(n_figures):\n",
    "            fig, axs = plt.subplots(2, 2, figsize=(30, 15))\n",
    "            axs = axs.flatten()\n",
    "\n",
    "            for i in range(n_plots_per_figure):\n",
    "                idx = fig_idx * n_plots_per_figure + i\n",
    "                if idx < n_plots:\n",
    "                    dataset = dataset_names[idx]\n",
    "                dataset_data = data[(data.dataset_name == dataset) & (data.type == type_of_experiment)]\n",
    "                # Compute the mean WER across line, sentence, and region levels\n",
    "                if 'icdar' not in dataset:\n",
    "                    dataset_data[f'Overall Levenshtein Improvement'] = dataset_data[[f'sentence-{error_rate}-improvement']].mean(axis=1)\n",
    "                else:\n",
    "                    dataset_data[f'Overall Levenshtein Improvement'] = dataset_data[[f'sentence-{error_rate}-improvement']].mean(axis=1)\n",
    "\n",
    "                try:\n",
    "                    # Plot the distribution of improvements for each model\n",
    "                    _ = sns.boxplot(x='model', y=f'Overall Levenshtein Improvement', data=dataset_data, \n",
    "                                    ax=axs[i], order=MODELS, hue='prompt', hue_order=prompt_names)\n",
    "                    axs[i].set_title(f'{dataset.upper()} ({type_of_experiment})')\n",
    "\n",
    "                    axs[i].set_ylim([-1.1, 1.1])\n",
    "                    axs[i].set_xticklabels(axs[i].get_xticklabels(), rotation=15)  # Rotate x-axis labels\n",
    "                    axs[i].set_xlabel('')  # Remove x-axis label\n",
    "                    axs[i].set_ylabel('')  # Remove y-axis label\n",
    "                except Exception as ex:\n",
    "                    print(f'Could not load {dataset} with {ex}')\n",
    "\n",
    "\n",
    "            # Remove empty subplots\n",
    "            for i in range(len(data.dataset_name.unique()), len(axs)):\n",
    "                fig.delaxes(axs[i])\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.suptitle(f'Overall Levenshtein Improvement across Datasets, Models, and Prompts ({type_of_experiment})', fontsize=20, y=1.02)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acfe884",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_palette('colorblind')\n",
    "sns.set_context(\"notebook\", font_scale=.7)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "for type_of_experiment in ['zero-shot']:\n",
    "    for error_rate in ['lev']:\n",
    "        fig, axs = plt.subplots(3, 2, figsize=(8, 12))  # Change here\n",
    "        axs = axs.flatten()  # To make it easy to index\n",
    "\n",
    "        for i, prompt in enumerate(prompt_names):\n",
    "            prompt_data = data[(data.prompt == prompt) & (data.type == type_of_experiment)]\n",
    "            \n",
    "            if 'icdar' not in dataset:\n",
    "                prompt_data[f'Overall Levenshtein Improvement'] = prompt_data[[f'line-{error_rate}-improvement', \n",
    "                                                                  f'sentence-{error_rate}-improvement', \n",
    "                                                                  f'region-{error_rate}-improvement']].mean(axis=1)\n",
    "            else:\n",
    "                prompt_data[f'Overall Levenshtein Improvement'] = prompt_data[[f'sentence-{error_rate}-improvement', \n",
    "                                                              f'region-{error_rate}-improvement']].mean(axis=1)\n",
    "\n",
    "            try:\n",
    "                if len(prompt_data) > 0:\n",
    "                    sns.kdeplot(data=prompt_data, x=f'Overall Levenshtein Improvement', hue='model', \n",
    "                                fill=True, ax=axs[i], hue_order=MODELS)\n",
    "                    axs[i].set_title(f'{prompt} ({type_of_experiment})')\n",
    "                    axs[i].set_xlim([-1, 1.2])\n",
    "                    axs[i].set_ylim([0, 1.4])\n",
    "            except Exception as ex:\n",
    "                print(f'Could not plot {prompt} with {ex}')\n",
    "\n",
    "        # Remove empty subplot\n",
    "        fig.delaxes(axs[-1])  # Change here\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "# A kernel density estimate (KDE) plot is a method for visualizing the distribution of observations in a dataset, \n",
    "# analogous to a histogram. KDE represents the data using a continuous probability density curve in one or more \n",
    "# dimensions.\n",
    "\n",
    "# Relative to a histogram, KDE can produce a plot that is less cluttered and more interpretable, especially when \n",
    "# drawing multiple distributions. But it has the potential to introduce distortions if the underlying distribution \n",
    "# is bounded or not smooth. Like a histogram, the quality of the representation also depends on the selection of \n",
    "# good smoothing parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d2e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd61e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_to_compare = ['prompt_complex_02', 'prompt_complex_lang']\n",
    "languages = [lang for lang in data['language'].unique() if lang != 'en']  # Exclude 'en' language\n",
    "\n",
    "for type_of_experiment in ['zero-shot']:\n",
    "    for error_rate in ['lev']:\n",
    "        plt.figure(figsize=(10, 6))  # Adjust as necessary\n",
    "\n",
    "        for language in languages:\n",
    "            language_data = data[(data.language == language) & \n",
    "                                 (data.type == type_of_experiment) & \n",
    "                                 (data.prompt.isin(prompts_to_compare))]\n",
    "\n",
    "            if 'icdar' not in dataset:\n",
    "                language_data[f'Overall Levenshtein Improvement'] = language_data[[f'line-{error_rate}-improvement', \n",
    "                                                                  f'sentence-{error_rate}-improvement', \n",
    "                                                                  f'region-{error_rate}-improvement']].mean(axis=1)\n",
    "            else:\n",
    "                language_data[f'Overall Levenshtein Improvement'] = language_data[[f'sentence-{error_rate}-improvement', \n",
    "                                                              f'region-{error_rate}-improvement']].mean(axis=1)\n",
    "\n",
    "            try:\n",
    "                if len(language_data) > 0:\n",
    "                    sns.kdeplot(data=language_data, x=f'Overall Levenshtein Improvement', hue='prompt', \n",
    "                                fill=True, hue_order=prompts_to_compare)\n",
    "            except Exception as ex:\n",
    "                print(f'Could not plot {language} with {ex}')\n",
    "\n",
    "        plt.title(f'All Languages ({type_of_experiment})')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22961951",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c3d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_palette('colorblind')\n",
    "sns.set_context(\"notebook\", font_scale=1.)\n",
    "\n",
    "\n",
    "prompts_to_compare = ['prompt_complex_02', 'prompt_complex_lang']\n",
    "languages = [lang for lang in data['language'].unique() if lang != 'en']  # Exclude 'en' language\n",
    "\n",
    "bar_data = []\n",
    "\n",
    "for type_of_experiment in ['zero-shot']:\n",
    "    for error_rate in ['lev']:\n",
    "        for language in languages:\n",
    "            for prompt in prompts_to_compare:\n",
    "                sub_data = data[(data.language == language) & \n",
    "                                 (data.type == type_of_experiment) & \n",
    "                                 (data.prompt == prompt)]\n",
    "                if 'icdar' not in dataset:\n",
    "                    sub_data[f'Overall Levenshtein Improvement'] = sub_data[[f'line-{error_rate}-improvement', \n",
    "                                                                          f'sentence-{error_rate}-improvement', \n",
    "                                                                          f'region-{error_rate}-improvement']].mean(axis=1)\n",
    "                else:\n",
    "                    sub_data[f'Overall Levenshtein Improvement'] = sub_data[[f'sentence-{error_rate}-improvement', \n",
    "                                                                      f'region-{error_rate}-improvement']].mean(axis=1)\n",
    "                \n",
    "                mean_improvement = np.mean(sub_data[f'Overall Levenshtein Improvement'])\n",
    "                bar_data.append({'Language': language, 'Prompt': prompt, 'Mean Improvement': mean_improvement})\n",
    "\n",
    "bar_data = pd.DataFrame(bar_data)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Language', y='Mean Improvement', hue='Prompt', data=bar_data, hue_order=prompts_to_compare)\n",
    "plt.title(f'Mean Levenshtein Improvement for all Languages ({type_of_experiment})')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better visibility\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d76ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d79348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dataset_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde994d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_palette('colorblind')\n",
    "sns.set_context(\"notebook\", font_scale=.7)\n",
    "\n",
    "segmentations = ['line', 'sentence', 'region']\n",
    "\n",
    "for type_of_experiment in ['zero-shot']:\n",
    "    for error_rate in ['lev']:\n",
    "        for segmentation in segmentations:\n",
    "            fig, axs = plt.subplots(3, 2, figsize=(8, 12))  # Change here\n",
    "            axs = axs.flatten()  # To make it easy to index\n",
    "\n",
    "            for i, prompt in enumerate(prompt_names):\n",
    "                prompt_data = data[(data.prompt == prompt) & (data.type == type_of_experiment)]\n",
    "                if segmentation == 'line':\n",
    "                    prompt_data = prompt_data[~prompt_data.dataset_name.isin(['icdar-2017', 'icdar-2019'])]\n",
    "                prompt_data[f'{segmentation.capitalize()} Levenshtein Improvement'] = prompt_data[f'{segmentation}-{error_rate}-improvement']\n",
    "\n",
    "                try:\n",
    "                    if len(prompt_data) > 0:\n",
    "                        sns.kdeplot(data=prompt_data, x=f'{segmentation.capitalize()} Levenshtein Improvement', \n",
    "                                    hue='model', fill=True, ax=axs[i], hue_order=MODELS)\n",
    "                        axs[i].set_title(f'{prompt} ({type_of_experiment})')\n",
    "                        axs[i].set_xlim([-1, 1.2])\n",
    "                        axs[i].set_ylim([0, 1.5])\n",
    "                except Exception as ex:\n",
    "                    print(f'Could not plot {prompt} with {ex}')\n",
    "\n",
    "            # Remove empty subplot\n",
    "            fig.delaxes(axs[-1])  # Change here\n",
    "\n",
    "            plt.suptitle(f'{segmentation.capitalize()} Levenshtein Improvement across Prompts and Models ({type_of_experiment})', fontsize=20, y=1.02)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf7f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e54da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "results = []  # Define results as a list\n",
    "\n",
    "\n",
    "for type_of_experiment in ['zero-shot', 'few-shot']:\n",
    "    for model in MODELS:\n",
    "        model_data = data[(data.model == model) & (data.type == type_of_experiment)]\n",
    "        \n",
    "        # Compute the mean Levenshtein Improvement across line, sentence, and region levels\n",
    "        if 'icdar' not in dataset:\n",
    "            model_data['Overall Levenshtein Improvement'] = model_data[[f'line-lev-improvement', \n",
    "                                                                        f'sentence-lev-improvement', \n",
    "                                                                        f'region-lev-improvement']].mean(axis=1)\n",
    "        else:\n",
    "            model_data['Overall Levenshtein Improvement'] = model_data[[f'sentence-lev-improvement', \n",
    "                                                                        f'region-lev-improvement']].mean(axis=1)\n",
    "\n",
    "        # Append the results\n",
    "#         print(model_data['Improvement Band'].unique())\n",
    "        results.append({'Model': model,\n",
    "                        'Type of Experiment': type_of_experiment,\n",
    "                        'Overall Levenshtein Improvement': np.nanmean(model_data['Overall Levenshtein Improvement'])})\n",
    "\n",
    "# Convert the results list to a DataFrame for plotting\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='Model', y='Overall Levenshtein Improvement', hue='Type of Experiment', data=results_df, order=MODELS)\n",
    "plt.title('Overall Levenshtein Improvement for Zero-Shot and Few-Shot Models')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba62497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for type_of_experiment in ['zero-shot', 'few-shot']:\n",
    "    results = []  # Define results as a list\n",
    "\n",
    "    for model in MODELS:\n",
    "        for band in data['Improvement Band'].unique():\n",
    "            model_band_data = data[(data.model == model) & (data.type == type_of_experiment) & (data['Improvement Band'] == band)]\n",
    "            \n",
    "            # Compute the mean Levenshtein Improvement across line, sentence, and region levels\n",
    "            if 'icdar' not in dataset:\n",
    "                model_band_data['Overall Levenshtein Improvement'] = model_band_data[[f'line-lev-improvement', \n",
    "                                                                                    f'sentence-lev-improvement', \n",
    "                                                                                    f'region-lev-improvement']].mean(axis=1)\n",
    "            else:\n",
    "                model_band_data['Overall Levenshtein Improvement'] = model_band_data[[f'sentence-lev-improvement', \n",
    "                                                                                    f'region-lev-improvement']].mean(axis=1)\n",
    "\n",
    "            # Append the results\n",
    "            results.append({'Model': model,\n",
    "                            'Type of Experiment': type_of_experiment,\n",
    "                            'Overall Levenshtein Improvement': np.nanmean(model_band_data['Overall Levenshtein Improvement']),\n",
    "                            'Improvement Band': band})\n",
    "\n",
    "    # Convert the results list to a DataFrame for plotting\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(x='Model', y='Overall Levenshtein Improvement', hue='Improvement Band', \n",
    "                data=results_df, order=MODELS)\n",
    "    plt.title('Overall Levenshtein Improvement for Zero-Shot and Few-Shot Models')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2578ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "g = sns.FacetGrid(data, col='Type', hue='Improvement Band', height=10, aspect=1)\n",
    "g.map(sns.barplot, 'model', 'Overall Levenshtein Improvement', order=MODELS)\n",
    "\n",
    "# Calculate means for each type of experiment and add horizontal lines\n",
    "for ax, (type_of_experiment, item) in zip(g.axes.flatten(), data.groupby('Type')):\n",
    "    mean_improvement = item['Overall Levenshtein Improvement'].mean()\n",
    "    ax.axhline(mean_improvement, color='black', linestyle='--')\n",
    "    ax.text(0.6, mean_improvement, f'Mean: {mean_improvement:.2f}', color='black')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68913b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818014ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b6097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ff5018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f60dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e38d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d142c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
