{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfadbdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "# !pip install pywer\n",
    "import pywer\n",
    "# !pip install pyjarowinkler\n",
    "from pyjarowinkler import distance as jwdistance\n",
    "\n",
    "class Const:\n",
    "    OCR = 'ocr'\n",
    "    GROUND = 'groundtruth'\n",
    "    REGION = 'region'\n",
    "    LINE = 'line'\n",
    "    SENTENCE = 'sentence'\n",
    "    FILE = 'filename'\n",
    "    DATASET = 'dataset_name'\n",
    "    PREDICTION = 'prediction'\n",
    "    PROMPT = 'prompt'\n",
    "    LANGUAGE = 'language'\n",
    "    NONE = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118ead6e",
   "metadata": {},
   "source": [
    "### Lookup datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79f14e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/datasets/ocr/converted/ajmc-mixed/ajmc_mixed.jsonl ajmc-mixed\n",
      "../data/datasets/ocr/converted/overproof/overproof.jsonl overproof\n",
      "../data/datasets/ocr/converted/icdar-2019/icdar-2019.jsonl icdar-2019\n",
      "../data/datasets/ocr/converted/icdar-2017/icdar-2017.jsonl icdar-2017\n",
      "../data/datasets/ocr/converted/impresso/impresso-nzz.jsonl impresso\n",
      "../data/datasets/ocr/converted/ajmc-primary/ajmc_primary_text.jsonl ajmc-primary\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "\n",
    "for root, dirs, files in os.walk('../data/datasets/ocr/converted'):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jsonl\"):\n",
    "            input_file = os.path.join(root, file)\n",
    "            if 'sample' not in input_file:\n",
    "                with open(input_file) as f:\n",
    "                    lines = f.read().splitlines()\n",
    "                df_inter = pd.DataFrame(lines)\n",
    "                df_inter.columns = ['json_element']\n",
    "                df_inter['json_element'].apply(json.loads)\n",
    "                df = pd.json_normalize(df_inter['json_element'].apply(json.loads))\n",
    "\n",
    "                dataset_name = root.split('/')[-1].replace('_', '-')\n",
    "                print(input_file, dataset_name)\n",
    "                df['dataset_name'] = [dataset_name] * len(df)\n",
    "                if 'ajmc' in dataset_name:\n",
    "                    df['language'] = ['el'] * len(df)\n",
    "                if 'overproof' in dataset_name:\n",
    "                    df['language'] = ['en'] * len(df)\n",
    "                if 'impresso' in dataset_name:\n",
    "                    df['language'] = ['de'] * len(df)\n",
    "                    \n",
    "                datasets.append(df)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58611ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique lines/sentences/regions.\n",
      "\n",
      "Dataset: ajmc-mixed 2131 with duplicates\n",
      "No. lines: 870 / 2131 No. sentences: 679 / 2131 No. regions: 63 / 2131\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: overproof 2669 with duplicates\n",
      "No. lines: 2278 / 2669 No. sentences: 399 / 2669 No. regions: 41 / 2669\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: icdar-2019 404 with duplicates\n",
      "No. lines: 0 / 404 No. sentences: 404 / 404 No. regions: 41 / 404\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: icdar-2017 477 with duplicates\n",
      "No. lines: 0 / 477 No. sentences: 461 / 477 No. regions: 28 / 477\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: impresso 1563 with duplicates\n",
      "No. lines: 1256 / 1563 No. sentences: 577 / 1563 No. regions: 203 / 1563\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: ajmc-primary 330 with duplicates\n",
      "No. lines: 151 / 330 No. sentences: 112 / 330 No. regions: 33 / 330\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique lines/sentences/regions.\\n')\n",
    "for dataset in datasets:\n",
    "    print('Dataset:', dataset['dataset_name'].unique()[0], len(dataset), 'with duplicates')\n",
    "    print('No. lines:', dataset['ocr.line']. nunique(), '/', len(dataset['ocr.sentence']), \n",
    "          'No. sentences:', dataset['ocr.sentence']. nunique(), '/', len(dataset['ocr.sentence']), \n",
    "          'No. regions:', dataset['ocr.region']. nunique(), '/', len(dataset['ocr.region']))\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e69fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE_SAMPLE = False\n",
    "\n",
    "# if GENERATE_SAMPLE:\n",
    "#     from sklearn.model_selection import train_test_split\n",
    "\n",
    "#     files_keep, files_removed, _, _ = train_test_split(dataset, dataset['dataset_name'], \n",
    "#                                                        test_size=0.90, random_state=42)\n",
    "    \n",
    "# if GENERATE_SAMPLE:\n",
    "#     output_file = '../data/datasets/ocr/converted/sample/sample.jsonl'\n",
    "#     with open(output_file, \"w\") as outfile:\n",
    "#         for index, row in files_keep.iterrows():\n",
    "\n",
    "#             json_line = json.dumps({Const.LANGUAGE: row['language'],\n",
    "#                                     Const.FILE: row['filename'],\n",
    "#                                     Const.DATASET: row['dataset_name'],\n",
    "#                                     Const.OCR: {Const.LINE: row['ocr.line'],\n",
    "#                                                 Const.SENTENCE: row['ocr.sentence'],\n",
    "#                                                 Const.REGION: row['ocr.region']}, \n",
    "#                                     Const.GROUND: {Const.LINE: row['groundtruth.line'],\n",
    "#                                                    Const.SENTENCE: row['groundtruth.sentence'],\n",
    "#                                                    Const.REGION: row['groundtruth.region']},\n",
    "#                                     'File': row['File'], \n",
    "#                                     'Date': row['Date'],\n",
    "#                                     'Type': row['Type'], \n",
    "#                                     'NbAlignedChar': row['NbAlignedChar'], \n",
    "#                                     'article_id': row['article_id']\n",
    "#                                     })\n",
    "\n",
    "#             outfile.write(json_line + \"\\n\")\n",
    "#             outfile.flush()\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0493b0",
   "metadata": {},
   "source": [
    "\n",
    "### Analsys of preliminary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cff1950d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overproof overproof gpt-4 prompt_basic_02\n",
      "overproof overproof gpt-3.5-turbo prompt_basic_02\n",
      "overproof overproof facebook-opt-350m prompt_basic_02\n",
      "overproof overproof decapoda-research-llama-7b-hf prompt_basic_02\n",
      "overproof overproof bigscience-bloom-560m prompt_basic_02\n",
      "htrec htrec facebook-opt-350m prompt_basic_02\n",
      "ajmc_mixed ajmc-mixed decapoda-research-llama-7b-hf prompt_basic_02\n",
      "ajmc_mixed ajmc-mixed bigscience-bloom-560m prompt_basic_02\n",
      "ajmc_mixed ajmc-mixed facebook-opt-350m prompt_basic_02\n",
      "ajmc_mixed ajmc-mixed gpt-4 prompt_basic_02\n",
      "icdar-2019 icdar-2019 bigscience-bloom-560m prompt_basic_02\n",
      "icdar-2019 icdar-2019 facebook-opt-350m prompt_basic_02\n",
      "icdar-2019 icdar-2019 gpt-4 prompt_basic_02\n",
      "icdar-2019 icdar-2019 gpt-3.5-turbo prompt_basic_02\n",
      "icdar-2017 icdar-2017 bigscience-bloom-560m prompt_basic_02\n",
      "icdar-2017 icdar-2017 gpt-4 prompt_basic_02\n",
      "icdar-2017 icdar-2017 facebook-opt-350m prompt_basic_02\n",
      "ajmc_primary_text ajmc-primary-text gpt-4 prompt_basic_02\n",
      "ajmc_primary_text ajmc-primary-text bigscience-bloom-560m prompt_basic_02\n",
      "ajmc_primary_text ajmc-primary-text facebook-opt-350m prompt_basic_02\n",
      "impresso-nzz impresso-nzz bigscience-bloom-560m prompt_complex_01\n",
      "impresso-nzz impresso-nzz facebook-opt-350m prompt_complex_01\n",
      "impresso-nzz impresso-nzz gpt-4 prompt_complex_01\n",
      "impresso-nzz impresso-nzz gpt-3.5-turbo prompt_complex_01\n",
      "overproof overproof gpt-4 prompt_complex_01\n",
      "overproof overproof gpt-3.5-turbo prompt_complex_01\n",
      "overproof overproof facebook-opt-350m prompt_complex_01\n",
      "overproof overproof decapoda-research-llama-7b-hf prompt_complex_01\n",
      "overproof overproof bigscience-bloom-560m prompt_complex_01\n",
      "We could not load results-htrec-facebook-opt-350m.jsonl\n",
      "ajmc_mixed ajmc-mixed decapoda-research-llama-7b-hf prompt_complex_01\n",
      "ajmc_mixed ajmc-mixed bigscience-bloom-560m prompt_complex_01\n",
      "ajmc_mixed ajmc-mixed facebook-opt-350m prompt_complex_01\n",
      "ajmc_mixed ajmc-mixed gpt-4 prompt_complex_01\n",
      "icdar-2019 icdar-2019 bigscience-bloom-560m prompt_complex_01\n",
      "icdar-2019 icdar-2019 decapoda-research-llama-7b-hf prompt_complex_01\n",
      "icdar-2019 icdar-2019 facebook-opt-350m prompt_complex_01\n",
      "icdar-2019 icdar-2019 gpt-4 prompt_complex_01\n",
      "icdar-2019 icdar-2019 gpt-3.5-turbo prompt_complex_01\n",
      "icdar-2017 icdar-2017 bigscience-bloom-560m prompt_complex_01\n",
      "icdar-2017 icdar-2017 gpt-4 prompt_complex_01\n",
      "icdar-2017 icdar-2017 facebook-opt-350m prompt_complex_01\n",
      "ajmc_primary_text ajmc-primary-text gpt-4 prompt_complex_01\n",
      "ajmc_primary_text ajmc-primary-text bigscience-bloom-560m prompt_complex_01\n",
      "ajmc_primary_text ajmc-primary-text facebook-opt-350m prompt_complex_01\n",
      "impresso-nzz impresso-nzz bigscience-bloom-560m prompt_basic_01\n",
      "impresso-nzz impresso-nzz facebook-opt-350m prompt_basic_01\n",
      "impresso-nzz impresso-nzz gpt-4 prompt_basic_01\n",
      "impresso-nzz impresso-nzz gpt-3.5-turbo prompt_basic_01\n",
      "overproof overproof davinci prompt_basic_01\n",
      "overproof overproof gpt-4 prompt_basic_01\n",
      "overproof overproof gpt-3.5-turbo prompt_basic_01\n",
      "overproof overproof gpt2 prompt_basic_01\n",
      "overproof overproof facebook-opt-350m prompt_basic_01\n",
      "overproof overproof tloen-alpaca-lora-7b prompt_basic_01\n",
      "overproof overproof decapoda-research-llama-7b-hf prompt_basic_01\n",
      "overproof overproof bigscience-bloom-560m prompt_basic_01\n",
      "htrec htrec gpt-4 prompt_basic_01\n",
      "htrec htrec tloen-alpaca-lora-7b prompt_basic_01\n",
      "htrec htrec bigscience-bloom-560m prompt_basic_01\n",
      "htrec htrec facebook-opt-350m prompt_basic_01\n",
      "htrec htrec gpt-3.5-turbo prompt_basic_01\n",
      "htrec htrec davinci prompt_basic_01\n",
      "htrec htrec gpt2 prompt_basic_01\n",
      "htrec htrec decapoda-research-llama-7b-hf prompt_basic_01\n",
      "ajmc_mixed ajmc-mixed tloen-alpaca-lora-7b prompt_basic_01\n",
      "ajmc_mixed ajmc-mixed decapoda-research-llama-7b-hf prompt_basic_01\n",
      "ajmc_mixed ajmc-mixed bigscience-bloom-560m prompt_basic_01\n",
      "ajmc_mixed ajmc-mixed gpt2 prompt_basic_01\n",
      "ajmc_mixed ajmc-mixed facebook-opt-350m prompt_basic_01\n",
      "ajmc_mixed ajmc-mixed gpt-4 prompt_basic_01\n",
      "ajmc_mixed ajmc-mixed davinci prompt_basic_01\n",
      "ajmc_mixed ajmc-mixed gpt-3.5-turbo prompt_basic_01\n",
      "icdar-2019 icdar-2019 gpt2 prompt_basic_01\n",
      "icdar-2019 icdar-2019 bigscience-bloom-560m prompt_basic_01\n",
      "icdar-2019 icdar-2019 decapoda-research-llama-7b-hf prompt_basic_01\n",
      "icdar-2019 icdar-2019 facebook-opt-350m prompt_basic_01\n",
      "icdar-2019 icdar-2019 gpt-4 prompt_basic_01\n",
      "icdar-2019 icdar-2019 gpt-3.5-turbo prompt_basic_01\n",
      "icdar-2019 icdar-2019 davinci prompt_basic_01\n",
      "icdar-2019 icdar-2019 tloen-alpaca-lora-7b prompt_basic_01\n",
      "icdar-2017 icdar-2017 bigscience-bloom-560m prompt_basic_01\n",
      "icdar-2017 icdar-2017 gpt-4 prompt_basic_01\n",
      "icdar-2017 icdar-2017 decapoda-research-llama-7b-hf prompt_basic_01\n",
      "icdar-2017 icdar-2017 davinci prompt_basic_01\n",
      "icdar-2017 icdar-2017 facebook-opt-350m prompt_basic_01\n",
      "icdar-2017 icdar-2017 gpt2 prompt_basic_01\n",
      "icdar-2017 icdar-2017 gpt-3.5-turbo prompt_basic_01\n",
      "ajmc_primary_text ajmc-primary-text gpt-4 prompt_basic_01\n",
      "ajmc_primary_text ajmc-primary-text bigscience-bloom-560m prompt_basic_01\n",
      "ajmc_primary_text ajmc-primary-text decapoda-research-llama-7b-hf prompt_basic_01\n",
      "ajmc_primary_text ajmc-primary-text davinci prompt_basic_01\n",
      "ajmc_primary_text ajmc-primary-text facebook-opt-350m prompt_basic_01\n",
      "ajmc_primary_text ajmc-primary-text gpt2 prompt_basic_01\n",
      "ajmc_primary_text ajmc-primary-text gpt-3.5-turbo prompt_basic_01\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for root, dirs, files in os.walk('../data/output'):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jsonl\"):\n",
    "            input_file = os.path.join(root, file)\n",
    "            \n",
    "            if 'sample' not in input_file:\n",
    "                prompt = root.split('/')[-2]\n",
    "                with open(input_file) as f:\n",
    "                    lines = f.read().splitlines()\n",
    "                try:\n",
    "                    df_inter = pd.DataFrame(lines)\n",
    "                    df_inter.columns = ['json_element']\n",
    "\n",
    "                    dataset_name = root.split('/')[-1].replace('_', '-')\n",
    "                    model_dataset_name = file[8:-6]\n",
    "                    model_name = model_dataset_name.replace(root.split('/')[-1] + '-', '').strip()\n",
    "                    \n",
    "                    df_inter['json_element'].apply(json.loads)\n",
    "                    df = pd.json_normalize(df_inter['json_element'].apply(json.loads))\n",
    "                    \n",
    "                    df['model'] = [model_name] * len(df)\n",
    "                    \n",
    "                    df['dataset_name'] = [dataset_name] * len(df)\n",
    "                    df['prompt'] = [prompt] * len(df)\n",
    "                    \n",
    "                    print(root.split('/')[-1], dataset_name, model_name, prompt)\n",
    "                    \n",
    "                    results.append(df)\n",
    "                except:\n",
    "                    print('We could not load {}'.format(file))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f6ef94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea001bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>article_id</th>\n",
       "      <th>ocr.line</th>\n",
       "      <th>ocr.sentence</th>\n",
       "      <th>ocr.region</th>\n",
       "      <th>groundtruth.line</th>\n",
       "      <th>groundtruth.sentence</th>\n",
       "      <th>groundtruth.region</th>\n",
       "      <th>prediction.prompt</th>\n",
       "      <th>prediction.line</th>\n",
       "      <th>prediction.sentence</th>\n",
       "      <th>prediction.region</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/datasets/ocr/original/overproof/dat...</td>\n",
       "      <td>overproof</td>\n",
       "      <td>7 year 1922 type Article title http://chronicl...</td>\n",
       "      <td>RAIDERS IN</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>RAIDERS IN</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>Correct the spelling and grammar of the follow...</td>\n",
       "      <td>Raiders Inc.</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000: Wat...</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000\\n\\nW...</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>prompt_basic_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/datasets/ocr/original/overproof/dat...</td>\n",
       "      <td>overproof</td>\n",
       "      <td>7 year 1922 type Article title http://chronicl...</td>\n",
       "      <td>FREDERICK</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>FREDER IC K</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>Correct the spelling and grammar of the follow...</td>\n",
       "      <td>Frederick</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000: Wat...</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000\\n\\nW...</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>prompt_basic_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/datasets/ocr/original/overproof/dat...</td>\n",
       "      <td>overproof</td>\n",
       "      <td>7 year 1922 type Article title http://chronicl...</td>\n",
       "      <td>LAND HAUL</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>LAND HAUL</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>Correct the spelling and grammar of the follow...</td>\n",
       "      <td>Land Haul</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000: Wat...</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000\\n\\nW...</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>prompt_basic_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/datasets/ocr/original/overproof/dat...</td>\n",
       "      <td>overproof</td>\n",
       "      <td>7 year 1922 type Article title http://chronicl...</td>\n",
       "      <td>OF $84,000</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>OF $84,000</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>Correct the spelling and grammar of the follow...</td>\n",
       "      <td>Of $84,000</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000: Wat...</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000\\n\\nW...</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>prompt_basic_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/datasets/ocr/original/overproof/dat...</td>\n",
       "      <td>overproof</td>\n",
       "      <td>7 year 1922 type Article title http://chronicl...</td>\n",
       "      <td>Watchman Bound and Gagged</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>Watchman Bound and Gagged</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>Correct the spelling and grammar of the follow...</td>\n",
       "      <td>Watchman Bound and Gagged</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000: Wat...</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000\\n\\nW...</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>prompt_basic_02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename dataset_name   \n",
       "0  ../../data/datasets/ocr/original/overproof/dat...    overproof  \\\n",
       "1  ../../data/datasets/ocr/original/overproof/dat...    overproof   \n",
       "2  ../../data/datasets/ocr/original/overproof/dat...    overproof   \n",
       "3  ../../data/datasets/ocr/original/overproof/dat...    overproof   \n",
       "4  ../../data/datasets/ocr/original/overproof/dat...    overproof   \n",
       "\n",
       "                                          article_id   \n",
       "0  7 year 1922 type Article title http://chronicl...  \\\n",
       "1  7 year 1922 type Article title http://chronicl...   \n",
       "2  7 year 1922 type Article title http://chronicl...   \n",
       "3  7 year 1922 type Article title http://chronicl...   \n",
       "4  7 year 1922 type Article title http://chronicl...   \n",
       "\n",
       "                    ocr.line   \n",
       "0                 RAIDERS IN  \\\n",
       "1                  FREDERICK   \n",
       "2                  LAND HAUL   \n",
       "3                 OF $84,000   \n",
       "4  Watchman Bound and Gagged   \n",
       "\n",
       "                                        ocr.sentence   \n",
       "0  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...  \\\n",
       "1  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...   \n",
       "2  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...   \n",
       "3  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...   \n",
       "4  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...   \n",
       "\n",
       "                                          ocr.region   \n",
       "0  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...  \\\n",
       "1  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...   \n",
       "2  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...   \n",
       "3  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...   \n",
       "4  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...   \n",
       "\n",
       "            groundtruth.line   \n",
       "0                 RAIDERS IN  \\\n",
       "1                FREDER IC K   \n",
       "2                  LAND HAUL   \n",
       "3                 OF $84,000   \n",
       "4  Watchman Bound and Gagged   \n",
       "\n",
       "                                groundtruth.sentence   \n",
       "0  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...  \\\n",
       "1  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...   \n",
       "2  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...   \n",
       "3  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...   \n",
       "4  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...   \n",
       "\n",
       "                                  groundtruth.region   \n",
       "0  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...  \\\n",
       "1  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...   \n",
       "2  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...   \n",
       "3  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...   \n",
       "4  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...   \n",
       "\n",
       "                                   prediction.prompt   \n",
       "0  Correct the spelling and grammar of the follow...  \\\n",
       "1  Correct the spelling and grammar of the follow...   \n",
       "2  Correct the spelling and grammar of the follow...   \n",
       "3  Correct the spelling and grammar of the follow...   \n",
       "4  Correct the spelling and grammar of the follow...   \n",
       "\n",
       "             prediction.line   \n",
       "0               Raiders Inc.  \\\n",
       "1                  Frederick   \n",
       "2                  Land Haul   \n",
       "3                 Of $84,000   \n",
       "4  Watchman Bound and Gagged   \n",
       "\n",
       "                                 prediction.sentence   \n",
       "0  Raiders in Frederick Land Haul of $84,000: Wat...  \\\n",
       "1  Raiders in Frederick Land Haul of $84,000: Wat...   \n",
       "2  Raiders in Frederick Land Haul of $84,000: Wat...   \n",
       "3  Raiders in Frederick Land Haul of $84,000: Wat...   \n",
       "4  Raiders in Frederick Land Haul of $84,000: Wat...   \n",
       "\n",
       "                                   prediction.region  model           prompt  \n",
       "0  Raiders in Frederick Land Haul of $84,000\\n\\nW...  gpt-4  prompt_basic_02  \n",
       "1  Raiders in Frederick Land Haul of $84,000\\n\\nW...  gpt-4  prompt_basic_02  \n",
       "2  Raiders in Frederick Land Haul of $84,000\\n\\nW...  gpt-4  prompt_basic_02  \n",
       "3  Raiders in Frederick Land Haul of $84,000\\n\\nW...  gpt-4  prompt_basic_02  \n",
       "4  Raiders in Frederick Land Haul of $84,000\\n\\nW...  gpt-4  prompt_basic_02  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b04e2574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>article_id</th>\n",
       "      <th>ocr.line</th>\n",
       "      <th>ocr.sentence</th>\n",
       "      <th>ocr.region</th>\n",
       "      <th>groundtruth.line</th>\n",
       "      <th>groundtruth.sentence</th>\n",
       "      <th>groundtruth.region</th>\n",
       "      <th>prediction.prompt</th>\n",
       "      <th>...</th>\n",
       "      <th>prediction.sentence</th>\n",
       "      <th>prediction.region</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>language</th>\n",
       "      <th>File</th>\n",
       "      <th>Date</th>\n",
       "      <th>Type</th>\n",
       "      <th>NbAlignedChar</th>\n",
       "      <th>century</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/datasets/ocr/original/overproof/dat...</td>\n",
       "      <td>overproof</td>\n",
       "      <td>7 year 1922 type Article title http://chronicl...</td>\n",
       "      <td>RAIDERS IN</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>RAIDERS IN</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>Correct the spelling and grammar of the follow...</td>\n",
       "      <td>...</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000: Wat...</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000\\n\\nW...</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>prompt_basic_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/datasets/ocr/original/overproof/dat...</td>\n",
       "      <td>overproof</td>\n",
       "      <td>7 year 1922 type Article title http://chronicl...</td>\n",
       "      <td>FREDERICK</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>FREDER IC K</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>Correct the spelling and grammar of the follow...</td>\n",
       "      <td>...</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000: Wat...</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000\\n\\nW...</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>prompt_basic_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/datasets/ocr/original/overproof/dat...</td>\n",
       "      <td>overproof</td>\n",
       "      <td>7 year 1922 type Article title http://chronicl...</td>\n",
       "      <td>LAND HAUL</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>LAND HAUL</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>Correct the spelling and grammar of the follow...</td>\n",
       "      <td>...</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000: Wat...</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000\\n\\nW...</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>prompt_basic_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/datasets/ocr/original/overproof/dat...</td>\n",
       "      <td>overproof</td>\n",
       "      <td>7 year 1922 type Article title http://chronicl...</td>\n",
       "      <td>OF $84,000</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>OF $84,000</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>Correct the spelling and grammar of the follow...</td>\n",
       "      <td>...</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000: Wat...</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000\\n\\nW...</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>prompt_basic_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/datasets/ocr/original/overproof/dat...</td>\n",
       "      <td>overproof</td>\n",
       "      <td>7 year 1922 type Article title http://chronicl...</td>\n",
       "      <td>Watchman Bound and Gagged</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...</td>\n",
       "      <td>Watchman Bound and Gagged</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...</td>\n",
       "      <td>Correct the spelling and grammar of the follow...</td>\n",
       "      <td>...</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000: Wat...</td>\n",
       "      <td>Raiders in Frederick Land Haul of $84,000\\n\\nW...</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>prompt_basic_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename dataset_name   \n",
       "0  ../../data/datasets/ocr/original/overproof/dat...    overproof  \\\n",
       "1  ../../data/datasets/ocr/original/overproof/dat...    overproof   \n",
       "2  ../../data/datasets/ocr/original/overproof/dat...    overproof   \n",
       "3  ../../data/datasets/ocr/original/overproof/dat...    overproof   \n",
       "4  ../../data/datasets/ocr/original/overproof/dat...    overproof   \n",
       "\n",
       "                                          article_id   \n",
       "0  7 year 1922 type Article title http://chronicl...  \\\n",
       "1  7 year 1922 type Article title http://chronicl...   \n",
       "2  7 year 1922 type Article title http://chronicl...   \n",
       "3  7 year 1922 type Article title http://chronicl...   \n",
       "4  7 year 1922 type Article title http://chronicl...   \n",
       "\n",
       "                    ocr.line   \n",
       "0                 RAIDERS IN  \\\n",
       "1                  FREDERICK   \n",
       "2                  LAND HAUL   \n",
       "3                 OF $84,000   \n",
       "4  Watchman Bound and Gagged   \n",
       "\n",
       "                                        ocr.sentence   \n",
       "0  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...  \\\n",
       "1  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...   \n",
       "2  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...   \n",
       "3  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...   \n",
       "4  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...   \n",
       "\n",
       "                                          ocr.region   \n",
       "0  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...  \\\n",
       "1  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...   \n",
       "2  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...   \n",
       "3  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...   \n",
       "4  RAIDERS IN FREDERICK LAND HAUL OF $84,000 Watc...   \n",
       "\n",
       "            groundtruth.line   \n",
       "0                 RAIDERS IN  \\\n",
       "1                FREDER IC K   \n",
       "2                  LAND HAUL   \n",
       "3                 OF $84,000   \n",
       "4  Watchman Bound and Gagged   \n",
       "\n",
       "                                groundtruth.sentence   \n",
       "0  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...  \\\n",
       "1  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...   \n",
       "2  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...   \n",
       "3  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...   \n",
       "4  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...   \n",
       "\n",
       "                                  groundtruth.region   \n",
       "0  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...  \\\n",
       "1  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...   \n",
       "2  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...   \n",
       "3  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...   \n",
       "4  RAIDERS IN FREDER IC K LAND HAUL OF $84,000 Wa...   \n",
       "\n",
       "                                   prediction.prompt  ...   \n",
       "0  Correct the spelling and grammar of the follow...  ...  \\\n",
       "1  Correct the spelling and grammar of the follow...  ...   \n",
       "2  Correct the spelling and grammar of the follow...  ...   \n",
       "3  Correct the spelling and grammar of the follow...  ...   \n",
       "4  Correct the spelling and grammar of the follow...  ...   \n",
       "\n",
       "                                 prediction.sentence   \n",
       "0  Raiders in Frederick Land Haul of $84,000: Wat...  \\\n",
       "1  Raiders in Frederick Land Haul of $84,000: Wat...   \n",
       "2  Raiders in Frederick Land Haul of $84,000: Wat...   \n",
       "3  Raiders in Frederick Land Haul of $84,000: Wat...   \n",
       "4  Raiders in Frederick Land Haul of $84,000: Wat...   \n",
       "\n",
       "                                   prediction.region  model           prompt   \n",
       "0  Raiders in Frederick Land Haul of $84,000\\n\\nW...  gpt-4  prompt_basic_02  \\\n",
       "1  Raiders in Frederick Land Haul of $84,000\\n\\nW...  gpt-4  prompt_basic_02   \n",
       "2  Raiders in Frederick Land Haul of $84,000\\n\\nW...  gpt-4  prompt_basic_02   \n",
       "3  Raiders in Frederick Land Haul of $84,000\\n\\nW...  gpt-4  prompt_basic_02   \n",
       "4  Raiders in Frederick Land Haul of $84,000\\n\\nW...  gpt-4  prompt_basic_02   \n",
       "\n",
       "  language File Date Type NbAlignedChar century  \n",
       "0      NaN  NaN  NaN  NaN           NaN     NaN  \n",
       "1      NaN  NaN  NaN  NaN           NaN     NaN  \n",
       "2      NaN  NaN  NaN  NaN           NaN     NaN  \n",
       "3      NaN  NaN  NaN  NaN           NaN     NaN  \n",
       "4      NaN  NaN  NaN  NaN           NaN     NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat(results)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d08ab9f",
   "metadata": {},
   "source": [
    "## Post-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d50ad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "from Levenshtein import distance\n",
    "\n",
    "def compute_normalized_levenshtein_distance(ocr_text, ground_truth_text):\n",
    "    length = max(len(ocr_text), len(ground_truth_text))\n",
    "    levenshtein_distance = distance(ocr_text, ground_truth_text)\n",
    "    similarity = (length - levenshtein_distance) / length\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def get_improvement(original_distance, corrected_distance):\n",
    "    return 1.0 - (original_distance - corrected_distance)\n",
    "\n",
    "def get_cer_wer_improvement(original_distance, corrected_distance):\n",
    "    return original_distance - corrected_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e931fa10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>article_id</th>\n",
       "      <th>ocr.line</th>\n",
       "      <th>ocr.sentence</th>\n",
       "      <th>ocr.region</th>\n",
       "      <th>groundtruth.line</th>\n",
       "      <th>groundtruth.sentence</th>\n",
       "      <th>groundtruth.region</th>\n",
       "      <th>prediction.prompt</th>\n",
       "      <th>...</th>\n",
       "      <th>prediction.sentence</th>\n",
       "      <th>prediction.region</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>language</th>\n",
       "      <th>File</th>\n",
       "      <th>Date</th>\n",
       "      <th>Type</th>\n",
       "      <th>NbAlignedChar</th>\n",
       "      <th>century</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Wecklein1894</td>\n",
       "      <td>ajmc-primary-text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ὅπου δ’ ὑβρίζειν δρᾶν θ’ ἃ βούλεται παρῇ,</td>\n",
       "      <td>δέος γὰρ πρόσεστιν αἰσχύνη W ὁμοῦ, σωτηρίαν ἔχ...</td>\n",
       "      <td>μηδὲν φόβου πρόβλημα und αἰδοῦς ἔχων. ἀλλ’ ἄνδ...</td>\n",
       "      <td>ὅπου δ’ ὑβρίζειν δρᾶν θ’ ἃ βούλεται παρῇ,</td>\n",
       "      <td>δέος γὰρ ᾧ πρόσεστιν αἰσχύνη θ’ ὁμοῦ, σωτηρίαν...</td>\n",
       "      <td>μηδὲν φόβου πρόβλημα μηδ’ αἰδοῦς ἔχων. ἀλλ’ ἄν...</td>\n",
       "      <td>Correct the text: \"δέος γὰρ πρόσεστιν αἰσχύνη ...</td>\n",
       "      <td>...</td>\n",
       "      <td>There are no errors in this text. Here is the ...</td>\n",
       "      <td>No changes are needed as this appears to be a ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>prompt_basic_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Wecklein1894</td>\n",
       "      <td>ajmc-primary-text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ταύτην νόμιζε τὴν πόλιν χρόνῳ ποτὲ</td>\n",
       "      <td>δέος γὰρ πρόσεστιν αἰσχύνη W ὁμοῦ, σωτηρίαν ἔχ...</td>\n",
       "      <td>μηδὲν φόβου πρόβλημα und αἰδοῦς ἔχων. ἀλλ’ ἄνδ...</td>\n",
       "      <td>ταύτην νόμιζε τὴν πόλιν χρόνῳ ποτὲ</td>\n",
       "      <td>δέος γὰρ ᾧ πρόσεστιν αἰσχύνη θ’ ὁμοῦ, σωτηρίαν...</td>\n",
       "      <td>μηδὲν φόβου πρόβλημα μηδ’ αἰδοῦς ἔχων. ἀλλ’ ἄν...</td>\n",
       "      <td>Correct the text: \"ταύτην νόμιζε τὴν πόλιν χρό...</td>\n",
       "      <td>...</td>\n",
       "      <td>There are no errors in this text. Here is the ...</td>\n",
       "      <td>No changes are needed as this appears to be a ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>prompt_basic_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Wecklein1894</td>\n",
       "      <td>ajmc-primary-text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ἐξ οὐρίων δραμοῦσαν ἐς βυθὸν πεσεῖν.</td>\n",
       "      <td>δέος γὰρ πρόσεστιν αἰσχύνη W ὁμοῦ, σωτηρίαν ἔχ...</td>\n",
       "      <td>μηδὲν φόβου πρόβλημα und αἰδοῦς ἔχων. ἀλλ’ ἄνδ...</td>\n",
       "      <td>ἐξ οὐρίων δραμοῦσαν ἐς βυθὸν πεσεῖν.</td>\n",
       "      <td>δέος γὰρ ᾧ πρόσεστιν αἰσχύνη θ’ ὁμοῦ, σωτηρίαν...</td>\n",
       "      <td>μηδὲν φόβου πρόβλημα μηδ’ αἰδοῦς ἔχων. ἀλλ’ ἄν...</td>\n",
       "      <td>Correct the text: \"ἐξ οὐρίων δραμοῦσαν ἐς βυθὸ...</td>\n",
       "      <td>...</td>\n",
       "      <td>There are no errors in this text. Here is the ...</td>\n",
       "      <td>No changes are needed as this appears to be a ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>prompt_basic_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Wecklein1894</td>\n",
       "      <td>ajmc-primary-text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ΧΟ. Μενέλαε, μὴ γνώμας ὑποστήσας σοφὰς</td>\n",
       "      <td>ΧΟ.</td>\n",
       "      <td>μηδὲν φόβου πρόβλημα und αἰδοῦς ἔχων. ἀλλ’ ἄνδ...</td>\n",
       "      <td>ΧΟ. Μενέλαε, un γνώμας ὑποστήσας σοφὰς</td>\n",
       "      <td>ΧΟ.</td>\n",
       "      <td>μηδὲν φόβου πρόβλημα μηδ’ αἰδοῦς ἔχων. ἀλλ’ ἄν...</td>\n",
       "      <td>Correct the text: \"ΧΟ. Μενέλαε, μὴ γνώμας ὑποσ...</td>\n",
       "      <td>...</td>\n",
       "      <td>I'm sorry but \"ΧΟ.\"</td>\n",
       "      <td>No changes are needed as this appears to be a ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>prompt_basic_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Wecklein1894</td>\n",
       "      <td>ajmc-primary-text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ΧΟ. Μενέλαε, μὴ γνώμας ὑποστήσας σοφὰς</td>\n",
       "      <td>ΧΟ.</td>\n",
       "      <td>μηδὲν φόβου πρόβλημα und αἰδοῦς ἔχων. ἀλλ’ ἄνδ...</td>\n",
       "      <td>ΧΟ. Μενέλαε, un γνώμας ὑποστήσας σοφὰς</td>\n",
       "      <td>ΧΟ.</td>\n",
       "      <td>μηδὲν φόβου πρόβλημα μηδ’ αἰδοῦς ἔχων. ἀλλ’ ἄν...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>I'm sorry but \"ΧΟ.\"</td>\n",
       "      <td>No changes are needed as this appears to be a ...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>prompt_basic_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename       dataset_name article_id   \n",
       "325  Wecklein1894  ajmc-primary-text        NaN  \\\n",
       "326  Wecklein1894  ajmc-primary-text        NaN   \n",
       "327  Wecklein1894  ajmc-primary-text        NaN   \n",
       "328  Wecklein1894  ajmc-primary-text        NaN   \n",
       "329  Wecklein1894  ajmc-primary-text        NaN   \n",
       "\n",
       "                                      ocr.line   \n",
       "325  ὅπου δ’ ὑβρίζειν δρᾶν θ’ ἃ βούλεται παρῇ,  \\\n",
       "326         ταύτην νόμιζε τὴν πόλιν χρόνῳ ποτὲ   \n",
       "327       ἐξ οὐρίων δραμοῦσαν ἐς βυθὸν πεσεῖν.   \n",
       "328     ΧΟ. Μενέλαε, μὴ γνώμας ὑποστήσας σοφὰς   \n",
       "329     ΧΟ. Μενέλαε, μὴ γνώμας ὑποστήσας σοφὰς   \n",
       "\n",
       "                                          ocr.sentence   \n",
       "325  δέος γὰρ πρόσεστιν αἰσχύνη W ὁμοῦ, σωτηρίαν ἔχ...  \\\n",
       "326  δέος γὰρ πρόσεστιν αἰσχύνη W ὁμοῦ, σωτηρίαν ἔχ...   \n",
       "327  δέος γὰρ πρόσεστιν αἰσχύνη W ὁμοῦ, σωτηρίαν ἔχ...   \n",
       "328                                                ΧΟ.   \n",
       "329                                                ΧΟ.   \n",
       "\n",
       "                                            ocr.region   \n",
       "325  μηδὲν φόβου πρόβλημα und αἰδοῦς ἔχων. ἀλλ’ ἄνδ...  \\\n",
       "326  μηδὲν φόβου πρόβλημα und αἰδοῦς ἔχων. ἀλλ’ ἄνδ...   \n",
       "327  μηδὲν φόβου πρόβλημα und αἰδοῦς ἔχων. ἀλλ’ ἄνδ...   \n",
       "328  μηδὲν φόβου πρόβλημα und αἰδοῦς ἔχων. ἀλλ’ ἄνδ...   \n",
       "329  μηδὲν φόβου πρόβλημα und αἰδοῦς ἔχων. ἀλλ’ ἄνδ...   \n",
       "\n",
       "                              groundtruth.line   \n",
       "325  ὅπου δ’ ὑβρίζειν δρᾶν θ’ ἃ βούλεται παρῇ,  \\\n",
       "326         ταύτην νόμιζε τὴν πόλιν χρόνῳ ποτὲ   \n",
       "327       ἐξ οὐρίων δραμοῦσαν ἐς βυθὸν πεσεῖν.   \n",
       "328     ΧΟ. Μενέλαε, un γνώμας ὑποστήσας σοφὰς   \n",
       "329     ΧΟ. Μενέλαε, un γνώμας ὑποστήσας σοφὰς   \n",
       "\n",
       "                                  groundtruth.sentence   \n",
       "325  δέος γὰρ ᾧ πρόσεστιν αἰσχύνη θ’ ὁμοῦ, σωτηρίαν...  \\\n",
       "326  δέος γὰρ ᾧ πρόσεστιν αἰσχύνη θ’ ὁμοῦ, σωτηρίαν...   \n",
       "327  δέος γὰρ ᾧ πρόσεστιν αἰσχύνη θ’ ὁμοῦ, σωτηρίαν...   \n",
       "328                                                ΧΟ.   \n",
       "329                                                ΧΟ.   \n",
       "\n",
       "                                    groundtruth.region   \n",
       "325  μηδὲν φόβου πρόβλημα μηδ’ αἰδοῦς ἔχων. ἀλλ’ ἄν...  \\\n",
       "326  μηδὲν φόβου πρόβλημα μηδ’ αἰδοῦς ἔχων. ἀλλ’ ἄν...   \n",
       "327  μηδὲν φόβου πρόβλημα μηδ’ αἰδοῦς ἔχων. ἀλλ’ ἄν...   \n",
       "328  μηδὲν φόβου πρόβλημα μηδ’ αἰδοῦς ἔχων. ἀλλ’ ἄν...   \n",
       "329  μηδὲν φόβου πρόβλημα μηδ’ αἰδοῦς ἔχων. ἀλλ’ ἄν...   \n",
       "\n",
       "                                     prediction.prompt  ...   \n",
       "325  Correct the text: \"δέος γὰρ πρόσεστιν αἰσχύνη ...  ...  \\\n",
       "326  Correct the text: \"ταύτην νόμιζε τὴν πόλιν χρό...  ...   \n",
       "327  Correct the text: \"ἐξ οὐρίων δραμοῦσαν ἐς βυθὸ...  ...   \n",
       "328  Correct the text: \"ΧΟ. Μενέλαε, μὴ γνώμας ὑποσ...  ...   \n",
       "329                                                NaN  ...   \n",
       "\n",
       "                                   prediction.sentence   \n",
       "325  There are no errors in this text. Here is the ...  \\\n",
       "326  There are no errors in this text. Here is the ...   \n",
       "327  There are no errors in this text. Here is the ...   \n",
       "328                                I'm sorry but \"ΧΟ.\"   \n",
       "329                                I'm sorry but \"ΧΟ.\"   \n",
       "\n",
       "                                     prediction.region          model   \n",
       "325  No changes are needed as this appears to be a ...  gpt-3.5-turbo  \\\n",
       "326  No changes are needed as this appears to be a ...  gpt-3.5-turbo   \n",
       "327  No changes are needed as this appears to be a ...  gpt-3.5-turbo   \n",
       "328  No changes are needed as this appears to be a ...  gpt-3.5-turbo   \n",
       "329  No changes are needed as this appears to be a ...  gpt-3.5-turbo   \n",
       "\n",
       "              prompt language File Date Type NbAlignedChar century  \n",
       "325  prompt_basic_01      NaN  NaN  NaN  NaN           NaN     NaN  \n",
       "326  prompt_basic_01      NaN  NaN  NaN  NaN           NaN     NaN  \n",
       "327  prompt_basic_01      NaN  NaN  NaN  NaN           NaN     NaN  \n",
       "328  prompt_basic_01      NaN  NaN  NaN  NaN           NaN     NaN  \n",
       "329  prompt_basic_01      NaN  NaN  NaN  NaN           NaN     NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41f8de4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.035738117721120566"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_text = \"149 Obrázek z maloměstského kukátka. Podává L. Gro\"\n",
    "ocr_text = \"149 Obrázek z maloměstského kukátka. Podává L. Grw\"\n",
    "pred_text = \"\"\"Correct the text: \"149 Obrázek z maloměstského kukátka. Podává L. Grwsmannová-Brodská. Místo děje: salon paní stavitelky; doba: čas věnovaný kávové „visitě\"; jednající osoby: dámy přednější honorace městské, z nichž •většina je mladá a některé skutečně hezké. Na stole prostřeném krásným ubrusem damaškovým stojí talíře s koláčky, věnečky a preclíčky, kol toho pěkně se vyjímají křišťálové sklenky s vodou, stříbrné lžičky a šálky z jemného porcelánu, jejichž vonný obsah na přítomné paničky zdá se velmi blaze působiti. Ze živějšího hovoru vyznívá právě hlas paní notářky, která ve spravedlivém rozhorlení mluví: „Ano, mé dámy, již jest to takové! Samy ráčily jste býti svědky, jak svorně i jednohlasně byl přijat návrh paní sládkové, abychom si pořídily kroje národní a tak přispěly ku zvýšení lesku slavnosti, již pořádá náš statečný studentský spolek „Hvězda\", a když již nás páni akademikové poctili důvěrou, že v naše ruce složili starost o buffet a jiné ještě funkce, tož měly bychom snad též jiti za příkladem slečen berních a vzdáti se činnosti jen proto, že se zdá paní berní národní kroj pro tři dcery býti nějakou zby tečnou výlohou?\" Paničky projevovaly svoji nevoli, každá jiným spůsobem. Mladá paní adjunktová v duchu si umiňovala, že ve svém přátel ství k berňovům trochu ochladne; to tak! aby ten jejich pošetilý nápad, úóinkovati při slavnosti v obyčejném oděvu, přece zvítězil a dámám se bylo odříci těch půvabných krojů venkovských, co by si jen ona, paní adjunktová, počala s tou haldou brokátu, atlasu, krajek, stuh a aksamitu, za což vydala nejednu desítku, utěšujíc se tím, jak jí to bude slušeti! Hm, a škodu z toho také míti nebude, muž se bude musit po několik měsíců uskrovnit, služka se má beztoho též až příliš dobře, uhradí se to na domácnosti a bude! Nyní ujala se slova paní doktorka: „Aj, od berních to není nic divného, považte jen: tolik dětí! Vždyť my všecky víme, že kdyby sobě slečny toillety samy ne řídily, mnohého by nemohly míti; ony pak mají zásadu: nemá-li být něco pěkné, tož raději nic!\" „Pravda, ale slečny Elišky, té nejmladší, jest mně líto; těšila se velice na selský kroj.\" „Ba ano, byla by v něm vypadala roztomile.\" „Nyní má po radosti.\" „Inu, proč má tak nepřející matinku.\" „To není to, má drahá, jest v tom však jiný háček.\" „Ah, ano; vždyť víme, že sotva tak tak vyjdou.\" „Ale na knihy, které jsi tvá, jinak našel byste jen krytí těch mladých mozí, jinak je vydáte.\" „A tak bude, ostatně jdu až na knihy; ale slyšet jsem od někoho, že o krojech něco dělat, a že to bylo bude dělat národní, a když jsi tento národní učil jak, pak by měl nalézt tuto kartu, ta by se jistě mohla vyměnit se všemi. Můžete-li to od nás odkázat?\" Všem ozdravila její hlas, když řekla: „Já, já! a já ho učím. S těmi páne akademiky jsem již mohla vyprávět o světě, v němž vznítí v některé nocy a jednoho dne vyrostá vám hrozný kouzelný strom zůstane, o němž je psáno: ‚Už jen žádat!\" 50 V tuto chvíli koupili mohou-li všichni pánové i paní, že když jsi to čerpala, dá se jen kupit. Přižili to, a já jim vám koupi ukáži.\n",
    "„A já už jste tím vyděštila. Pánové, děkuji vám za chytré vědomí, se kterým vám projeví, že se už točí dívčí zrcadlo.\" – 151\"\"\"\n",
    "                \n",
    "get_improvement(compute_normalized_levenshtein_distance(gt_text, ocr_text), compute_normalized_levenshtein_distance(gt_text, pred_text))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c55678d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(text):\n",
    "    if text is not None:\n",
    "        if len(text.strip()) > 0:\n",
    "            if text.startswith('\"'):\n",
    "                text = text[1:]\n",
    "            if text.endswith('\"'):\n",
    "                text = text[:-1]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced49b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: overproof Model: gpt-4 Prompt: prompt_basic_02\n"
     ]
    }
   ],
   "source": [
    "# Define OCR noise level bins\n",
    "# bins = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "bins = [0, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "# Assign OCR noise level labels\n",
    "# labels = [\"0-10%\", \"10-20%\", \"20-30%\", \"30-40%\", \"40-50%\", \"50-60%\", \"60-70%\", \"70-80%\", \"80-90%\", \"90-100%\"]\n",
    "labels = [\"0-70%\", \"70-80%\", \"80-90%\", \"90-100%\"]\n",
    "\n",
    "\n",
    "for idx, result in enumerate(results):\n",
    "    \n",
    "    results[idx] = results[idx].fillna('No text')\n",
    "    \n",
    "    results[idx] = results[idx][results[idx] != 'tloen-alpaca-lora-7b']\n",
    "    \n",
    "    dataset_name = results[idx]['dataset_name'].unique()[0]\n",
    "    model_name = results[idx]['model'].unique()[0]\n",
    "    prompt = results[idx]['prompt'].unique()[0]\n",
    "    \n",
    "    print('Dataset:', dataset_name, 'Model:', model_name, 'Prompt:', prompt)\n",
    "    \n",
    "    if type(model_name) == float:\n",
    "        import pdb;pdb.set_trace()\n",
    "        \n",
    "    if 'alpaca' not in model_name:\n",
    "    \n",
    "        if 'icdar' in dataset_name:\n",
    "            text_types = ['sentence', 'region']\n",
    "        else:\n",
    "            text_types = ['line', 'sentence', 'region']\n",
    "        for segment_type in text_types:\n",
    "\n",
    "            results[idx]['length'] = results[idx][f'groundtruth.{segment_type}'].str.len()\n",
    "            results[idx] = results[idx][results[idx]['length'] > 3]\n",
    "\n",
    "            results[idx][f'prediction.{segment_type}'] = results[idx][f'prediction.{segment_type}'].apply(postprocess)\n",
    "\n",
    "            results[idx][f'{segment_type}-lev-ocr'] = \\\n",
    "                results[idx].apply(lambda x: compute_normalized_levenshtein_distance(x[f'groundtruth.{segment_type}'],\n",
    "                                                                          x[f'ocr.{segment_type}']), axis=1)\n",
    "            results[idx][f'{segment_type}-lev-pred'] = \\\n",
    "                results[idx].apply(lambda x: compute_normalized_levenshtein_distance(x[f'groundtruth.{segment_type}'],\n",
    "                                                                          x[f'prediction.{segment_type}']), axis=1)\n",
    "\n",
    "            results[idx][f'{segment_type}-lev-improvement'] = \\\n",
    "                results[idx].apply(lambda x: get_improvement(x[f'{segment_type}-lev-ocr'],\n",
    "                                                             x[f'{segment_type}-lev-pred']), axis=1)\n",
    "            # Compute CER\n",
    "            results[idx][f'{segment_type}-cer-ocr'] = results[idx].apply(lambda x: pywer.cer(x[f'ocr.{segment_type}'], \n",
    "                                                         x[f'groundtruth.{segment_type}']), axis=1)\n",
    "            results[idx][f'{segment_type}-cer-pred'] = results[idx].apply(lambda x: pywer.cer(x[f'prediction.{segment_type}'], \n",
    "                                                         x[f'groundtruth.{segment_type}']), axis=1)\n",
    "\n",
    "            # Computer WER\n",
    "            results[idx][f'{segment_type}-wer-ocr'] = results[idx].apply(lambda x: pywer.wer(x[f'ocr.{segment_type}'], \n",
    "                                                         x[f'groundtruth.{segment_type}']), axis=1)\n",
    "            results[idx][f'{segment_type}-wer-pred'] = results[idx].apply(lambda x: pywer.wer(x[f'prediction.{segment_type}'], \n",
    "                                                         x[f'groundtruth.{segment_type}']), axis=1)\n",
    "\n",
    "            # CER & WER improvement\n",
    "            results[idx][f'{segment_type}-cer-improvement'] = \\\n",
    "                results[idx].apply(lambda x: get_cer_wer_improvement(x[f'{segment_type}-cer-ocr'],\n",
    "                                                             x[f'{segment_type}-cer-pred']), axis=1)\n",
    "            results[idx][f'{segment_type}-wer-improvement'] = \\\n",
    "                results[idx].apply(lambda x: get_cer_wer_improvement(x[f'{segment_type}-wer-ocr'],\n",
    "                                                             x[f'{segment_type}-wer-pred']), axis=1)\n",
    "\n",
    "            # Create a new column for the OCR noise level bins\n",
    "            results[idx][f\"{segment_type}-ocr-noise-group\"] = pd.cut(results[idx][f'{segment_type}-lev-ocr'], \n",
    "                                                     bins=bins, labels=labels, \n",
    "                                                     include_lowest=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7756144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3341f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdabfa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af4774",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687dd2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dataset_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f7dd1d",
   "metadata": {},
   "source": [
    "## AJMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cac3e609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>article_id</th>\n",
       "      <th>ocr.line</th>\n",
       "      <th>ocr.sentence</th>\n",
       "      <th>ocr.region</th>\n",
       "      <th>groundtruth.line</th>\n",
       "      <th>groundtruth.sentence</th>\n",
       "      <th>groundtruth.region</th>\n",
       "      <th>prediction.prompt</th>\n",
       "      <th>...</th>\n",
       "      <th>prediction.sentence</th>\n",
       "      <th>prediction.region</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>language</th>\n",
       "      <th>File</th>\n",
       "      <th>Date</th>\n",
       "      <th>Type</th>\n",
       "      <th>NbAlignedChar</th>\n",
       "      <th>century</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bsb10234118</td>\n",
       "      <td>ajmc-mixed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "      <td>Correct the spelling and grammar of the follow...</td>\n",
       "      <td>...</td>\n",
       "      <td>1 Corinthians 10:10. οὐκ ἐπιδεῖξαι μέρος τὴν ἡ...</td>\n",
       "      <td>⁇  Correct the spelling and grammar of the fo...</td>\n",
       "      <td>decapoda-research-llama-7b-hf</td>\n",
       "      <td>prompt_basic_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bsb10234118</td>\n",
       "      <td>ajmc-mixed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I. T. XVI. p. 731. et 718. eamque κακόζηλον ἑρ...</td>\n",
       "      <td>p. 731.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>1. T. XVI. p. 731. et 718. eamque κακόζηλον ἑρ...</td>\n",
       "      <td>p. 731.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "      <td>Correct the spelling and grammar of the follow...</td>\n",
       "      <td>...</td>\n",
       "      <td>The main features of the political system of t...</td>\n",
       "      <td>⁇  Correct the spelling and grammar of the fo...</td>\n",
       "      <td>decapoda-research-llama-7b-hf</td>\n",
       "      <td>prompt_basic_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bsb10234118</td>\n",
       "      <td>ajmc-mixed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V. 9. Ἔνδον γὰρ ἀνήρ - Olim adnotavi articulum...</td>\n",
       "      <td>V. 9.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>V. 9. \"Evdov γὰρ ‘arıjg — Olim adnotavi articu...</td>\n",
       "      <td>V. 9.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "      <td>Correct the spelling and grammar of the follow...</td>\n",
       "      <td>...</td>\n",
       "      <td>The only thing that can really make us happy i...</td>\n",
       "      <td>⁇  Correct the spelling and grammar of the fo...</td>\n",
       "      <td>decapoda-research-llama-7b-hf</td>\n",
       "      <td>prompt_basic_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bsb10234118</td>\n",
       "      <td>ajmc-mixed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>δατος Aristoph. Lys. 370. αἱρώμεθ’ ὑμεῖς θοὔδ...</td>\n",
       "      <td>Lys.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>durog Aristoph. Lys. 370. αἱρώμεθ’ ὑμεῖς θοὔδα...</td>\n",
       "      <td>Lys.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "      <td>Correct the spelling and grammar of the follow...</td>\n",
       "      <td>...</td>\n",
       "      <td>and Pup.s will have no school on February 17.</td>\n",
       "      <td>⁇  Correct the spelling and grammar of the fo...</td>\n",
       "      <td>decapoda-research-llama-7b-hf</td>\n",
       "      <td>prompt_basic_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bsb10234118</td>\n",
       "      <td>ajmc-mixed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xerit Sophocles χθονὸς ἀείρας et Oppian. Cyn. ...</td>\n",
       "      <td>Cyn.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>xerit Sophocles χθονὸς deigag et Oppian. Cyn. ...</td>\n",
       "      <td>Cyn.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "      <td>Correct the spelling and grammar of the follow...</td>\n",
       "      <td>...</td>\n",
       "      <td>Cynthia has been a patient in this hospital fo...</td>\n",
       "      <td>⁇  Correct the spelling and grammar of the fo...</td>\n",
       "      <td>decapoda-research-llama-7b-hf</td>\n",
       "      <td>prompt_basic_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename dataset_name article_id   \n",
       "0  bsb10234118   ajmc-mixed        NaN  \\\n",
       "1  bsb10234118   ajmc-mixed        NaN   \n",
       "2  bsb10234118   ajmc-mixed        NaN   \n",
       "3  bsb10234118   ajmc-mixed        NaN   \n",
       "4  bsb10234118   ajmc-mixed        NaN   \n",
       "\n",
       "                                            ocr.line   \n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...  \\\n",
       "1  I. T. XVI. p. 731. et 718. eamque κακόζηλον ἑρ...   \n",
       "2  V. 9. Ἔνδον γὰρ ἀνήρ - Olim adnotavi articulum...   \n",
       "3  δατος Aristoph. Lys. 370. αἱρώμεθ’ ὑμεῖς θοὔδ...   \n",
       "4  xerit Sophocles χθονὸς ἀείρας et Oppian. Cyn. ...   \n",
       "\n",
       "                              ocr.sentence   \n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm.  \\\n",
       "1                                  p. 731.   \n",
       "2                                    V. 9.   \n",
       "3                                     Lys.   \n",
       "4                                     Cyn.   \n",
       "\n",
       "                                          ocr.region   \n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...  \\\n",
       "1  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...   \n",
       "2  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...   \n",
       "3  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...   \n",
       "4  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...   \n",
       "\n",
       "                                    groundtruth.line   \n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...  \\\n",
       "1  1. T. XVI. p. 731. et 718. eamque κακόζηλον ἑρ...   \n",
       "2  V. 9. \"Evdov γὰρ ‘arıjg — Olim adnotavi articu...   \n",
       "3  durog Aristoph. Lys. 370. αἱρώμεθ’ ὑμεῖς θοὔδα...   \n",
       "4  xerit Sophocles χθονὸς deigag et Oppian. Cyn. ...   \n",
       "\n",
       "                      groundtruth.sentence   \n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm.  \\\n",
       "1                                  p. 731.   \n",
       "2                                    V. 9.   \n",
       "3                                     Lys.   \n",
       "4                                     Cyn.   \n",
       "\n",
       "                                  groundtruth.region   \n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...  \\\n",
       "1  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...   \n",
       "2  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...   \n",
       "3  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...   \n",
       "4  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...   \n",
       "\n",
       "                                   prediction.prompt  ...   \n",
       "0  Correct the spelling and grammar of the follow...  ...  \\\n",
       "1  Correct the spelling and grammar of the follow...  ...   \n",
       "2  Correct the spelling and grammar of the follow...  ...   \n",
       "3  Correct the spelling and grammar of the follow...  ...   \n",
       "4  Correct the spelling and grammar of the follow...  ...   \n",
       "\n",
       "                                 prediction.sentence   \n",
       "0  1 Corinthians 10:10. οὐκ ἐπιδεῖξαι μέρος τὴν ἡ...  \\\n",
       "1  The main features of the political system of t...   \n",
       "2  The only thing that can really make us happy i...   \n",
       "3      and Pup.s will have no school on February 17.   \n",
       "4  Cynthia has been a patient in this hospital fo...   \n",
       "\n",
       "                                   prediction.region   \n",
       "0   ⁇  Correct the spelling and grammar of the fo...  \\\n",
       "1   ⁇  Correct the spelling and grammar of the fo...   \n",
       "2   ⁇  Correct the spelling and grammar of the fo...   \n",
       "3   ⁇  Correct the spelling and grammar of the fo...   \n",
       "4   ⁇  Correct the spelling and grammar of the fo...   \n",
       "\n",
       "                           model           prompt language File Date Type   \n",
       "0  decapoda-research-llama-7b-hf  prompt_basic_02      NaN  NaN  NaN  NaN  \\\n",
       "1  decapoda-research-llama-7b-hf  prompt_basic_02      NaN  NaN  NaN  NaN   \n",
       "2  decapoda-research-llama-7b-hf  prompt_basic_02      NaN  NaN  NaN  NaN   \n",
       "3  decapoda-research-llama-7b-hf  prompt_basic_02      NaN  NaN  NaN  NaN   \n",
       "4  decapoda-research-llama-7b-hf  prompt_basic_02      NaN  NaN  NaN  NaN   \n",
       "\n",
       "  NbAlignedChar century  \n",
       "0           NaN     NaN  \n",
       "1           NaN     NaN  \n",
       "2           NaN     NaN  \n",
       "3           NaN     NaN  \n",
       "4           NaN     NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data[data.dataset_name == 'ajmc-mixed']\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f338f4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line level **************************************************\n",
      "sentence level **************************************************\n",
      "region level **************************************************\n"
     ]
    }
   ],
   "source": [
    "# for idx, result in enumerate(results):\n",
    "for segment_type in ['line', 'sentence', 'region']:\n",
    "    print(segment_type, 'level', '*'*50)\n",
    "    try:\n",
    "        improved_texts = dataset[dataset['model'] == 'bigscience-bloom-560m'] \n",
    "        impooved_texts = improved_texts[improved_texts[f'{segment_type}-lev-improvement'] >= 0.7]\n",
    "        #result[result[f'{segment_type}-lev-improvement'] >= 0.3]\n",
    "        for _, improved_text in improved_texts.iterrows():\n",
    "            print('Model:', improved_texts['model'].unique()[0])\n",
    "            print('Dataset:', improved_texts['dataset_name'].unique()[0])\n",
    "            print('Quality Band:', improved_text[f'{segment_type}-ocr-noise-group'])\n",
    "\n",
    "            print('LEV ground-ocr', improved_text[f'{segment_type}-lev-ocr'], \n",
    "                  'LEV ground-pred', improved_text[f'{segment_type}-lev-pred'])\n",
    "            print('LEV Improvement:', improved_text[f'{segment_type}-lev-improvement'])\n",
    "            print('CER Improvement:', improved_text[f'{segment_type}-cer-improvement'])\n",
    "            print('WER Improvement:', improved_text[f'{segment_type}-wer-improvement'])\n",
    "\n",
    "            print('Ground:', improved_text[f'groundtruth.{segment_type}'][:50])\n",
    "            print('OCR:', improved_text[f'ocr.{segment_type}'][:50])\n",
    "            print('Pred:', improved_text[f'prediction.{segment_type}'])\n",
    "            print('--'*50)\n",
    "    except:\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b0f3f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prompt_order = ['prompt_basic_01', 'prompt_basic_02', 'prompt_complex_01']  # Replace these with your actual prompt names in the desired order\n",
    "\n",
    "segment_levels = ['line', 'sentence', 'region']\n",
    "\n",
    "for level in segment_levels:\n",
    "    # Create a bar plot for CER improvement\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    barplot = sns.barplot(data=dataset, x='model', y=f'{level}-lev-improvement', hue='prompt', hue_order=prompt_order)\n",
    "    \n",
    "    barplot.set_xticklabels(barplot.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "    plt.title(f'{level.capitalize()}-level CER Improvement for ajmc by Model and Prompt')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a3773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c47988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e208ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a258b74e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0143228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d7fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab60d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mean_metrics_df = data.groupby(['dataset_name', 'model', 'prompt', 'line-lev-improvement']).mean().reset_index()\n",
    "print(mean_metrics_df.head())\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=mean_metrics_df, x='dataset_name', y='line-lev-improvement', hue='model')\n",
    "plt.title('Line-level CER Improvement by Dataset and Model')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3860d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bded1db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2da865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f28ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f379f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d3027",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Set the colorblind color palette\n",
    "sns.set_palette(\"colorblind\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for model in data['model'].unique():\n",
    "    data_per_model = data[data['model'] == model]\n",
    "    for segment_type in ['line', 'sentence', 'region']:\n",
    "        # Filter the data by dataset and segment type\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "        # Create the box plot\n",
    "        sns.boxplot(x=f'{segment_type}-ocr-noise-group', y=f'{segment_type}-lev-improvement', \n",
    "                    data=data_per_model, hue='dataset_name', palette='colorblind', ax=ax)\n",
    "\n",
    "        # Set the plot title and axis labels\n",
    "        plt.title(f'Levenshtein Distance Improvement for {segment_type.capitalize()} Segments ({model})')\n",
    "        plt.xlabel('Quality Bands')\n",
    "        plt.ylabel('Levenshtein Distance Improvement')\n",
    "        \n",
    "        plt.ylim((-0.5, 1.5))\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038e4203",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model in data['dataset_name'].unique():\n",
    "    data_per_model = data[data['dataset_name'] == model]\n",
    "    for segment_type in ['line', 'sentence', 'region']:\n",
    "        # Filter the data by dataset and segment type\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "        # Create the box plot\n",
    "        sns.boxplot(x=f'{segment_type}-ocr-noise-group', y=f'{segment_type}-lev-improvement', \n",
    "                    data=data_per_model, hue='model', palette='colorblind', ax=ax)\n",
    "\n",
    "        # Set the plot title and axis labels\n",
    "        plt.title(f'Levenshtein Distance Improvement for {segment_type.capitalize()} Segments ({model})')\n",
    "        plt.xlabel('Quality Bands')\n",
    "        plt.ylabel('Levenshtein Distance Improvement')\n",
    "        \n",
    "        plt.ylim((-0.2, 1.0))\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0902d03b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe33cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Set the colorblind color palette\n",
    "sns.set_palette(\"colorblind\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for result in results:\n",
    "    \n",
    "    dataset_name = result['dataset_name'].unique()[0]\n",
    "    \n",
    "    for segment_type in ['line', 'sentence', 'region']:\n",
    "        \n",
    "        #grouped_results = result.groupby([f\"{segment_type}-ocr-noise-group\", \"dataset_name\"]).size().reset_index(name=\"count\")\n",
    "        \n",
    "        grouped_results = result.groupby([f\"{segment_type}-ocr-noise-group\", \"dataset_name\"])[f\"{segment_type}-lev-improvement\"].mean().reset_index()\n",
    "\n",
    "        print(grouped_results.head())\n",
    "        \n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        _ = sns.lineplot(x=f\"{segment_type}-ocr-noise-group\", y=f'{segment_type}-lev-improvement', hue='dataset_name',\n",
    "                 data=grouped_results, ax=ax, markers=True, linestyle='-', linewidth=2.5)\n",
    "\n",
    "\n",
    "        # Set plot labels\n",
    "        ax.set_xlabel(f\"{dataset_name} Ground Truth {segment_type.capitalize()}\")\n",
    "        ax.set_ylabel(f\"{dataset_name} {segment_type.capitalize()} Improvement\")\n",
    "        ax.set_title(f\"{dataset_name} Levenshtein Improvement for {segment_type.capitalize()} OCR Examples\")\n",
    "\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b6097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ff5018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f60dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e38d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d142c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
