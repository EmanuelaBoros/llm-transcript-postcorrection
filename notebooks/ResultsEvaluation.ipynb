{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfadbdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "class Const:\n",
    "    OCR = 'ocr'\n",
    "    GROUND = 'groundtruth'\n",
    "    REGION = 'region'\n",
    "    LINE = 'line'\n",
    "    SENTENCE = 'sentence'\n",
    "    FILE = 'filename'\n",
    "    DATASET = 'dataset_name'\n",
    "    PREDICTION = 'prediction'\n",
    "    PROMPT = 'prompt'\n",
    "    LANGUAGE = 'language'\n",
    "    NONE = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79f14e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/datasets/ocr/converted/ajmc_mixed.jsonl\n",
      "../data/datasets/ocr/converted/ajmc_primary_text.jsonl\n",
      "../data/datasets/ocr/converted/icdar-2017.jsonl\n",
      "../data/datasets/ocr/converted/overproof.jsonl\n",
      "../data/datasets/ocr/converted/icdar-2019.jsonl\n",
      "../data/datasets/ocr/converted/impresso-nzz.jsonl\n",
      "../data/datasets/ocr/converted/sample/sample.jsonl\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "\n",
    "for root, dirs, files in os.walk('../data/datasets/ocr/converted'):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jsonl\"):\n",
    "            input_file = os.path.join(root, file)\n",
    "            print(input_file)\n",
    "            with open(input_file) as f:\n",
    "                lines = f.read().splitlines()\n",
    "            df_inter = pd.DataFrame(lines)\n",
    "            df_inter.columns = ['json_element']\n",
    "            df_inter['json_element'].apply(json.loads)\n",
    "            df = pd.json_normalize(df_inter['json_element'].apply(json.loads))\n",
    "            datasets.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58611ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique lines/sentences/regions.\n",
      "\n",
      "Dataset: ajmc\n",
      "No. lines: 870 / 2131 No. sentences: 679 / 2131 No. regions: 63 / 2131\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: ajmc\n",
      "No. lines: 151 / 330 No. sentences: 112 / 330 No. regions: 33 / 330\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: icdar-2017\n",
      "No. lines: 0 / 477 No. sentences: 461 / 477 No. regions: 28 / 477\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: overproof\n",
      "No. lines: 2278 / 2669 No. sentences: 399 / 2669 No. regions: 41 / 2669\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: icdar-2019\n",
      "No. lines: 0 / 404 No. sentences: 404 / 404 No. regions: 41 / 404\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: impresso-nzz\n",
      "No. lines: 3709 / 6140 No. sentences: 1943 / 6140 No. regions: 635 / 6140\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: impresso-nzz\n",
      "No. lines: 1016 / 1215 No. sentences: 837 / 1215 No. regions: 427 / 1215\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique lines/sentences/regions.\\n')\n",
    "for dataset in datasets:\n",
    "    print('Dataset:', dataset['dataset_name'].unique()[0])\n",
    "    print('No. lines:', dataset['ocr.line']. nunique(), '/', len(dataset['ocr.sentence']), \n",
    "          'No. sentences:', dataset['ocr.sentence']. nunique(), '/', len(dataset['ocr.sentence']), \n",
    "          'No. regions:', dataset['ocr.region']. nunique(), '/', len(dataset['ocr.region']))\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a98df9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>ocr.line</th>\n",
       "      <th>ocr.sentence</th>\n",
       "      <th>ocr.region</th>\n",
       "      <th>groundtruth.line</th>\n",
       "      <th>groundtruth.sentence</th>\n",
       "      <th>groundtruth.region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bsb10234118</td>\n",
       "      <td>ajmc</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bsb10234118</td>\n",
       "      <td>ajmc</td>\n",
       "      <td>I. T. XVI. p. 731. et 718. eamque κακόζηλον ἑρ...</td>\n",
       "      <td>p. 731.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>1. T. XVI. p. 731. et 718. eamque κακόζηλον ἑρ...</td>\n",
       "      <td>p. 731.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bsb10234118</td>\n",
       "      <td>ajmc</td>\n",
       "      <td>V. 9. Ἔνδον γὰρ ἀνήρ - Olim adnotavi articulum...</td>\n",
       "      <td>V. 9.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>V. 9. \"Evdov γὰρ ‘arıjg — Olim adnotavi articu...</td>\n",
       "      <td>V. 9.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bsb10234118</td>\n",
       "      <td>ajmc</td>\n",
       "      <td>δατος Aristoph. Lys. 370. αἱρώμεθ’ ὑμεῖς θοὔδ...</td>\n",
       "      <td>Lys.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>durog Aristoph. Lys. 370. αἱρώμεθ’ ὑμεῖς θοὔδα...</td>\n",
       "      <td>Lys.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bsb10234118</td>\n",
       "      <td>ajmc</td>\n",
       "      <td>xerit Sophocles χθονὸς ἀείρας et Oppian. Cyn. ...</td>\n",
       "      <td>Cyn.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>xerit Sophocles χθονὸς deigag et Oppian. Cyn. ...</td>\n",
       "      <td>Cyn.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename dataset_name  \\\n",
       "0  bsb10234118         ajmc   \n",
       "1  bsb10234118         ajmc   \n",
       "2  bsb10234118         ajmc   \n",
       "3  bsb10234118         ajmc   \n",
       "4  bsb10234118         ajmc   \n",
       "\n",
       "                                            ocr.line  \\\n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...   \n",
       "1  I. T. XVI. p. 731. et 718. eamque κακόζηλον ἑρ...   \n",
       "2  V. 9. Ἔνδον γὰρ ἀνήρ - Olim adnotavi articulum...   \n",
       "3  δατος Aristoph. Lys. 370. αἱρώμεθ’ ὑμεῖς θοὔδ...   \n",
       "4  xerit Sophocles χθονὸς ἀείρας et Oppian. Cyn. ...   \n",
       "\n",
       "                              ocr.sentence  \\\n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm.   \n",
       "1                                  p. 731.   \n",
       "2                                    V. 9.   \n",
       "3                                     Lys.   \n",
       "4                                     Cyn.   \n",
       "\n",
       "                                          ocr.region  \\\n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...   \n",
       "1  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...   \n",
       "2  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...   \n",
       "3  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...   \n",
       "4  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...   \n",
       "\n",
       "                                    groundtruth.line  \\\n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...   \n",
       "1  1. T. XVI. p. 731. et 718. eamque κακόζηλον ἑρ...   \n",
       "2  V. 9. \"Evdov γὰρ ‘arıjg — Olim adnotavi articu...   \n",
       "3  durog Aristoph. Lys. 370. αἱρώμεθ’ ὑμεῖς θοὔδα...   \n",
       "4  xerit Sophocles χθονὸς deigag et Oppian. Cyn. ...   \n",
       "\n",
       "                      groundtruth.sentence  \\\n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm.   \n",
       "1                                  p. 731.   \n",
       "2                                    V. 9.   \n",
       "3                                     Lys.   \n",
       "4                                     Cyn.   \n",
       "\n",
       "                                  groundtruth.region  \n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...  \n",
       "1  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...  \n",
       "2  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...  \n",
       "3  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...  \n",
       "4  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53ae3ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_SAMPLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4218b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c95cece7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13366"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8435f3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'dataset_name', 'ocr.line', 'ocr.sentence', 'ocr.region',\n",
       "       'groundtruth.line', 'groundtruth.sentence', 'groundtruth.region',\n",
       "       'language', 'File', 'Date', 'Type', 'NbAlignedChar', 'article_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7e69fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_SAMPLE:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    files_keep, files_removed, _, _ = train_test_split(dataset, dataset['dataset_name'], \n",
    "                                                       test_size=0.90, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8e25dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_SAMPLE:\n",
    "    output_file = '../data/datasets/ocr/converted/sample/sample.jsonl'\n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        for index, row in files_keep.iterrows():\n",
    "\n",
    "            json_line = json.dumps({Const.LANGUAGE: row['language'],\n",
    "                                    Const.FILE: row['filename'],\n",
    "                                    Const.DATASET: row['dataset_name'],\n",
    "                                    Const.OCR: {Const.LINE: row['ocr.line'],\n",
    "                                                Const.SENTENCE: row['ocr.sentence'],\n",
    "                                                Const.REGION: row['ocr.region']}, \n",
    "                                    Const.GROUND: {Const.LINE: row['groundtruth.line'],\n",
    "                                                   Const.SENTENCE: row['groundtruth.sentence'],\n",
    "                                                   Const.REGION: row['groundtruth.region']},\n",
    "                                    'File': row['File'], \n",
    "                                    'Date': row['Date'],\n",
    "                                    'Type': row['Type'], \n",
    "                                    'NbAlignedChar': row['NbAlignedChar'], \n",
    "                                    'article_id': row['article_id']\n",
    "                                    })\n",
    "\n",
    "            outfile.write(json_line + \"\\n\")\n",
    "            outfile.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0493b0",
   "metadata": {},
   "source": [
    "### Analsys of preliminary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff1950d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/output/prompt_basic_01/sample/results-sample-facebook-opt-350m.jsonl\n",
      "../data/output/prompt_basic_01/sample/results-sample-gpt2.jsonl\n",
      "../data/output/prompt_basic_01/sample/results-sample-bigscience-bloom-560m.jsonl\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for root, dirs, files in os.walk('../data/output'):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jsonl\"):\n",
    "            input_file = os.path.join(root, file)\n",
    "            print(input_file)\n",
    "            with open(input_file) as f:\n",
    "                lines = f.read().splitlines()\n",
    "            df_inter = pd.DataFrame(lines)\n",
    "            df_inter.columns = ['json_element']\n",
    "            df_inter['json_element'].apply(json.loads)\n",
    "            df = pd.json_normalize(df_inter['json_element'].apply(json.loads))\n",
    "            df['LM'] = [file[16:-6]] * len(df)\n",
    "            results.append(df)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91f6ef94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['language', 'filename', 'dataset_name', 'File', 'Date', 'Type',\n",
       "       'NbAlignedChar', 'article_id', 'ocr.line', 'ocr.sentence', 'ocr.region',\n",
       "       'groundtruth.line', 'groundtruth.sentence', 'groundtruth.region',\n",
       "       'prediction.prompt', 'prediction.line', 'prediction.sentence',\n",
       "       'prediction.region', 'LM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6e2d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance\n",
    "\n",
    "def levenshtein(reference, hypothesis, progress_bar=False):\n",
    "    print(reference, hypothesis)\n",
    "    \n",
    "    assert len(reference) == len(hypothesis)\n",
    "    text = zip(reference, hypothesis)\n",
    "    if progress_bar:\n",
    "        text = tqdm(text, total=len(reference))\n",
    "    d = [distance(r, h) for r, h in text]\n",
    "    output = pd.DataFrame({\"reference\": reference, \"hypothesis\": hypothesis})\\\n",
    "        .assign(distance=lambda df: d)\\\n",
    "        .assign(\n",
    "        cer=lambda df: df.apply(\n",
    "            lambda r: 100 * r[\"distance\"] / max(len(r[\"reference\"]), 1),\n",
    "            axis=1\n",
    "        )\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cc33983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ve>nachlässig'c»\", 'Slilrichtung', 'wieder', 'gebührende', 'Beach'] [\"ve>nachlässig'c»\", 'Slilrichtung', 'wieder', 'gebührende', 'Beach']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>distance</th>\n",
       "      <th>cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ve&gt;nachlässig'c»</td>\n",
       "      <td>ve&gt;nachlässig'c»</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Slilrichtung</td>\n",
       "      <td>Slilrichtung</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wieder</td>\n",
       "      <td>wieder</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gebührende</td>\n",
       "      <td>gebührende</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beach</td>\n",
       "      <td>Beach</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          reference        hypothesis  distance  cer\n",
       "0  ve>nachlässig'c»  ve>nachlässig'c»         0  0.0\n",
       "1      Slilrichtung      Slilrichtung         0  0.0\n",
       "2            wieder            wieder         0  0.0\n",
       "3        gebührende        gebührende         0  0.0\n",
       "4             Beach             Beach         0  0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein(\"ve>nachlässig'c» Slilrichtung wieder gebührende Beach\".split(), \n",
    "            \"ve>nachlässig'c» Slilrichtung wieder gebührende Beach\".split(), progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d50ad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "\n",
    "def compute_levenshtein_distance(text1, text2):\n",
    "#     print(text1, text2)\n",
    "    if ('No text' in text1) or 'No text' in text2:\n",
    "        return -150\n",
    "    return Levenshtein.distance(text1, text2)\n",
    "\n",
    "def compute_normalized_levenshtein_distance(text1, text2):\n",
    "    distance = Levenshtein.distance(text1, text2)\n",
    "    max_length = max(len(text1), len(text2))\n",
    "    normalized_distance = distance / max_length\n",
    "    return normalized_distance\n",
    "\n",
    "\n",
    "def evaluate_ocr(original_ocr_text, corrected_ocr_text, ground_truth_text):\n",
    "    original_distance = compute_levenshtein_distance(original_ocr_text, ground_truth_text)\n",
    "    corrected_distance = compute_levenshtein_distance(corrected_ocr_text, ground_truth_text)\n",
    "    return original_distance, corrected_distance\n",
    "\n",
    "\n",
    "def get_improvement(original_distance, corrected_distance):\n",
    "    return original_distance - corrected_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06855908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the OCR noise level\n",
    "def compute_ocr_noise_level(ground_truth, ocr_text):\n",
    "#     print('ground_truth', ground_truth, len(ground_truth))\n",
    "    levenshtein_dist = Levenshtein.distance(ground_truth, ocr_text)\n",
    "    return levenshtein_dist / len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f914500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def align_text(ground_truth_text, ocr_text):\n",
    "    # Define a window size for matching substrings\n",
    "    window_size = 10\n",
    "\n",
    "    # Find the substring in the OCR text with the smallest Levenshtein distance to the ground truth text\n",
    "    min_distance = np.inf\n",
    "    best_start_idx = 0\n",
    "    for start_idx in range(len(ocr_text) - window_size + 1):\n",
    "        end_idx = start_idx + window_size\n",
    "        window_text = ocr_text[start_idx:end_idx]\n",
    "        window_distance = distance(window_text, ground_truth_text)\n",
    "        if window_distance < min_distance:\n",
    "            min_distance = window_distance\n",
    "            best_start_idx = start_idx\n",
    "\n",
    "    # Align the OCR and ground truth text based on the best matching substring\n",
    "    aligned_ocr_text = \" \" * best_start_idx + ocr_text[best_start_idx:best_start_idx+len(ground_truth_text)]\n",
    "    \n",
    "    print(ground_truth_text)\n",
    "    print(aligned_ocr_text, '\\n------')\n",
    "    return ground_truth_text, aligned_ocr_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff56cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genalog.text import anchor\n",
    "from metrics import get_stats\n",
    "\n",
    "metrics_char = ['edit_insert', 'edit_delete', 'edit_replace', 'edit_insert_spacing', 'edit_delete_spacing',\n",
    "                'insert', 'delete', 'replace', 'spacing', 'total_chars',\n",
    "                'total_words', 'total_alnum_words', 'matching_chars', 'matching_alnum_words',\n",
    "                'matching_words', 'alnum_word_accuracy', 'word_accuracy', 'char_accuracy']\n",
    "                                                                    \n",
    "def align_texts(gt_text, ocr_text):\n",
    "\n",
    "    # We align the texts with RETAS Method\n",
    "    try:\n",
    "        aligned_gt, aligned_noise = anchor.align_w_anchor(gt_text, ocr_text)\n",
    "    except:\n",
    "        aligned_gt, aligned_noise = gt_text, ocr_text\n",
    "    \n",
    "    stats = get_stats(gt_text, ocr_text)[0]\n",
    "    \n",
    "    stats = {key: stats[key] for key in metrics_char}\n",
    "    print(len(stats), stats)\n",
    "    return stats\n",
    "#     print('GT:', aligned_gt)\n",
    "#     print('OCR:', aligned_noise)\n",
    "#     print('--'*100)\n",
    "#     return aligned_gt, aligned_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54f62c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin the OCR quality scores into groups with labels\n",
    "bins = [0, 0.7, 0.8, 0.9, 1]\n",
    "labels = [\"<=0.7\", \">0.7\", \">0.8\", \">0.9\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ced49b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 6, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 6, 'spacing': 0, 'total_chars': 64, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 58, 'matching_alnum_words': 4, 'matching_words': 4, 'alnum_word_accuracy': 0.5, 'word_accuracy': 0.5, 'char_accuracy': 0.90625}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 6, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 6, 'spacing': 0, 'total_chars': 64, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 58, 'matching_alnum_words': 4, 'matching_words': 4, 'alnum_word_accuracy': 0.5, 'word_accuracy': 0.5, 'char_accuracy': 0.90625}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 6, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 6, 'spacing': 0, 'total_chars': 64, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 58, 'matching_alnum_words': 4, 'matching_words': 4, 'alnum_word_accuracy': 0.5, 'word_accuracy': 0.5, 'char_accuracy': 0.90625}\n",
      "18 {'edit_insert': 0, 'edit_delete': 1, 'edit_replace': 3, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 3, 'spacing': 0, 'total_chars': 54, 'total_words': 9, 'total_alnum_words': 8, 'matching_chars': 50, 'matching_alnum_words': 5, 'matching_words': 6, 'alnum_word_accuracy': 0.625, 'word_accuracy': 0.6666666666666666, 'char_accuracy': 0.9259259259259259}\n",
      "18 {'edit_insert': 0, 'edit_delete': 1, 'edit_replace': 3, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 3, 'spacing': 0, 'total_chars': 54, 'total_words': 9, 'total_alnum_words': 8, 'matching_chars': 50, 'matching_alnum_words': 5, 'matching_words': 6, 'alnum_word_accuracy': 0.625, 'word_accuracy': 0.6666666666666666, 'char_accuracy': 0.9259259259259259}\n",
      "18 {'edit_insert': 0, 'edit_delete': 1, 'edit_replace': 3, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 3, 'spacing': 0, 'total_chars': 54, 'total_words': 9, 'total_alnum_words': 8, 'matching_chars': 50, 'matching_alnum_words': 5, 'matching_words': 6, 'alnum_word_accuracy': 0.625, 'word_accuracy': 0.6666666666666666, 'char_accuracy': 0.9259259259259259}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 53, 'total_words': 9, 'total_alnum_words': 9, 'matching_chars': 53, 'matching_alnum_words': 9, 'matching_words': 9, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 53, 'total_words': 9, 'total_alnum_words': 9, 'matching_chars': 53, 'matching_alnum_words': 9, 'matching_words': 9, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 53, 'total_words': 9, 'total_alnum_words': 9, 'matching_chars': 53, 'matching_alnum_words': 9, 'matching_words': 9, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 37, 'total_words': 5, 'total_alnum_words': 5, 'matching_chars': 37, 'matching_alnum_words': 5, 'matching_words': 5, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 37, 'total_words': 5, 'total_alnum_words': 5, 'matching_chars': 37, 'matching_alnum_words': 5, 'matching_words': 5, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 37, 'total_words': 5, 'total_alnum_words': 5, 'matching_chars': 37, 'matching_alnum_words': 5, 'matching_words': 5, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 1, 'edit_replace': 1, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 1, 'spacing': 0, 'total_chars': 41, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 39, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 0.875, 'word_accuracy': 0.875, 'char_accuracy': 0.9512195121951219}\n",
      "18 {'edit_insert': 0, 'edit_delete': 1, 'edit_replace': 1, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 1, 'spacing': 0, 'total_chars': 41, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 39, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 0.875, 'word_accuracy': 0.875, 'char_accuracy': 0.9512195121951219}\n",
      "18 {'edit_insert': 0, 'edit_delete': 1, 'edit_replace': 1, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 1, 'spacing': 0, 'total_chars': 41, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 39, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 0.875, 'word_accuracy': 0.875, 'char_accuracy': 0.9512195121951219}\n",
      "18 {'edit_insert': 1, 'edit_delete': 0, 'edit_replace': 7, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 6, 'spacing': 0, 'total_chars': 44, 'total_words': 10, 'total_alnum_words': 10, 'matching_chars': 36, 'matching_alnum_words': 6, 'matching_words': 6, 'alnum_word_accuracy': 0.6, 'word_accuracy': 0.6, 'char_accuracy': 0.8181818181818182}\n",
      "18 {'edit_insert': 1, 'edit_delete': 0, 'edit_replace': 7, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 6, 'spacing': 0, 'total_chars': 44, 'total_words': 10, 'total_alnum_words': 10, 'matching_chars': 36, 'matching_alnum_words': 6, 'matching_words': 6, 'alnum_word_accuracy': 0.6, 'word_accuracy': 0.6, 'char_accuracy': 0.8181818181818182}\n",
      "18 {'edit_insert': 1, 'edit_delete': 0, 'edit_replace': 7, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 6, 'spacing': 0, 'total_chars': 44, 'total_words': 10, 'total_alnum_words': 10, 'matching_chars': 36, 'matching_alnum_words': 6, 'matching_words': 6, 'alnum_word_accuracy': 0.6, 'word_accuracy': 0.6, 'char_accuracy': 0.8181818181818182}\n",
      "18 {'edit_insert': 0, 'edit_delete': 1, 'edit_replace': 1, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 2, 'replace': 0, 'spacing': 0, 'total_chars': 61, 'total_words': 9, 'total_alnum_words': 9, 'matching_chars': 59, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 0.7777777777777778, 'word_accuracy': 0.7777777777777778, 'char_accuracy': 0.9672131147540983}\n",
      "18 {'edit_insert': 0, 'edit_delete': 1, 'edit_replace': 1, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 2, 'replace': 0, 'spacing': 0, 'total_chars': 61, 'total_words': 9, 'total_alnum_words': 9, 'matching_chars': 59, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 0.7777777777777778, 'word_accuracy': 0.7777777777777778, 'char_accuracy': 0.9672131147540983}\n",
      "18 {'edit_insert': 0, 'edit_delete': 1, 'edit_replace': 1, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 2, 'replace': 0, 'spacing': 0, 'total_chars': 61, 'total_words': 9, 'total_alnum_words': 9, 'matching_chars': 59, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 0.7777777777777778, 'word_accuracy': 0.7777777777777778, 'char_accuracy': 0.9672131147540983}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 2, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 2, 'spacing': 0, 'total_chars': 47, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 45, 'matching_alnum_words': 5, 'matching_words': 5, 'alnum_word_accuracy': 0.625, 'word_accuracy': 0.625, 'char_accuracy': 0.9574468085106383}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 2, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 2, 'spacing': 0, 'total_chars': 47, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 45, 'matching_alnum_words': 5, 'matching_words': 5, 'alnum_word_accuracy': 0.625, 'word_accuracy': 0.625, 'char_accuracy': 0.9574468085106383}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 2, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 2, 'spacing': 0, 'total_chars': 47, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 45, 'matching_alnum_words': 5, 'matching_words': 5, 'alnum_word_accuracy': 0.625, 'word_accuracy': 0.625, 'char_accuracy': 0.9574468085106383}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 26, 'total_words': 3, 'total_alnum_words': 3, 'matching_chars': 26, 'matching_alnum_words': 3, 'matching_words': 3, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 26, 'total_words': 3, 'total_alnum_words': 3, 'matching_chars': 26, 'matching_alnum_words': 3, 'matching_words': 3, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 26, 'total_words': 3, 'total_alnum_words': 3, 'matching_chars': 26, 'matching_alnum_words': 3, 'matching_words': 3, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 32, 'total_words': 4, 'total_alnum_words': 4, 'matching_chars': 32, 'matching_alnum_words': 4, 'matching_words': 4, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 32, 'total_words': 4, 'total_alnum_words': 4, 'matching_chars': 32, 'matching_alnum_words': 4, 'matching_words': 4, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 32, 'total_words': 4, 'total_alnum_words': 4, 'matching_chars': 32, 'matching_alnum_words': 4, 'matching_words': 4, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 46, 'total_words': 9, 'total_alnum_words': 9, 'matching_chars': 46, 'matching_alnum_words': 9, 'matching_words': 9, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 46, 'total_words': 9, 'total_alnum_words': 9, 'matching_chars': 46, 'matching_alnum_words': 9, 'matching_words': 9, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 46, 'total_words': 9, 'total_alnum_words': 9, 'matching_chars': 46, 'matching_alnum_words': 9, 'matching_words': 9, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 6, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 2, 'replace': 0, 'spacing': 0, 'total_chars': 39, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 33, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 0.875, 'word_accuracy': 0.875, 'char_accuracy': 0.8461538461538461}\n",
      "18 {'edit_insert': 0, 'edit_delete': 6, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 2, 'replace': 0, 'spacing': 0, 'total_chars': 39, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 33, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 0.875, 'word_accuracy': 0.875, 'char_accuracy': 0.8461538461538461}\n",
      "18 {'edit_insert': 0, 'edit_delete': 6, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 2, 'replace': 0, 'spacing': 0, 'total_chars': 39, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 33, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 0.875, 'word_accuracy': 0.875, 'char_accuracy': 0.8461538461538461}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 47, 'total_words': 7, 'total_alnum_words': 7, 'matching_chars': 47, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 47, 'total_words': 7, 'total_alnum_words': 7, 'matching_chars': 47, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 47, 'total_words': 7, 'total_alnum_words': 7, 'matching_chars': 47, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 2, 'edit_delete': 8, 'edit_replace': 20, 'edit_insert_spacing': 0, 'edit_delete_spacing': 1, 'insert': 0, 'delete': 0, 'replace': 6, 'spacing': 1, 'total_chars': 34, 'total_words': 5, 'total_alnum_words': 5, 'matching_chars': 5, 'matching_alnum_words': 0, 'matching_words': 0, 'alnum_word_accuracy': 0.0, 'word_accuracy': 0.0, 'char_accuracy': 0.14705882352941177}\n",
      "18 {'edit_insert': 2, 'edit_delete': 8, 'edit_replace': 20, 'edit_insert_spacing': 0, 'edit_delete_spacing': 1, 'insert': 0, 'delete': 0, 'replace': 6, 'spacing': 1, 'total_chars': 34, 'total_words': 5, 'total_alnum_words': 5, 'matching_chars': 5, 'matching_alnum_words': 0, 'matching_words': 0, 'alnum_word_accuracy': 0.0, 'word_accuracy': 0.0, 'char_accuracy': 0.14705882352941177}\n",
      "18 {'edit_insert': 2, 'edit_delete': 8, 'edit_replace': 20, 'edit_insert_spacing': 0, 'edit_delete_spacing': 1, 'insert': 0, 'delete': 0, 'replace': 6, 'spacing': 1, 'total_chars': 34, 'total_words': 5, 'total_alnum_words': 5, 'matching_chars': 5, 'matching_alnum_words': 0, 'matching_words': 0, 'alnum_word_accuracy': 0.0, 'word_accuracy': 0.0, 'char_accuracy': 0.14705882352941177}\n",
      "18 {'edit_insert': 7, 'edit_delete': 2, 'edit_replace': 9, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 2, 'delete': 1, 'replace': 6, 'spacing': 0, 'total_chars': 44, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 28, 'matching_alnum_words': 1, 'matching_words': 1, 'alnum_word_accuracy': 0.125, 'word_accuracy': 0.125, 'char_accuracy': 0.6363636363636364}\n",
      "18 {'edit_insert': 7, 'edit_delete': 2, 'edit_replace': 9, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 2, 'delete': 1, 'replace': 6, 'spacing': 0, 'total_chars': 44, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 28, 'matching_alnum_words': 1, 'matching_words': 1, 'alnum_word_accuracy': 0.125, 'word_accuracy': 0.125, 'char_accuracy': 0.6363636363636364}\n",
      "18 {'edit_insert': 7, 'edit_delete': 2, 'edit_replace': 9, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 2, 'delete': 1, 'replace': 6, 'spacing': 0, 'total_chars': 44, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 28, 'matching_alnum_words': 1, 'matching_words': 1, 'alnum_word_accuracy': 0.125, 'word_accuracy': 0.125, 'char_accuracy': 0.6363636363636364}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 3, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 1, 'spacing': 0, 'total_chars': 39, 'total_words': 7, 'total_alnum_words': 7, 'matching_chars': 36, 'matching_alnum_words': 5, 'matching_words': 5, 'alnum_word_accuracy': 0.7142857142857143, 'word_accuracy': 0.7142857142857143, 'char_accuracy': 0.9230769230769231}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 3, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 1, 'spacing': 0, 'total_chars': 39, 'total_words': 7, 'total_alnum_words': 7, 'matching_chars': 36, 'matching_alnum_words': 5, 'matching_words': 5, 'alnum_word_accuracy': 0.7142857142857143, 'word_accuracy': 0.7142857142857143, 'char_accuracy': 0.9230769230769231}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 64, 'total_words': 11, 'total_alnum_words': 11, 'matching_chars': 64, 'matching_alnum_words': 11, 'matching_words': 11, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 64, 'total_words': 11, 'total_alnum_words': 11, 'matching_chars': 64, 'matching_alnum_words': 11, 'matching_words': 11, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 28, 'total_words': 5, 'total_alnum_words': 5, 'matching_chars': 28, 'matching_alnum_words': 5, 'matching_words': 5, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 28, 'total_words': 5, 'total_alnum_words': 5, 'matching_chars': 28, 'matching_alnum_words': 5, 'matching_words': 5, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 28, 'total_words': 5, 'total_alnum_words': 5, 'matching_chars': 28, 'matching_alnum_words': 5, 'matching_words': 5, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 2, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 1, 'spacing': 0, 'total_chars': 51, 'total_words': 9, 'total_alnum_words': 9, 'matching_chars': 49, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 0.7777777777777778, 'word_accuracy': 0.7777777777777778, 'char_accuracy': 0.9607843137254902}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 2, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 1, 'spacing': 0, 'total_chars': 51, 'total_words': 9, 'total_alnum_words': 9, 'matching_chars': 49, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 0.7777777777777778, 'word_accuracy': 0.7777777777777778, 'char_accuracy': 0.9607843137254902}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 2, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 1, 'spacing': 0, 'total_chars': 51, 'total_words': 9, 'total_alnum_words': 9, 'matching_chars': 49, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 0.7777777777777778, 'word_accuracy': 0.7777777777777778, 'char_accuracy': 0.9607843137254902}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 3, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 3, 'spacing': 0, 'total_chars': 35, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 32, 'matching_alnum_words': 5, 'matching_words': 5, 'alnum_word_accuracy': 0.625, 'word_accuracy': 0.625, 'char_accuracy': 0.9142857142857143}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 3, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 3, 'spacing': 0, 'total_chars': 35, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 32, 'matching_alnum_words': 5, 'matching_words': 5, 'alnum_word_accuracy': 0.625, 'word_accuracy': 0.625, 'char_accuracy': 0.9142857142857143}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 47, 'total_words': 7, 'total_alnum_words': 7, 'matching_chars': 47, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 47, 'total_words': 7, 'total_alnum_words': 7, 'matching_chars': 47, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 47, 'total_words': 7, 'total_alnum_words': 7, 'matching_chars': 47, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 30, 'total_words': 3, 'total_alnum_words': 3, 'matching_chars': 30, 'matching_alnum_words': 3, 'matching_words': 3, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 30, 'total_words': 3, 'total_alnum_words': 3, 'matching_chars': 30, 'matching_alnum_words': 3, 'matching_words': 3, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 30, 'total_words': 3, 'total_alnum_words': 3, 'matching_chars': 30, 'matching_alnum_words': 3, 'matching_words': 3, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 36, 'total_words': 7, 'total_alnum_words': 7, 'matching_chars': 36, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 36, 'total_words': 7, 'total_alnum_words': 7, 'matching_chars': 36, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 36, 'total_words': 7, 'total_alnum_words': 7, 'matching_chars': 36, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 49, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 49, 'matching_alnum_words': 8, 'matching_words': 8, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 49, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 49, 'matching_alnum_words': 8, 'matching_words': 8, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 49, 'total_words': 8, 'total_alnum_words': 8, 'matching_chars': 49, 'matching_alnum_words': 8, 'matching_words': 8, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 48, 'total_words': 9, 'total_alnum_words': 9, 'matching_chars': 48, 'matching_alnum_words': 9, 'matching_words': 9, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 48, 'total_words': 9, 'total_alnum_words': 9, 'matching_chars': 48, 'matching_alnum_words': 9, 'matching_words': 9, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 48, 'total_words': 9, 'total_alnum_words': 9, 'matching_chars': 48, 'matching_alnum_words': 9, 'matching_words': 9, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 48, 'total_words': 7, 'total_alnum_words': 7, 'matching_chars': 48, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 48, 'total_words': 7, 'total_alnum_words': 7, 'matching_chars': 48, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 0, 'edit_replace': 0, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 0, 'delete': 0, 'replace': 0, 'spacing': 0, 'total_chars': 48, 'total_words': 7, 'total_alnum_words': 7, 'matching_chars': 48, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 1.0, 'word_accuracy': 1.0, 'char_accuracy': 1.0}\n",
      "18 {'edit_insert': 0, 'edit_delete': 2, 'edit_replace': 1, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 1, 'delete': 2, 'replace': 0, 'spacing': 0, 'total_chars': 55, 'total_words': 12, 'total_alnum_words': 12, 'matching_chars': 52, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 0.5833333333333334, 'word_accuracy': 0.5833333333333334, 'char_accuracy': 0.9454545454545454}\n",
      "18 {'edit_insert': 0, 'edit_delete': 2, 'edit_replace': 1, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 1, 'delete': 2, 'replace': 0, 'spacing': 0, 'total_chars': 55, 'total_words': 12, 'total_alnum_words': 12, 'matching_chars': 52, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 0.5833333333333334, 'word_accuracy': 0.5833333333333334, 'char_accuracy': 0.9454545454545454}\n",
      "18 {'edit_insert': 0, 'edit_delete': 2, 'edit_replace': 1, 'edit_insert_spacing': 0, 'edit_delete_spacing': 0, 'insert': 1, 'delete': 2, 'replace': 0, 'spacing': 0, 'total_chars': 55, 'total_words': 12, 'total_alnum_words': 12, 'matching_chars': 52, 'matching_alnum_words': 7, 'matching_words': 7, 'alnum_word_accuracy': 0.5833333333333334, 'word_accuracy': 0.5833333333333334, 'char_accuracy': 0.9454545454545454}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "one of the input strings is empty",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/rv/x6hk7f3j7dzb763m4m3kgmb00000gp/T/ipykernel_81755/2577569307.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     20\u001B[0m                                                                  x[f'ocr.{segment_type}']), axis=1)\n\u001B[1;32m     21\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m         \u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmetrics_char\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mrow\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0malign_texts\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'groundtruth.line'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrow\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'ocr.line'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36mapply\u001B[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001B[0m\n\u001B[1;32m   8846\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8847\u001B[0m         )\n\u001B[0;32m-> 8848\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__finalize__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"apply\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   8849\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   8850\u001B[0m     def applymap(\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001B[0m in \u001B[0;36mapply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    731\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_raw\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    732\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 733\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_standard\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    734\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    735\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0magg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001B[0m in \u001B[0;36mapply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    855\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    856\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mapply_standard\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 857\u001B[0;31m         \u001B[0mresults\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mres_index\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_series_generator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    858\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    859\u001B[0m         \u001B[0;31m# wrap results\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001B[0m in \u001B[0;36mapply_series_generator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    871\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mseries_gen\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    872\u001B[0m                 \u001B[0;31m# ignore SettingWithCopy here in case the user mutates\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 873\u001B[0;31m                 \u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    874\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mABCSeries\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    875\u001B[0m                     \u001B[0;31m# If we have a view on v, we need to make a copy because\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/rv/x6hk7f3j7dzb763m4m3kgmb00000gp/T/ipykernel_81755/2577569307.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(row)\u001B[0m\n\u001B[1;32m     20\u001B[0m                                                                  x[f'ocr.{segment_type}']), axis=1)\n\u001B[1;32m     21\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m         \u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmetrics_char\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mrow\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0malign_texts\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'groundtruth.line'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrow\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'ocr.line'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/rv/x6hk7f3j7dzb763m4m3kgmb00000gp/T/ipykernel_81755/2404584667.py\u001B[0m in \u001B[0;36malign_texts\u001B[0;34m(gt_text, ocr_text)\u001B[0m\n\u001B[1;32m     15\u001B[0m         \u001B[0maligned_gt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maligned_noise\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgt_text\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mocr_text\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m     \u001B[0mstats\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_stats\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgt_text\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mocr_text\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0mstats\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstats\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmetrics_char\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/gpt-text-correction/notebooks/metrics.py\u001B[0m in \u001B[0;36mget_stats\u001B[0;34m(target, src_string)\u001B[0m\n\u001B[1;32m    696\u001B[0m     )\n\u001B[1;32m    697\u001B[0m     \u001B[0malignment\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0malign_w_anchor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc_string\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgap_char\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mgap_char\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 698\u001B[0;31m     align_stats, substitution_dict = get_align_stats(\n\u001B[0m\u001B[1;32m    699\u001B[0m         \u001B[0malignment\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msrc_string\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgap_char\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    700\u001B[0m     )\n",
      "\u001B[0;32m~/projects/gpt-text-correction/notebooks/metrics.py\u001B[0m in \u001B[0;36mget_align_stats\u001B[0;34m(alignment, src_string, target, gap_char)\u001B[0m\n\u001B[1;32m    664\u001B[0m     \"\"\"\n\u001B[1;32m    665\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0msrc_string\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstrip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"\"\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstrip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 666\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"one of the input strings is empty\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    667\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    668\u001B[0m     \u001B[0m_log\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"alignment results\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: one of the input strings is empty"
     ]
    }
   ],
   "source": [
    "# Define OCR noise level bins\n",
    "bins = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 1]\n",
    "\n",
    "# Assign OCR noise level labels\n",
    "labels = [\"0-10%\", \"10-20%\", \"20-30%\", \"30-40%\", \"40-50%\", \"50-100%\"]\n",
    "\n",
    "for idx, result in enumerate(results):\n",
    "    \n",
    "#     results[idx] = results[idx].fillna('No text')\n",
    "    \n",
    "    \n",
    "    for segment_type in ['line', 'sentence', 'region']:\n",
    "        \n",
    "        results[idx]['length'] = results[idx][f'groundtruth.{segment_type}'].str.len()\n",
    "        results[idx] = results[idx][results[idx]['length'] > 3]\n",
    "        \n",
    "        \n",
    "        results[idx][f'{segment_type}-ocr-level'] = \\\n",
    "            results[idx].apply(lambda x: compute_ocr_noise_level(x[f'groundtruth.{segment_type}'],\n",
    "                                                                 x[f'ocr.{segment_type}']), axis=1)\n",
    "        \n",
    "        results[idx][metrics_char] = results[idx].apply(lambda row: pd.Series(align_texts(row[f'groundtruth.{segment_type}'], \n",
    "                                                                                          row[f'ocr.{segment_type}'])), axis=1)\n",
    "\n",
    "        \n",
    "        results[idx].apply(lambda x: pd.Series(align_texts(x[f'groundtruth.{segment_type}'], x[f'prediction.{segment_type}'])), axis=1)\n",
    "        \n",
    "        results[idx][f'{segment_type}-ground-ocr'] = \\\n",
    "            results[idx].apply(lambda x: compute_normalized_levenshtein_distance(x[f'groundtruth.{segment_type}'],\n",
    "                                                                      x[f'ocr.{segment_type}']), axis=1)\n",
    "        results[idx][f'{segment_type}-ground-pred'] = \\\n",
    "            results[idx].apply(lambda x: compute_normalized_levenshtein_distance(x[f'groundtruth.{segment_type}'],\n",
    "                                                                      x[f'prediction.{segment_type}']), axis=1)\n",
    "\n",
    "        results[idx][f'{segment_type}-improvement'] = \\\n",
    "            results[idx].apply(lambda x: get_improvement(x[f'{segment_type}-ground-ocr'],\n",
    "                                                         x[f'{segment_type}-ground-pred']), axis=1)\n",
    "        \n",
    "        # Create a new column for the OCR noise level bins\n",
    "        results[idx][f\"{segment_type}-ocr-noise-group\"] = pd.cut(results[idx][f'{segment_type}-ocr-level'], \n",
    "                                                 bins=bins, labels=labels, \n",
    "                                                 include_lowest=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ced908",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, result in enumerate(results):\n",
    "    for segment_type in ['line', 'sentence', 'region']:\n",
    "        improved_texts = result[result[f'{segment_type}-improvement'] >= 0.0]\n",
    "        for _, improved_text in improved_texts.iterrows():\n",
    "            print('Improvement:', improved_text[f'{segment_type}-improvement'])\n",
    "            print(improved_text[f'groundtruth.{segment_type}'][:50])\n",
    "            print(improved_text[f'ocr.{segment_type}'][:50])\n",
    "            print(improved_text[f'prediction.{segment_type}'][:50])\n",
    "            print('--'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ff7967",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547cc7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0902d03b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Set the colorblind color palette\n",
    "sns.set_palette(\"colorblind\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "for result in results:\n",
    "    \n",
    "    dataset_name = result['dataset_name'].unique()[0]\n",
    "    lm_name = result['LM'].unique()[0]\n",
    "    \n",
    "    for segment_type in ['line', 'sentence', 'region']:\n",
    "        \n",
    "        #grouped_results = result.groupby([f\"{segment_type}-ocr-noise-group\", \"dataset_name\"]).size().reset_index(name=\"count\")\n",
    "        \n",
    "        grouped_results = result.groupby([f\"{segment_type}-ocr-noise-group\", \"dataset_name\"])[f\"{segment_type}-improvement\"].mean().reset_index()\n",
    "\n",
    "        print(grouped_results.head())\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        # Set the y-axis limits\n",
    "        ax.set_ylim(-1, 1)\n",
    "        \n",
    "        _ = sns.lineplot(x=f\"{segment_type}-ocr-noise-group\", y=f'{segment_type}-improvement', hue='dataset_name',\n",
    "                 data=grouped_results, ax=ax, markers=True, linestyle='-', linewidth=2.5)\n",
    "\n",
    "        # Set plot labels\n",
    "        ax.set_xlabel(f\"{lm_name}: Ground Truth {segment_type.capitalize()}\")\n",
    "        ax.set_ylabel(f\"{lm_name}: {segment_type.capitalize()} Improvement\")\n",
    "        ax.set_title(f\"{lm_name}: Levenshtein Improvement for {segment_type.capitalize()} OCR Examples\")\n",
    "\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        \n",
    "#         # Create the line plot\n",
    "#         fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "#         sns.lineplot(x=f\"groundtruth.{segment_type}\", y=f\"{segment_type}-improvement\", hue='dataset_name',\n",
    "#                     data=result, ax=ax)\n",
    "\n",
    "#         # Set plot labels\n",
    "#         ax.set_xlabel(f\"Ground Truth {segment_type.capitalize()}\")\n",
    "#         ax.set_ylabel(f\"{segment_type.capitalize()} Improvement\")\n",
    "#         ax.set_title(f\"Levenshtein Improvement for {segment_type.capitalize()} OCR Examples\")\n",
    "\n",
    "\n",
    "#         # Show the plot\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe33cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86be95c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7be3f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, result in enumerate(results):\n",
    "    \n",
    "    results[idx] = results[idx].fillna('No text')\n",
    "    \n",
    "    def replace(x):\n",
    "        if len(x.strip()) == 0:\n",
    "            return 'No text'\n",
    "        return x\n",
    "    \n",
    "    for column in results[idx].columns:\n",
    "        results[idx][column] = results[idx][column].apply(lambda x: replace(x))\n",
    "        \n",
    "    #results[idx][['groundtruth.line', 'ocr.line']] = results[idx].apply(lambda x: align_texts(x['groundtruth.line'], \n",
    "    #                                                                                        x['ocr.line']), axis=1)\n",
    "    print('--'*40, idx)\n",
    "    print(results[idx][['groundtruth.line', 'prediction.line']])\n",
    "    results[idx][['groundtruth.line', 'prediction.line']] = results[idx].apply(lambda x: align_texts(x['groundtruth.line'], \n",
    "                                                                                                     x['prediction.line']), axis=1)\n",
    "    \n",
    "#     x = results[idx].apply(lambda x: levenshtein(x['groundtruth.line'].split(), \n",
    "#                                                             x['ocr.line'].split()), axis=1)\n",
    "#     x = results[idx].apply(lambda x: levenshtein(x['groundtruth.sentence'].split(), \n",
    "#                                                                 x['ocr.sentence'].split()), axis=1)\n",
    "#     x = results[idx].apply(lambda x: levenshtein(x['groundtruth.region'].split(), \n",
    "#                                                               x['ocr.region'].split()), axis=1)\n",
    "    #print(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaedac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f04a736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae27e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18099c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a17d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe6e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d62894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[idx]['ocr.line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c0223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[idx]['ocr.sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc777d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[idx]['ocr.region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351b194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01acbb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ht_raw = \" \".join(df['ocr.sentence'].to_list())\n",
    "# print(f\"{len(set(ht_raw.lower()))} characters in human transcription\")\n",
    "# print(f\"The following characters have not been system-transcribed: \\n{set(ht_raw.lower())-set(st_raw.lower())}\")\n",
    "tokens = ht_raw.split()\n",
    "WORDS = set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1704285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eddi(input_text, reference_words=WORDS, ed_threshold=25, max_unk_tokens=3):\n",
    "    \"\"\" Baseline I: Edit distance -based Baseline\n",
    "    An edit distance-based baseline: Given a list of valid (reference) words,\n",
    "    this baseline (called eddi) detects words not in the reference list and \n",
    "    changes them to the closest one in the reference list.\n",
    "    :param input_text: the source text\n",
    "    :param reference_words: a list of valid words (e.g., computed from the target data) \n",
    "    :param ed_threshold: the edit distance threshold below from which a word is replaced\n",
    "    :param max_unk_tokens: the max number of unknown tokens in the transcribed text \n",
    "    :return: the new text\n",
    "    \"\"\"\n",
    "    tokens = input_text.split()\n",
    "    # Unknown transcribed tokens; proceed only if few\n",
    "    unknowns = [i for i, w in enumerate(tokens) if w not in reference_words]\n",
    "    if len(unknowns) > max_unk_tokens:\n",
    "        return \" \".join(tokens)\n",
    "\n",
    "    for ind in unknowns:\n",
    "        # Replace each uknown token with the ground truth token w/min edit distance \n",
    "        word = tokens[ind]\n",
    "        min_cer, new_word = 100, word\n",
    "        for ref in reference_words:\n",
    "            candidate_min_cer = pywer.cer([ref], [word])\n",
    "            if candidate_min_cer < min_cer:\n",
    "                min_cer = candidate_min_cer\n",
    "                if min_cer < ed_threshold:\n",
    "                    new_word = ref\n",
    "    tokens[ind] = new_word\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab1d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b6097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ff5018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f60dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e38d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d142c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
