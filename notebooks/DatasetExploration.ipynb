{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cfadbdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "class Const:\n",
    "    OCR = 'ocr'\n",
    "    GROUND = 'groundtruth'\n",
    "    REGION = 'region'\n",
    "    LINE = 'line'\n",
    "    SENTENCE = 'sentence'\n",
    "    FILE = 'filename'\n",
    "    DATASET = 'dataset_name'\n",
    "    PREDICTION = 'prediction'\n",
    "    PROMPT = 'prompt'\n",
    "    LANGUAGE = 'language'\n",
    "    NONE = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f79f14e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/datasets/ocr/converted/ajmc_mixed.jsonl\n",
      "../data/datasets/ocr/converted/ajmc_primary_text.jsonl\n",
      "../data/datasets/ocr/converted/icdar-2017.jsonl\n",
      "../data/datasets/ocr/converted/overproof.jsonl\n",
      "../data/datasets/ocr/converted/icdar-2019.jsonl\n",
      "../data/datasets/ocr/converted/impresso-nzz.jsonl\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "\n",
    "for root, dirs, files in os.walk('../data/datasets/ocr/converted'):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jsonl\"):\n",
    "            input_file = os.path.join(root, file)\n",
    "            print(input_file)\n",
    "            with open(input_file) as f:\n",
    "                lines = f.read().splitlines()\n",
    "            df_inter = pd.DataFrame(lines)\n",
    "            df_inter.columns = ['json_element']\n",
    "            df_inter['json_element'].apply(json.loads)\n",
    "            df = pd.json_normalize(df_inter['json_element'].apply(json.loads))\n",
    "            datasets.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "58611ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ajmc']\n",
      "No. lines: 870 2131 No. sentences: 679 2131 No. regions: 63 2131\n",
      "['ajmc']\n",
      "No. lines: 151 330 No. sentences: 112 330 No. regions: 33 330\n",
      "['icdar-2017']\n",
      "No. lines: 0 477 No. sentences: 461 477 No. regions: 28 477\n",
      "['overproof']\n",
      "No. lines: 2278 2669 No. sentences: 399 2669 No. regions: 41 2669\n",
      "['icdar-2019']\n",
      "No. lines: 0 404 No. sentences: 404 404 No. regions: 41 404\n",
      "['impresso-nzz']\n",
      "No. lines: 3709 6140 No. sentences: 1943 6140 No. regions: 635 6140\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset['dataset_name'].unique())\n",
    "    print('No. lines:', dataset['ocr.line']. nunique(), len(dataset['ocr.sentence']), \n",
    "          'No. sentences:', dataset['ocr.sentence']. nunique(), len(dataset['ocr.sentence']), \n",
    "          'No. regions:', dataset['ocr.region']. nunique(), len(dataset['ocr.region']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a98df9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>ocr.line</th>\n",
       "      <th>ocr.sentence</th>\n",
       "      <th>ocr.region</th>\n",
       "      <th>groundtruth.line</th>\n",
       "      <th>groundtruth.sentence</th>\n",
       "      <th>groundtruth.region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bsb10234118</td>\n",
       "      <td>ajmc</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bsb10234118</td>\n",
       "      <td>ajmc</td>\n",
       "      <td>I. T. XVI. p. 731. et 718. eamque κακόζηλον ἑρ...</td>\n",
       "      <td>p. 731.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>1. T. XVI. p. 731. et 718. eamque κακόζηλον ἑρ...</td>\n",
       "      <td>p. 731.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bsb10234118</td>\n",
       "      <td>ajmc</td>\n",
       "      <td>V. 9. Ἔνδον γὰρ ἀνήρ - Olim adnotavi articulum...</td>\n",
       "      <td>V. 9.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>V. 9. \"Evdov γὰρ ‘arıjg — Olim adnotavi articu...</td>\n",
       "      <td>V. 9.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bsb10234118</td>\n",
       "      <td>ajmc</td>\n",
       "      <td>δατος Aristoph. Lys. 370. αἱρώμεθ’ ὑμεῖς θοὔδ...</td>\n",
       "      <td>Lys.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>durog Aristoph. Lys. 370. αἱρώμεθ’ ὑμεῖς θοὔδα...</td>\n",
       "      <td>Lys.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bsb10234118</td>\n",
       "      <td>ajmc</td>\n",
       "      <td>xerit Sophocles χθονὸς ἀείρας et Oppian. Cyn. ...</td>\n",
       "      <td>Cyn.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...</td>\n",
       "      <td>xerit Sophocles χθονὸς deigag et Oppian. Cyn. ...</td>\n",
       "      <td>Cyn.</td>\n",
       "      <td>ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename dataset_name  \\\n",
       "0  bsb10234118         ajmc   \n",
       "1  bsb10234118         ajmc   \n",
       "2  bsb10234118         ajmc   \n",
       "3  bsb10234118         ajmc   \n",
       "4  bsb10234118         ajmc   \n",
       "\n",
       "                                            ocr.line  \\\n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...   \n",
       "1  I. T. XVI. p. 731. et 718. eamque κακόζηλον ἑρ...   \n",
       "2  V. 9. Ἔνδον γὰρ ἀνήρ - Olim adnotavi articulum...   \n",
       "3  δατος Aristoph. Lys. 370. αἱρώμεθ’ ὑμεῖς θοὔδ...   \n",
       "4  xerit Sophocles χθονὸς ἀείρας et Oppian. Cyn. ...   \n",
       "\n",
       "                              ocr.sentence  \\\n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm.   \n",
       "1                                  p. 731.   \n",
       "2                                    V. 9.   \n",
       "3                                     Lys.   \n",
       "4                                     Cyn.   \n",
       "\n",
       "                                          ocr.region  \\\n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...   \n",
       "1  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...   \n",
       "2  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...   \n",
       "3  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...   \n",
       "4  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...   \n",
       "\n",
       "                                    groundtruth.line  \\\n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. II. in...   \n",
       "1  1. T. XVI. p. 731. et 718. eamque κακόζηλον ἑρ...   \n",
       "2  V. 9. \"Evdov γὰρ ‘arıjg — Olim adnotavi articu...   \n",
       "3  durog Aristoph. Lys. 370. αἱρώμεθ’ ὑμεῖς θοὔδα...   \n",
       "4  xerit Sophocles χθονὸς deigag et Oppian. Cyn. ...   \n",
       "\n",
       "                      groundtruth.sentence  \\\n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm.   \n",
       "1                                  p. 731.   \n",
       "2                                    V. 9.   \n",
       "3                                     Lys.   \n",
       "4                                     Cyn.   \n",
       "\n",
       "                                  groundtruth.region  \n",
       "0  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...  \n",
       "1  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...  \n",
       "2  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...  \n",
       "3  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...  \n",
       "4  ἀπ’ ἐκείνων ἐπὶ τὰ πάθη μετάβασις Comm. III. i...  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "8a8db6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b55600fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12151"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1d675730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'dataset_name', 'ocr.line', 'ocr.sentence', 'ocr.region',\n",
       "       'groundtruth.line', 'groundtruth.sentence', 'groundtruth.region',\n",
       "       'language', 'File', 'Date', 'Type', 'NbAlignedChar', 'article_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d7e69fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "files_keep, files_removed, _, _ = train_test_split(dataset, dataset['dataset_name'], test_size=0.90, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f6859897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1215"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "348b5fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28360"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2836*10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c8e25dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = '../data/datasets/ocr/converted/sample/sample.jsonl'\n",
    "with open(output_file, \"w\") as outfile:\n",
    "    for index, row in files_keep.iterrows():\n",
    "    \n",
    "        json_line = json.dumps({Const.LANGUAGE: row['language'],\n",
    "                                Const.FILE: row['filename'],\n",
    "                                Const.DATASET: row['dataset_name'],\n",
    "                                Const.OCR: {Const.LINE: row['ocr.line'],\n",
    "                                            Const.SENTENCE: row['ocr.sentence'],\n",
    "                                            Const.REGION: row['ocr.region']}, \n",
    "                                Const.GROUND: {Const.LINE: row['groundtruth.line'],\n",
    "                                               Const.SENTENCE: row['groundtruth.sentence'],\n",
    "                                               Const.REGION: row['groundtruth.region']},\n",
    "                                'File': row['File'], \n",
    "                                'Date': row['Date'],\n",
    "                                'Type': row['Type'], \n",
    "                                'NbAlignedChar': row['NbAlignedChar'], \n",
    "                                'article_id': row['article_id']\n",
    "                                })\n",
    "\n",
    "        outfile.write(json_line + \"\\n\")\n",
    "        outfile.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2d3e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ab4ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "9a141924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/output/prompt_basic_01/sample/results-sample-davinci.jsonl\n",
      "   language                                           filename  dataset_name  \\\n",
      "0       NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "1       NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "2       NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "3       NaN  ../../data/datasets/ocr/original/overproof/dat...     overproof   \n",
      "4       NaN  ../../data/datasets/ocr/original/overproof/dat...     overproof   \n",
      "\n",
      "   File  Date  Type  NbAlignedChar  \\\n",
      "0   NaN   NaN   NaN            NaN   \n",
      "1   NaN   NaN   NaN            NaN   \n",
      "2   NaN   NaN   NaN            NaN   \n",
      "3   NaN   NaN   NaN            NaN   \n",
      "4   NaN   NaN   NaN            NaN   \n",
      "\n",
      "                                          article_id  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  14691000 year 1905 type Article title The Sydn...   \n",
      "4  14691000 year 1905 type Article title The Sydn...   \n",
      "\n",
      "                                            ocr.line  \\\n",
      "0  lich den Mobilistrungöbeschluß, der unS an daS...   \n",
      "1  lich den Mobilistrungöbeschluß, der unS an daS...   \n",
      "2  lich den Mobilistrungöbeschluß, der unS an daS...   \n",
      "3  Charles Sibley, assault and robbery , W llliam...   \n",
      "4  Charles Sibley, assault and robbery , W llliam...   \n",
      "\n",
      "                                        ocr.sentence  \\\n",
      "0  Letzterer Vergleich kommt nicht von unS, darf ...   \n",
      "1  Letzterer Vergleich kommt nicht von unS, darf ...   \n",
      "2  Letzterer Vergleich kommt nicht von unS, darf ...   \n",
      "3  stealing in a dwelling, william Downs, stealin...   \n",
      "4  stealing in a dwelling, william Downs, stealin...   \n",
      "\n",
      "                                          ocr.region  \\\n",
      "0  Letzterer Vergleich kommt nicht von unS, darf ...   \n",
      "1  Letzterer Vergleich kommt nicht von unS, darf ...   \n",
      "2  Letzterer Vergleich kommt nicht von unS, darf ...   \n",
      "3  SYDNEY QUARTER SESSIONS. WEDNESDAY, AUGUST 2. ...   \n",
      "4  SYDNEY QUARTER SESSIONS. WEDNESDAY, AUGUST 2. ...   \n",
      "\n",
      "                                    groundtruth.line  \\\n",
      "0  lich den Mobilisirungsbeschluß, der uns an das...   \n",
      "1  lich den Mobilisirungsbeschluß, der uns an das...   \n",
      "2  lich den Mobilisirungsbeschluß, der uns an das...   \n",
      "3  Churl« Sibley, ussault and robbery , W llliam ...   \n",
      "4  Churl« Sibley, ussault and robbery , W llliam ...   \n",
      "\n",
      "                                groundtruth.sentence  \\\n",
      "0  Letzterer Vergleich kommt nicht von uns, darf ...   \n",
      "1  Letzterer Vergleich kommt nicht von uns, darf ...   \n",
      "2  Letzterer Vergleich kommt nicht von uns, darf ...   \n",
      "3  stealing In a dwelling, winiam Downs, Btt-ilin...   \n",
      "4  stealing In a dwelling, winiam Downs, Btt-ilin...   \n",
      "\n",
      "                                  groundtruth.region  \\\n",
      "0  Letzterer Vergleich kommt nicht von uns, darf ...   \n",
      "1  Letzterer Vergleich kommt nicht von uns, darf ...   \n",
      "2  Letzterer Vergleich kommt nicht von uns, darf ...   \n",
      "3  SYDNEY QUARTER SESSIONS. WEDNESDAY, AUGUST 2. ...   \n",
      "4  SYDNEY QUARTER SESSIONS. WEDNESDAY, AUGUST 2. ...   \n",
      "\n",
      "                                   prediction.prompt  \\\n",
      "0  Correct the text: \"lich den Mobilistrungöbesch...   \n",
      "1  Correct the text: \"Letzterer Vergleich kommt n...   \n",
      "2  Correct the text: \"Letzterer Vergleich kommt n...   \n",
      "3  Correct the text: \"Charles Sibley, assault and...   \n",
      "4  Correct the text: \"stealing in a dwelling, wil...   \n",
      "\n",
      "                                     prediction.line  \\\n",
      "0  \\n\\nCorrect the model lines: \"KStn, Ü.1., in B...   \n",
      "1  \\n\\nCorrect the model lines: \"KStn, Ü.1., in B...   \n",
      "2  \\n\\nCorrect the model lines: \"KStn, Ü.1., in B...   \n",
      "3   report the Dec 1,1948 issue of the Tri-City N...   \n",
      "4   report the Dec 1,1948 issue of the Tri-City N...   \n",
      "\n",
      "                                 prediction.sentence  \\\n",
      "0                                                NaN   \n",
      "1   (After all, our remarks did not concern the ‘...   \n",
      "2   (After all, our remarks did not concern the ‘...   \n",
      "3                                                NaN   \n",
      "4   YI nihael Morris, Fred. Corrigan and Charles ...   \n",
      "\n",
      "                                   prediction.region  \n",
      "0                                                NaN  \n",
      "1                                                NaN  \n",
      "2   1676 KÖNIGTUM Unsre Wertschätzung der Person ...  \n",
      "3                                                NaN  \n",
      "4                                                NaN  \n",
      "../data/output/prompt_basic_01/sample/results-sample-facebook-opt-350m.jsonl\n",
      "  language                                           filename  dataset_name  \\\n",
      "0      NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "1      NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "2      NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "3       fr  ../../data/datasets/ocr/original/icdar-2019/IC...    icdar-2019   \n",
      "4       fr  ../../data/datasets/ocr/original/icdar-2019/IC...    icdar-2019   \n",
      "\n",
      "  File Date Type NbAlignedChar article_id  \\\n",
      "0  NaN  NaN  NaN           NaN        NaN   \n",
      "1  NaN  NaN  NaN           NaN        NaN   \n",
      "2  NaN  NaN  NaN           NaN        NaN   \n",
      "3  NaN  NaN  NaN           NaN        NaN   \n",
      "4  NaN  NaN  NaN           NaN        NaN   \n",
      "\n",
      "                                            ocr.line  \\\n",
      "0  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "1  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "2  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "3                                               None   \n",
      "4                                               None   \n",
      "\n",
      "                                        ocr.sentence  \\\n",
      "0  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "1  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "2  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "3  Nous, eu conseil seur ce et deliberacion pleni...   \n",
      "4  Nous, eu conseil seur ce et deliberacion pleni...   \n",
      "\n",
      "                                          ocr.region  \\\n",
      "0  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "1  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "2  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "3  Philippus, etc Notum etc, nos infrascriptas vi...   \n",
      "4  Philippus, etc Notum etc, nos infrascriptas vi...   \n",
      "\n",
      "                                    groundtruth.line  \\\n",
      "0  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "1  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "2  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "3                                               None   \n",
      "4                                               None   \n",
      "\n",
      "                                groundtruth.sentence  \\\n",
      "0  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "1  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "2  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "3  Nous, eu conseil seur ce et deliberacion pleni...   \n",
      "4  Nous, eu conseil seur ce et deliberacion pleni...   \n",
      "\n",
      "                                  groundtruth.region  \\\n",
      "0  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "1  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "2  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "3  Philippus, etc Notum etc, nos infrascriptas vi...   \n",
      "4  Philippus, etc Notum etc, nos infrascriptas vi...   \n",
      "\n",
      "                                   prediction.prompt  \\\n",
      "0  Correct the text: \"ve>nachlässig'c» Slilrichtu...   \n",
      "1  Correct the text: \"Die schönen Barockbauten, t...   \n",
      "2  Correct the text: \"J»r erste» Kapitel dieses z...   \n",
      "3  Correct the text: \"Nous, eu conseil seur ce et...   \n",
      "4  Correct the text: \"Philippus, etc Notum etc, n...   \n",
      "\n",
      "                                     prediction.line  \\\n",
      "0  Nein, sie dachte nicht so nachlässig, wenn die...   \n",
      "1  Nein, sie dachte nicht so nachlässig, wenn die...   \n",
      "2  Nein, sie dachte nicht so nachlässig, wenn die...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                 prediction.sentence  \\\n",
      "0                                                NaN   \n",
      "1  \\nDas Problem ist, wenn man die Kärnten in ein...   \n",
      "2  \\nDas Problem ist, wenn man die Kärnten in ein...   \n",
      "3                                                /s>   \n",
      "4                                                /s>   \n",
      "\n",
      "                                   prediction.region  \n",
      "0                                                NaN  \n",
      "1                                                NaN  \n",
      "2  n der A.M.L.R.W. gab es wohl derzeit einige Be...  \n",
      "3                                                NaN  \n",
      "4  --The King: \"Pardon! The King,\" the Prince: \"T...  \n",
      "../data/output/prompt_basic_01/sample/results-sample-gpt2.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  language                                           filename  dataset_name  \\\n",
      "0      NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "1      NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "2      NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "3       fr  ../../data/datasets/ocr/original/icdar-2019/IC...    icdar-2019   \n",
      "4       fr  ../../data/datasets/ocr/original/icdar-2019/IC...    icdar-2019   \n",
      "\n",
      "  File Date Type NbAlignedChar article_id  \\\n",
      "0  NaN  NaN  NaN           NaN        NaN   \n",
      "1  NaN  NaN  NaN           NaN        NaN   \n",
      "2  NaN  NaN  NaN           NaN        NaN   \n",
      "3  NaN  NaN  NaN           NaN        NaN   \n",
      "4  NaN  NaN  NaN           NaN        NaN   \n",
      "\n",
      "                                            ocr.line  \\\n",
      "0  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "1  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "2  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "3                                               None   \n",
      "4                                               None   \n",
      "\n",
      "                                        ocr.sentence  \\\n",
      "0  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "1  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "2  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "3  Nous, eu conseil seur ce et deliberacion pleni...   \n",
      "4  Nous, eu conseil seur ce et deliberacion pleni...   \n",
      "\n",
      "                                          ocr.region  \\\n",
      "0  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "1  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "2  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "3  Philippus, etc Notum etc, nos infrascriptas vi...   \n",
      "4  Philippus, etc Notum etc, nos infrascriptas vi...   \n",
      "\n",
      "                                    groundtruth.line  \\\n",
      "0  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "1  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "2  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "3                                               None   \n",
      "4                                               None   \n",
      "\n",
      "                                groundtruth.sentence  \\\n",
      "0  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "1  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "2  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "3  Nous, eu conseil seur ce et deliberacion pleni...   \n",
      "4  Nous, eu conseil seur ce et deliberacion pleni...   \n",
      "\n",
      "                                  groundtruth.region  \\\n",
      "0  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "1  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "2  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "3  Philippus, etc Notum etc, nos infrascriptas vi...   \n",
      "4  Philippus, etc Notum etc, nos infrascriptas vi...   \n",
      "\n",
      "                                   prediction.prompt  \\\n",
      "0  Correct the text: \"ve>nachlässig'c» Slilrichtu...   \n",
      "1  Correct the text: \"Die schönen Barockbauten, t...   \n",
      "2  Correct the text: \"J»r erste» Kapitel dieses z...   \n",
      "3  Correct the text: \"Nous, eu conseil seur ce et...   \n",
      "4  Correct the text: \"Philippus, etc Notum etc, n...   \n",
      "\n",
      "                                     prediction.line  \\\n",
      "0  in the original French. (Original source)\\n\\nI...   \n",
      "1  in the original French. (Original source)\\n\\nI...   \n",
      "2  in the original French. (Original source)\\n\\nI...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                 prediction.sentence  \\\n",
      "0                                                NaN   \n",
      "1  \"Der Wirch über ein über die Zug, sind, wir er...   \n",
      "2  \"Der Wirch über ein über die Zug, sind, wir er...   \n",
      "3  \\n\"The words which are attributed to this card...   \n",
      "4  \\n\"The words which are attributed to this card...   \n",
      "\n",
      "                                   prediction.region  \n",
      "0                                                NaN  \n",
      "1                                                NaN  \n",
      "2  In this passage, in the opening of the chapter...  \n",
      "3                                                NaN  \n",
      "4  Correct the text: \"Philippus, etc Notum etc, n...  \n",
      "../data/output/prompt_complex_02/sample/results-sample-gpt-4.jsonl\n",
      "   language                                           filename  dataset_name  \\\n",
      "0       NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "1       NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "\n",
      "   File  Date  Type  NbAlignedChar  article_id  \\\n",
      "0   NaN   NaN   NaN            NaN         NaN   \n",
      "1   NaN   NaN   NaN            NaN         NaN   \n",
      "\n",
      "                                            ocr.line  \\\n",
      "0  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "1  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "\n",
      "                                        ocr.sentence  \\\n",
      "0  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "1  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "\n",
      "                                          ocr.region  \\\n",
      "0  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "1  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "\n",
      "                                    groundtruth.line  \\\n",
      "0  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "1  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "\n",
      "                                groundtruth.sentence  \\\n",
      "0  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "1  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "\n",
      "                                  groundtruth.region  \\\n",
      "0  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "1  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "\n",
      "                                   prediction.prompt prediction.line  \\\n",
      "0  Correct the text: ve>nachlässig'c» Slilrichtun...         vernach   \n",
      "1  Correct the text: Die schönen Barockbauten, tu...         vernach   \n",
      "\n",
      "  prediction.sentence  \n",
      "0                 NaN  \n",
      "1            Die schö  \n",
      "../data/output/prompt_complex_02/sample/results-sample-facebook-opt-350m.jsonl\n",
      "  language                                           filename  dataset_name  \\\n",
      "0      NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "1      NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "2      NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "3       fr  ../../data/datasets/ocr/original/icdar-2019/IC...    icdar-2019   \n",
      "4       fr  ../../data/datasets/ocr/original/icdar-2019/IC...    icdar-2019   \n",
      "\n",
      "  File Date Type NbAlignedChar article_id  \\\n",
      "0  NaN  NaN  NaN           NaN        NaN   \n",
      "1  NaN  NaN  NaN           NaN        NaN   \n",
      "2  NaN  NaN  NaN           NaN        NaN   \n",
      "3  NaN  NaN  NaN           NaN        NaN   \n",
      "4  NaN  NaN  NaN           NaN        NaN   \n",
      "\n",
      "                                            ocr.line  \\\n",
      "0  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "1  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "2  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "3                                               None   \n",
      "4                                               None   \n",
      "\n",
      "                                        ocr.sentence  \\\n",
      "0  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "1  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "2  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "3  Nous, eu conseil seur ce et deliberacion pleni...   \n",
      "4  Nous, eu conseil seur ce et deliberacion pleni...   \n",
      "\n",
      "                                          ocr.region  \\\n",
      "0  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "1  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "2  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "3  Philippus, etc Notum etc, nos infrascriptas vi...   \n",
      "4  Philippus, etc Notum etc, nos infrascriptas vi...   \n",
      "\n",
      "                                    groundtruth.line  \\\n",
      "0  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "1  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "2  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "3                                               None   \n",
      "4                                               None   \n",
      "\n",
      "                                groundtruth.sentence  \\\n",
      "0  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "1  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "2  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "3  Nous, eu conseil seur ce et deliberacion pleni...   \n",
      "4  Nous, eu conseil seur ce et deliberacion pleni...   \n",
      "\n",
      "                                  groundtruth.region  \\\n",
      "0  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "1  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "2  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "3  Philippus, etc Notum etc, nos infrascriptas vi...   \n",
      "4  Philippus, etc Notum etc, nos infrascriptas vi...   \n",
      "\n",
      "                                   prediction.prompt prediction.line  \\\n",
      "0  Correct the spelling and grammar of the follow...               s   \n",
      "1  Correct the spelling and grammar of the follow...               s   \n",
      "2  Correct the spelling and grammar of the follow...               s   \n",
      "3  Correct the spelling and grammar of the follow...             NaN   \n",
      "4  Correct the spelling and grammar of the follow...             NaN   \n",
      "\n",
      "  prediction.sentence prediction.region  \n",
      "0                 NaN               NaN  \n",
      "1                                   NaN  \n",
      "2                                        \n",
      "3                                   NaN  \n",
      "4                                     P  \n",
      "../data/output/prompt_complex_02/sample/results-sample-gpt2.jsonl\n",
      "  language                                           filename  dataset_name  \\\n",
      "0      NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "1      NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "2      NaN  ../../data/datasets/ocr/original/impresso-nzz/...  impresso-nzz   \n",
      "3       fr  ../../data/datasets/ocr/original/icdar-2019/IC...    icdar-2019   \n",
      "\n",
      "   File  Date  Type  NbAlignedChar  article_id  \\\n",
      "0   NaN   NaN   NaN            NaN         NaN   \n",
      "1   NaN   NaN   NaN            NaN         NaN   \n",
      "2   NaN   NaN   NaN            NaN         NaN   \n",
      "3   NaN   NaN   NaN            NaN         NaN   \n",
      "\n",
      "                                            ocr.line  \\\n",
      "0  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "1  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "2  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "3                                               None   \n",
      "\n",
      "                                        ocr.sentence  \\\n",
      "0  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "1  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "2  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "3  Nous, eu conseil seur ce et deliberacion pleni...   \n",
      "\n",
      "                                          ocr.region  \\\n",
      "0  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "1  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "2  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "3  Philippus, etc Notum etc, nos infrascriptas vi...   \n",
      "\n",
      "                                    groundtruth.line  \\\n",
      "0  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "1  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "2  ve>nachlässig'c» Slilrichtung wieder gebührend...   \n",
      "3                                               None   \n",
      "\n",
      "                                groundtruth.sentence  \\\n",
      "0  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "1  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "2  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "3  Nous, eu conseil seur ce et deliberacion pleni...   \n",
      "\n",
      "                                  groundtruth.region  \\\n",
      "0  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "1  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "2  J»r erste» Kapitel dieses zweiten Teiles „Kirc...   \n",
      "3  Philippus, etc Notum etc, nos infrascriptas vi...   \n",
      "\n",
      "                                   prediction.prompt  \\\n",
      "0  Correct the spelling and grammar of the follow...   \n",
      "1  Correct the spelling and grammar of the follow...   \n",
      "2  Correct the spelling and grammar of the follow...   \n",
      "3  Correct the spelling and grammar of the follow...   \n",
      "\n",
      "                                     prediction.line  \\\n",
      "0  \"Värst der welt der wirtschaftlicher von seite...   \n",
      "1  \"Värst der welt der wirtschaftlicher von seite...   \n",
      "2  \"Värst der welt der wirtschaftlicher von seite...   \n",
      "3                                                NaN   \n",
      "\n",
      "                                 prediction.sentence  \\\n",
      "0                                                NaN   \n",
      "1  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "2  Die schönen Barockbauten, tu e sie namentlich ...   \n",
      "3  \"In order to be considered a true saint, the i...   \n",
      "\n",
      "                                   prediction.region  \n",
      "0                                                NaN  \n",
      "1                                                NaN  \n",
      "2  j»r erste» Kapitel die einigen Gorten müsschen...  \n",
      "3                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for root, dirs, files in os.walk('../data/output'):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jsonl\"):\n",
    "            input_file = os.path.join(root, file)\n",
    "            print(input_file)\n",
    "            with open(input_file) as f:\n",
    "                lines = f.read().splitlines()\n",
    "            df_inter = pd.DataFrame(lines)\n",
    "            df_inter.columns = ['json_element']\n",
    "            df_inter['json_element'].apply(json.loads)\n",
    "            df = pd.json_normalize(df_inter['json_element'].apply(json.loads))\n",
    "            results.append(df)\n",
    "            print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b6874171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['language', 'filename', 'dataset_name', 'File', 'Date', 'Type',\n",
       "       'NbAlignedChar', 'article_id', 'ocr.line', 'ocr.sentence', 'ocr.region',\n",
       "       'groundtruth.line', 'groundtruth.sentence', 'groundtruth.region',\n",
       "       'prediction.prompt', 'prediction.line', 'prediction.sentence',\n",
       "       'prediction.region'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "7d2fd86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _, item in results[1].iterrows():\n",
    "    print('**', item['groundtruth.sentence'])\n",
    "    print('**', item['prediction.sentence'])\n",
    "    print('--'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1e9e23c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance\n",
    "\n",
    "def levenshtein(reference, hypothesis, progress_bar=False):\n",
    "    print(reference, hypothesis)\n",
    "    \n",
    "    assert len(reference) == len(hypothesis)\n",
    "    text = zip(reference, hypothesis)\n",
    "    if progress_bar:\n",
    "        text = tqdm(text, total=len(reference))\n",
    "    d = [distance(r, h) for r, h in text]\n",
    "    output = pd.DataFrame({\"reference\": reference, \"hypothesis\": hypothesis})\\\n",
    "        .assign(distance=lambda df: d)\\\n",
    "        .assign(\n",
    "        cer=lambda df: df.apply(\n",
    "            lambda r: 100 * r[\"distance\"] / max(len(r[\"reference\"]), 1),\n",
    "            axis=1\n",
    "        )\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "769fcf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ve>nachlässig'c»\", 'Slilrichtung', 'wieder', 'gebührende', 'Beach'] [\"ve>nachlässig'c»\", 'Slilrichtung', 'wieder', 'gebührende', 'Beach']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>distance</th>\n",
       "      <th>cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ve&gt;nachlässig'c»</td>\n",
       "      <td>ve&gt;nachlässig'c»</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Slilrichtung</td>\n",
       "      <td>Slilrichtung</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wieder</td>\n",
       "      <td>wieder</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gebührende</td>\n",
       "      <td>gebührende</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beach</td>\n",
       "      <td>Beach</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          reference        hypothesis  distance  cer\n",
       "0  ve>nachlässig'c»  ve>nachlässig'c»         0  0.0\n",
       "1      Slilrichtung      Slilrichtung         0  0.0\n",
       "2            wieder            wieder         0  0.0\n",
       "3        gebührende        gebührende         0  0.0\n",
       "4             Beach             Beach         0  0.0"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein(\"ve>nachlässig'c» Slilrichtung wieder gebührende Beach\".split(), \n",
    "            \"ve>nachlässig'c» Slilrichtung wieder gebührende Beach\".split(), progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "c8cd641f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "f852dff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genalog.text import anchor\n",
    "\n",
    "def align_texts(gt_text, ocr_text):\n",
    "\n",
    "    # We align the texts with RETAS Method\n",
    "    aligned_gt, aligned_noise = anchor.align_w_anchor(gt_text, ocr_text)\n",
    "    \n",
    "    print('GT:', gt_text)\n",
    "    print('OCR:', ocr_text)\n",
    "    print('--'*100)\n",
    "    return aligned_gt, aligned_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "400da48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT: lich den Mobilisirungsbeschluß, der uns an das Lichterauslöschen\n",
      "OCR: lich den Mobilistrungöbeschluß, der unS an daS LtchterauSlöschen\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GT: lich den Mobilisirungsbeschluß, der uns an das Lichterauslöschen\n",
      "OCR: lich den Mobilistrungöbeschluß, der unS an daS LtchterauSlöschen\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GT: lich den Mobilisirungsbeschluß, der uns an das Lichterauslöschen\n",
      "OCR: lich den Mobilistrungöbeschluß, der unS an daS LtchterauSlöschen\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GT: Churl« Sibley, ussault and robbery , W llliam Downie,\n",
      "OCR: Charles Sibley, assault and robbery , W llliam Downie,\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GT: Churl« Sibley, ussault and robbery , W llliam Downie,\n",
      "OCR: Charles Sibley, assault and robbery , W llliam Downie,\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GT: Churl« Sibley, ussault and robbery , W llliam Downie,\n",
      "OCR: Charles Sibley, assault and robbery , W llliam Downie,\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GT: Treue besäßen als wir, damit Spanten eines ewigen Glü\n",
      "OCR: Treue besäßen als wir, damit Spanten eines ewigen Glü\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GT: Treue besäßen als wir, damit Spanten eines ewigen Glü\n",
      "OCR: Treue besäßen als wir, damit Spanten eines ewigen Glü\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GT: Treue besäßen als wir, damit Spanten eines ewigen Glü\n",
      "OCR: Treue besäßen als wir, damit Spanten eines ewigen Glü\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GT: Schranken des bloßen Orden» o''Üiend.\n",
      "OCR: Schranken des bloßen Orden» o''Üiend.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GT: Schranken des bloßen Orden» o''Üiend.\n",
      "OCR: Schranken des bloßen Orden» o''Üiend.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GT: Schranken des bloßen Orden» o''Üiend.\n",
      "OCR: Schranken des bloßen Orden» o''Üiend.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GT: Die Zahl der am 19. November gefangen ge\n",
      "OCR: Die Zahl der ani 19. November gefangen ge\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GT: Die Zahl der am 19. November gefangen ge\n",
      "OCR: Die Zahl der ani 19. November gefangen ge\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/rv/x6hk7f3j7dzb763m4m3kgmb00000gp/T/ipykernel_54449/2213641330.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m         \u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcolumn\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcolumn\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mreplace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m     results[idx][['groundtruth.line', 'ocr.line']] = results[idx].apply(lambda x: align_texts(x['groundtruth.line'], \n\u001B[0m\u001B[1;32m     14\u001B[0m                                                                                               x['ocr.line']), axis=1)\n\u001B[1;32m     15\u001B[0m     results[idx][['groundtruth.line', 'prediction.line']] = results[idx].apply(lambda x: align_texts(x['groundtruth.line'], \n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__setitem__\u001B[0;34m(self, key, value)\u001B[0m\n\u001B[1;32m   3641\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_setitem_frame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3642\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mSeries\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mIndex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3643\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_setitem_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3644\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3645\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_set_item_frame_value\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m_setitem_array\u001B[0;34m(self, key, value)\u001B[0m\n\u001B[1;32m   3700\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3701\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3702\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iset_not_inplace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3703\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3704\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_iset_not_inplace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m_iset_not_inplace\u001B[0;34m(self, key, value)\u001B[0m\n\u001B[1;32m   3719\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_unique\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3720\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3721\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Columns must be same length as key\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3722\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3723\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcol\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "for idx, result in enumerate(results):\n",
    "    \n",
    "    results[idx] = results[idx].fillna('No text')\n",
    "    \n",
    "    def replace(x):\n",
    "        if len(x.strip()) == 0:\n",
    "            return 'No text'\n",
    "        return x\n",
    "    \n",
    "    for column in results[idx].columns:\n",
    "        results[idx][column] = results[idx][column].apply(lambda x: replace(x))\n",
    "        \n",
    "#     results[idx][['groundtruth.line', 'ocr.line']] = results[idx].apply(lambda x: align_texts(x['groundtruth.line'], \n",
    "#                                                                                               x['ocr.line']), axis=1)\n",
    "    results[idx][['groundtruth.line', 'prediction.line']] = results[idx].apply(lambda x: align_texts(x['groundtruth.line'], \n",
    "                                                                                                     x['prediction.line']), axis=1)\n",
    "    \n",
    "#     x = results[idx].apply(lambda x: levenshtein(x['groundtruth.line'].split(), \n",
    "#                                                             x['ocr.line'].split()), axis=1)\n",
    "#     x = results[idx].apply(lambda x: levenshtein(x['groundtruth.sentence'].split(), \n",
    "#                                                                 x['ocr.sentence'].split()), axis=1)\n",
    "#     x = results[idx].apply(lambda x: levenshtein(x['groundtruth.region'].split(), \n",
    "#                                                               x['ocr.region'].split()), axis=1)\n",
    "    print(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c91a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17376b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad23574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be027b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1498901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "afe6e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "61d62894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frankreich. Paris, 7 Pluv. (17 Jan.)'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[idx]['ocr.line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d30c0223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frankreich.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[idx]['ocr.sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fc777d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frankreich. Paris, 7 Pluv. (17 Jan.) Das Tribunal hat nach einem zweimaligen Scratin Dupuy (Mitglied des National-Institutö ) zu seinem Candidaten für den Erhaltunge - Senat ernannt. Im gesezgebcnden Rath erhielt noch niemand die absolute Mehrheit; wohl aber erblikt man unter den in Vorschlag gebrachten Namen die Exdi- rektorrn Merlin, Revcilliere und Treilhard, dexen erster sogar zi Stimmen hatte.'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[idx]['ocr.region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "351b194c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'ocr.line', 'ocr.sentence', 'ocr.region',\n",
       "       'groundtruth.line', 'groundtruth.sentence', 'groundtruth.region'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "01acbb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ht_raw = \" \".join(df['ocr.sentence'].to_list())\n",
    "# print(f\"{len(set(ht_raw.lower()))} characters in human transcription\")\n",
    "# print(f\"The following characters have not been system-transcribed: \\n{set(ht_raw.lower())-set(st_raw.lower())}\")\n",
    "tokens = ht_raw.split()\n",
    "WORDS = set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a1704285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eddi(input_text, reference_words=WORDS, ed_threshold=25, max_unk_tokens=3):\n",
    "    \"\"\" Baseline I: Edit distance -based Baseline\n",
    "    An edit distance-based baseline: Given a list of valid (reference) words,\n",
    "    this baseline (called eddi) detects words not in the reference list and \n",
    "    changes them to the closest one in the reference list.\n",
    "    :param input_text: the source text\n",
    "    :param reference_words: a list of valid words (e.g., computed from the target data) \n",
    "    :param ed_threshold: the edit distance threshold below from which a word is replaced\n",
    "    :param max_unk_tokens: the max number of unknown tokens in the transcribed text \n",
    "    :return: the new text\n",
    "    \"\"\"\n",
    "    tokens = input_text.split()\n",
    "    # Unknown transcribed tokens; proceed only if few\n",
    "    unknowns = [i for i, w in enumerate(tokens) if w not in reference_words]\n",
    "    if len(unknowns) > max_unk_tokens:\n",
    "        return \" \".join(tokens)\n",
    "\n",
    "    for ind in unknowns:\n",
    "        # Replace each uknown token with the ground truth token w/min edit distance \n",
    "        word = tokens[ind]\n",
    "        min_cer, new_word = 100, word\n",
    "        for ref in reference_words:\n",
    "            candidate_min_cer = pywer.cer([ref], [word])\n",
    "            if candidate_min_cer < min_cer:\n",
    "                min_cer = candidate_min_cer\n",
    "                if min_cer < ed_threshold:\n",
    "                    new_word = ref\n",
    "    tokens[ind] = new_word\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab1d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b6097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ff5018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f60dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e38d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d142c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
