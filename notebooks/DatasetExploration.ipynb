{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfadbdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f79f14e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/datasets/ocr/converted/icdar-2017.jsonl\n",
      "../data/datasets/ocr/converted/overproof.jsonl\n",
      "../data/datasets/ocr/converted/icdar-2019.jsonl\n",
      "../data/datasets/ocr/converted/impresso-nzz.jsonl\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "\n",
    "for root, dirs, files in os.walk('../data/datasets/ocr/converted'):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jsonl\"):\n",
    "            input_file = os.path.join(root, file)\n",
    "            print(input_file)\n",
    "            with open(input_file) as f:\n",
    "                lines = f.read().splitlines()\n",
    "            df_inter = pd.DataFrame(lines)\n",
    "            df_inter.columns = ['json_element']\n",
    "            df_inter['json_element'].apply(json.loads)\n",
    "            df = pd.json_normalize(df_inter['json_element'].apply(json.loads))\n",
    "            datasets.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "121a8252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " Index(['language', 'filename', 'dataset_name', 'File', 'Date', 'Type',\n",
       "        'NbAlignedChar', 'ocr.line', 'ocr.sentence', 'ocr.region',\n",
       "        'groundtruth.line', 'groundtruth.sentence', 'groundtruth.region'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets), datasets[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58611ad0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched '[' (4215641899.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"/var/folders/rv/x6hk7f3j7dzb763m4m3kgmb00000gp/T/ipykernel_54449/4215641899.py\"\u001B[0;36m, line \u001B[0;32m3\u001B[0m\n\u001B[0;31m    print(f'No. lines: {dataset}, Total: {len(dataset['ocr.sentence'])}',\u001B[0m\n\u001B[0m                                                       ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m f-string: unmatched '['\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset['dataset_name'].unique())\n",
    "    print('No. lines:', dataset['ocr.line']. nunique(), len(dataset['ocr.sentence']), \n",
    "          'No. sentences:', dataset['ocr.sentence']. nunique(), len(dataset['ocr.sentence']), \n",
    "          'No. regions:', dataset['ocr.region']. nunique(), len(dataset['ocr.region']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98df9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e69fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6859897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e25dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "afe6e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "61d62894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frankreich. Paris, 7 Pluv. (17 Jan.)'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[idx]['ocr.line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d30c0223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frankreich.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[idx]['ocr.sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fc777d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frankreich. Paris, 7 Pluv. (17 Jan.) Das Tribunal hat nach einem zweimaligen Scratin Dupuy (Mitglied des National-Institutö ) zu seinem Candidaten für den Erhaltunge - Senat ernannt. Im gesezgebcnden Rath erhielt noch niemand die absolute Mehrheit; wohl aber erblikt man unter den in Vorschlag gebrachten Namen die Exdi- rektorrn Merlin, Revcilliere und Treilhard, dexen erster sogar zi Stimmen hatte.'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[idx]['ocr.region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "351b194c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'ocr.line', 'ocr.sentence', 'ocr.region',\n",
       "       'groundtruth.line', 'groundtruth.sentence', 'groundtruth.region'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "01acbb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ht_raw = \" \".join(df['ocr.sentence'].to_list())\n",
    "# print(f\"{len(set(ht_raw.lower()))} characters in human transcription\")\n",
    "# print(f\"The following characters have not been system-transcribed: \\n{set(ht_raw.lower())-set(st_raw.lower())}\")\n",
    "tokens = ht_raw.split()\n",
    "WORDS = set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a1704285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eddi(input_text, reference_words=WORDS, ed_threshold=25, max_unk_tokens=3):\n",
    "    \"\"\" Baseline I: Edit distance -based Baseline\n",
    "    An edit distance-based baseline: Given a list of valid (reference) words,\n",
    "    this baseline (called eddi) detects words not in the reference list and \n",
    "    changes them to the closest one in the reference list.\n",
    "    :param input_text: the source text\n",
    "    :param reference_words: a list of valid words (e.g., computed from the target data) \n",
    "    :param ed_threshold: the edit distance threshold below from which a word is replaced\n",
    "    :param max_unk_tokens: the max number of unknown tokens in the transcribed text \n",
    "    :return: the new text\n",
    "    \"\"\"\n",
    "    tokens = input_text.split()\n",
    "    # Unknown transcribed tokens; proceed only if few\n",
    "    unknowns = [i for i, w in enumerate(tokens) if w not in reference_words]\n",
    "    if len(unknowns) > max_unk_tokens:\n",
    "        return \" \".join(tokens)\n",
    "\n",
    "    for ind in unknowns:\n",
    "        # Replace each uknown token with the ground truth token w/min edit distance \n",
    "        word = tokens[ind]\n",
    "        min_cer, new_word = 100, word\n",
    "        for ref in reference_words:\n",
    "            candidate_min_cer = pywer.cer([ref], [word])\n",
    "            if candidate_min_cer < min_cer:\n",
    "                min_cer = candidate_min_cer\n",
    "                if min_cer < ed_threshold:\n",
    "                    new_word = ref\n",
    "    tokens[ind] = new_word\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab1d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b6097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ff5018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f60dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e38d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d142c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
